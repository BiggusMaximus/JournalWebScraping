title,link,number_of_citation,article_type,publisher,publication_date,abstract,keyword
Evaluating Deep Reinforcement Learning Methods to Develop an Intelligent Traffic Controller,https://ieeexplore.ieee.org/document/9970176/,1,Conference Paper,IEEE,2022,"In this study, deep reinforcement learning-based algorithms - Deep Q-Learning (DQN), Covariance Matrix Adaptation Evolution Strategy (CMA-ES), and Advantage Actor- Critic (A2C) - are tested to control vehicle traffic in Webots World Simulation. This work also uses a microscopic traffic simulator called Simulation of Urban Mobility (SUMO) to run traffic simulations. Ray, an open-source distributed computing platform, was used to accelerate the model's training, which uses a single dynamic execution engine to allow task-parallel and actor- based computations. The algorithms were evaluated and tested against fixed-time traffic control configurations and were proven more efficient. The results also show that A2C had the best performance among the learning-based approaches, while CMA- ES had the least in terms of total vehicle wait time.","Deep Learning ,  Deep Reinforcement Learning ,  Traffic Control ,  Intelligent Control ,  Reinforcement Learning Methods ,  Deep Reinforcement Learning Method ,  Covariance Matrix ,  Waiting Time ,  Distributed Computing ,  Traffic Simulation ,  Deep Q-learning ,  Single Execution ,  Control System ,  Deep Neural Network ,  PyTorch ,  Light Signal ,  Traffic Congestion ,  State Representation ,  Traffic Light ,  Real-world Environments ,  Abstract Representations ,  Road Intersections ,  Reinforcement Learning Algorithm ,  Traffic System ,  Experience Replay ,  Vehicle Routing ,  Deep Reinforcement Learning Algorithm ,  Traffic Management ,  Reinforcement Learning Agent ,  Traffic Control System "
Routing based on layered stochastic games for multi-hop cognitive radio networks,https://ieeexplore.ieee.org/document/6951923/,1,Conference Paper,IEEE,2014,"This paper proposes a distributed routing mechanism for the multi-hop Cognitive Radio Networks (CRNs) over multiple primary channels. The Secondary Users (SUs) attempts to utilize the channels and minimize their delay along the route while avoiding causing interference to the Primary Users (PUs). In order to address the problem of time-varying channel condition due to the PU dynamics, the route-selection process is modeled as a global Markov Decision Process (MDP). We show that such a global routing MDP can be decomposed into the layered MDPs, in which the interactions between neighbor SUs with their local next-hop selection are modeled as the local stochastic games. By applying reinforcement learning with utility based fictitious play, the best response of each SU can be learned from the local game with the only need for the information exchange from next-hop SUs. The proposed algorithm is evaluated through simulations and is shown to be effective in reducing the delays for multiple flows in the CRN.","Cognitive Networks ,  Multi-hop Networks ,  Stochastic Game ,  Channel State ,  Best Response ,  Markov Decision Process ,  Multiple Flow ,  Primary Channel ,  Secondary Users ,  Application Of Reinforcement Learning ,  Transition State ,  Local Information ,  Inner Layer ,  Time Slot ,  Local Strategies ,  Spectrum Information ,  Dijkstra’s Algorithm ,  State Transition Probability ,  Unlicensed Spectrum ,  Routing Algorithm ,  Relay Selection ,  Action-value Function ,  Routing Scheme ,  Cluster Head ,  Stage Of The Game ,  Topological Clusters ,  Cost Path ,  Static Algorithm ,  State-value Function ,  Sum Of Delay "
Secure-Energy Efficient Bio-Inspired Clustering and Deep Learning-Based Routing Using Blockchain for Edge Assisted WSN Environment,https://ieeexplore.ieee.org/document/10366278/,0,Journal Article,IEEE,2023,"In recent days, the usage of data transmission has increased in Wireless Sensor Network (WSN) environments due to its dynamic nature. However, WSNs face many issues during data transmission, such as less energy efficiency, less security, and less network lifetime. Here, in this research it presents secure and energy-efficient clustering and routing techniques for an edge-assisted WSN environment to address these problems. The proposed work includes four major processes: Quad tree-based network construction, energy-efficient clustering, RL-based duty cycling, and secure multipath routing. This work constructs the network based on a quad-tree structure to increase network management performance and reduce complexity. After network construction, authentication of sensors is performed by considering ID and location using the Lightweight Encryption Algorithm (LEA), which provides high security by eliminating illegitimate sensor nodes. Then, this research model performs clustering using Tasmanian Devil Optimization (TDO), which selects optimal CH and performs clustering. In contrast, the CH selection and clustering are performed dynamically by considering time and event metrics, which increases communication efficiency and reduces energy depletion. To reduce energy consumption, This research model performs duty cycling using the Improved Twin Delayed Deep Deterministic Policy Gradient (ITD3) algorithm, increasing the network lifetime. Finally, A secure multipath routing is performed using a game theory-based Generative Adversarial Network (GTGAN). During routing, GTGAN ranks the selected multipath based on their hop counts. The highest-ranked paths are chosen for transmitting an emergency message, and medium-ranked paths are selected for non-emergency message transmission, which reduces data loss due to energy depletion. Here, all the transactions are stored on the blockchain for increased security. The NS-3.26 network simulator conducts the simulation of this research, a...","Wireless Sensor Networks ,  Efficient Route ,  Efficient Clustering ,  Wireless Sensor Networks Environment ,  Energy Consumption ,  Energy Efficiency ,  Performance Metrics ,  Data Transmission ,  Authentication ,  Duty Cycle ,  Data Loss ,  Reduce Energy Consumption ,  Efficient Communication ,  Simulated Networks ,  Network Management ,  High Security ,  Energy Depletion ,  Network Lifetime ,  Tasmanian Devil ,  Packet Delivery Ratio ,  Edge Server ,  Pathfinding ,  Target Network ,  Packet Loss Rate ,  Shortest Path ,  Cluster Head ,  Optimal Path ,  Optimization Algorithm ,  Trust Value "
An Intelligent Path Planning Mechanism for Firefighting in Wireless Sensor and Actor Networks,https://ieeexplore.ieee.org/document/10014987/,4,Journal Article,IEEE,2023,"Forests have an important role in environmental preservation and maintenance. The primary threat is forest fires, which have disastrous repercussions. As a result, it is critical to identify and extinguish a fire before it spreads and destroys resources. To that end, we propose a forest fire detection and fighting mechanism using wireless sensor and actor networks (WSANs). Temperature sensors are utilized to detect fires, and actors (robots) are employed to extinguish them. Sensors and robots are distributed at random throughout the forest, forming clusters. Clustering, sleep/active scheduling for the sensors, and energy harvesting (EH)/moving modes for the robots, are used to extend and maximize the sensors/robots lifetime in the WSAN. In such a network, robots should move to the fire site as quickly as possible. To do this, we further propose a robot routing mechanism that focuses on determining the shortest path for each firefighting robot. In particular, each firefighting robot equipped with on-board processing uses a fuzzy 
 $Q$ 
-learning (FQL)-based trajectory mechanism to learn the shortest path to the fire zone in the least amount of time. Simulations are conducted to demonstrate the benefits of employing the proposed framework for rapid and effective fire response. When compared to the traditional 
 $Q$ 
-learning, the total approaching rate (a measure of how quickly the firefighting robots can reach the fire) to the fire spot is greater when utilizing the proposed FQL-based strategy.","Sensor Networks ,  Path Planning ,  Actor Network ,  Wireless Sensor ,  Wireless Sensor Networks ,  Shortest Path ,  Wildfire ,  Temperature Sensor ,  Energy Harvesting ,  Fire Detection ,  Local Actors ,  Internet Of Things ,  Thermal Energy ,  Shortest Distance ,  Detection Probability ,  Fuzzy Set ,  Firefighters ,  Fuzzy System ,  Active Sensors ,  Optimal Path ,  Fire Extinguishing ,  Fire Occurrence ,  Trajectory Design ,  Learning Agent ,  Sleep Mode ,  Dangerous Areas ,  Humanoid Robot ,  Straight Path ,  Scheduling Scheme ,  Ultrasonic Sensors "
Mobility-Aware Routing and Caching in Small Cell Networks Using Federated Learning,https://ieeexplore.ieee.org/document/10292924/,1,Journal Article,IEEE,2024,"We consider a service cost minimization problem for resource-constrained small-cell networks with caching, where the challenge mainly stems from (i) the insufficient backhaul capacity and limited network bandwidth and (ii) the limited storing capacity of small-cell base stations (SBSs). Besides, the optimization problem is NP-hard since both the users’ mobility patterns and content preferences are unknown. In this paper, we develop a novel mobility-aware joint routing and caching strategy to address the challenges. The designed framework divides the entire geographical area into small sections containing one SBS and several mobile users (MUs). Based on the concept of one-stop-shop (OSS), we propose a federated routing and popularity learning (FRPL) approach in which the SBSs cooperatively learn the routing and preference of their respective MUs and make a caching decision. The FRPL method completes multiple tasks in one shot, thus reducing the average processing time per global aggregation of learning. By exploiting the outcomes of FRPL together with the estimated service edge of SBSs, the proposed cache placement solution greedily approximates the minimizer of the challenging service cost optimization problem. Theoretical and numerical analyses show the effectiveness of our proposed approaches.","Federated Learning ,  Small Cell Networks ,  Optimization Problem ,  Mobility Patterns ,  Mobile Users ,  Routing Scheme ,  Caching Scheme ,  Global Model ,  Dynamic Network ,  Internet Of Things ,  Time Slot ,  Quality Of Experience ,  Deep Reinforcement Learning ,  File Size ,  Cumulative Density ,  Network Cost ,  Greedy Approach ,  Integer Programming Problem ,  Content Popularity ,  Content Caching ,  Federated Learning Model ,  Cache Size ,  Cache Hit ,  Federated Learning Framework ,  Mean Opinion Score ,  Network Coding ,  Cache Misses ,  Lowest Cost ,  Least Square Error ,  Cluster Centroids "
Software-Defined Networking for Flying Ad-hoc Network Security: A Survey,https://ieeexplore.ieee.org/document/9842415/,1,Conference Paper,IEEE,2022,"Despite the immense use of single Unmanned Aerial Vehicle (UAV) systems in various applications, it is not yet able to cover large areas with optimized energy consumption. Accordingly, Flying Ad-hoc Network (FANET), as a collaborative groups of UAV s, is tremendously employed in recent research works allowing larger coverage and efficient monitoring. To ensure a secure FANET control, Software-Defined Networking (SDN) based solutions are frequently considered. This work presents and compares the recent SDN-based solutions proposed to reinforce FANET security and reduce its attacks. In addition, open research issues are highlighted with respect to SDN-FANET challenges.","Flying Ad Hoc Networks ,  Energy Consumption ,  Unmanned Aerial Vehicles ,  Efficient Monitoring ,  Recent Research Work ,  Learning Algorithms ,  Center For Control ,  Encryption ,  Data Transmission ,  Pathfinding ,  Security Measures ,  Wireless Technologies ,  Wireless Sensor Networks ,  Reinforcement Learning Algorithm ,  Attack Detection ,  Ground Station ,  Low Earth Orbit ,  Minimum Energy Consumption ,  Control Plane ,  Jamming Attacks ,  Dynamic Topology ,  Network Attacks ,  Blockchain ,  Control Station ,  Secure Data Transmission ,  Throughput ,  High Altitude ,  Routing Path ,  Routing Scheme "
Leveraging Deep Reinforcement Learning for Traffic Engineering: A Survey,https://ieeexplore.ieee.org/document/9507541/,50,Journal Article,IEEE,2021,"After decades of unprecedented development, modern networks have evolved far beyond expectations in terms of scale and complexity. In many cases, traditional traffic engineering (TE) approaches fail to address the quality of service (QoS) requirements of modern networks. In recent years, deep reinforcement learning (DRL) has proved to be a feasible and effective solution for autonomously controlling and managing complex systems. Massive growth in the use of DRL applications in various domains is beginning to benefit the communications industry. In this paper, we firstly provide a comprehensive overview of DRL-based TE. Then, we present a detailed literature review on applications of DRL for TE including three fundamental issues: routing optimization, congestion control, and resource management. Finally, we discuss our insights into the challenges and future research perspectives of DRL-based TE.","Deep Learning ,  Deep Reinforcement Learning ,  Traffic Engineering ,  Complex Systems ,  Service Quality ,  Resource Management ,  Optimal Management ,  Applicability Domain ,  Pathfinding ,  Quality Of Service Requirements ,  Detailed Literature Review ,  Number Of Researchers ,  Optimal Policy ,  Reinforcement Learning Algorithm ,  Critic Network ,  Policy Gradient ,  Mobile Edge Computing ,  Trust Region ,  Round-trip Time ,  Deep Reinforcement Learning Algorithm ,  Deep Q-network ,  Multi-agent Reinforcement Learning ,  Deep Reinforcement Learning Model ,  Deep Reinforcement Learning Agent ,  Continuous Action Space ,  Proximal Policy Optimization ,  Policy Gradient Algorithm ,  Network Slicing ,  Experience Replay ,  Reinforcement Learning Problem "
Reinforcement Learning based Scheduling for Cooperative EV-to-EV Dynamic Wireless Charging,https://ieeexplore.ieee.org/document/9356077/,5,Conference Paper,IEEE,2020,"Previous Electric Vehicle (EV) charging scheduling methods and EV route planning methods require EVs to spend extra waiting time and driving burden for a recharge. With the advancement of dynamic wireless charging for EVs, Mobile Energy Disseminator (MED), which can charge an EV in motion, becomes available. However, existing wireless charging scheduling methods for wireless sensors, which are the most related works to the deployment of MEDs, are not directly applicable for the scheduling of MEDs on city-scale road networks. We present MobiCharger: a Mobile wireless Charger guidance system that determines the number of serving MEDs, and the optimal routes of the MEDs periodically (e.g., every 30 minutes). Through analyzing a metropolitan-scale vehicle mobility dataset, we found that most vehicles have routines, and the temporal change of the number of driving vehicles changes during different time slots, which means the number of MEDs should adaptively change as well. Then, we propose a Reinforcement Learning based method to determine the number and the driving route of serving MEDs. Our experiments driven by the dataset demonstrate that MobiCharger increases the medium state-of-charge and the number of charges of all EVs by 50% and 100%, respectively.","Wireless Charging ,  Dynamic Wireless Charging ,  Electric Vehicles ,  Road Network ,  Time Slot ,  Pathfinding ,  Wireless Sensor ,  Number Of Charges ,  Route Planning ,  Guidance System ,  Travel Time ,  Current Position ,  Wireless Sensor Networks ,  Autoregressive Integrated Moving Average ,  Battery Capacity ,  Historical Trajectory ,  Road Segments ,  Charging Time ,  Time Trajectories ,  Multiple Constraints ,  Reinforcement Learning Model ,  Electric Vehicles Charging ,  Taxicab ,  Average Flow Rate ,  Vehicle Density ,  State St ,  Current Trajectory ,  Routing Method ,  Charging Demand ,  Dijkstra’s Algorithm "
Intelligent Fault-Tolerance Data Routing Scheme for IoT-Enabled WSNs,https://ieeexplore.ieee.org/document/9714263/,30,Journal Article,IEEE,2022,"Wireless sensor networks (WSNs) have become one of the essential components of the Internet of Things (IoT). In any IoT application, different sensor-based devices gather data from physical objects and transmit the sensed information to the base station (BS). The BS analyzes this information depending on the sensor location. A high-performance intelligent WSNs is essential for any IoT-based application. In this article, high-performance intelligent WSNs are referred to as IoT-enabled WSNs. In IoT-enabled WSNs, fault occurrence probability is much more than traditional networks. Faulty nodes and broken links affect the reliability of the IoT-enabled WSNs. Various fault-tolerance algorithms enhance the network’s reliability using multipath transmission, relay node placement, and backup node selection. However, these algorithms suffer from huge data transmission delays, packet overhead, and less detection accuracy. In this work, a multiobjective-deep reinforcement-learning (DRL)-based algorithm is proposed for fault tolerance in IoT-enabled WSNs. The main objective of this work is to detect the faulty nodes with high accuracy and less overhead. Furthermore, this work focuses on reliable data transmission after fault detection. Finally, a mobile sink (MS) is used for energy-efficient data gathering that significantly improves the network lifetime. Extensive simulations and theoretical analysis prove that the proposed algorithm outperformed as compared to the state-of-the-art algorithms in terms of fault detection accuracy (FDA), false alarm rate (FAR), false-positive rate (FPR), network lifetime, and throughput.","Fault-tolerant ,  Wireless Sensor Networks ,  IoT-enabled Wireless Sensor Networks ,  False Positive Rate ,  Internet Of Things ,  Physical Body ,  Data Transmission ,  Base Station ,  Extensive Simulations ,  False Alarm Rate ,  Deep Reinforcement Learning ,  Transmission Delay ,  Internet Of Things Applications ,  Relay Nodes ,  Network Lifetime ,  Deep Learning ,  Deep Neural Network ,  Shortest Path ,  Feed-forward Network ,  Multi-objective Optimization ,  Pareto Optimal Set ,  Optimal Path ,  Network Throughput ,  Residual Energy ,  Adaptive Moment Estimation Optimizer ,  Network Reliability ,  Pareto Optimal ,  Double Deep Q-network ,  Markov Decision Process ,  Types Of Defects "
Adaptive congestion avoidance scheme based on reinforcement learning for wireless sensor network,https://ieeexplore.ieee.org/document/6192860/,3,Conference Paper,IEEE,2011,"Energy efficiency and QoS-aware are the key issues of wireless sensor network (WSN). In this paper, we proposed a congestion avoidance scheme devoting to efficient use of energy and adaptive maintain well QoS quality by self-adapt routing. Because it is difficult to obtain the state of network energy and QoS in a practical condition, we are motivated to utilize reinforcement learning to obtain the routing strategy in multi-path communication of WSN. We extend the R-learning algorithm to solve the difficulty of the nodes obtaining the network's status information. We compare the proposed scheme to other congestion avoidance protocols, such as CR. The simulation results show that the performance of our schemes is prior to existing ones.","ordsReinforcement learning ,  adaptive congestion avoidance ,  wireless sensor network ,  QoS "
Q-Learning Based Routing Optimization Algorithm for Underwater Sensor Networks,https://ieeexplore.ieee.org/document/10531215/,1,other,IEEE,2024,"Underwater wireless sensor network (UWSN) plays a vital role in the field of ocean development and exploration. Designing a routing protocol for UWSN is a great challenge due to the characteristics of short lifetime and high delay. This paper proposes a Q-learning based routing optimization algorithm for UWSN. Two reward functions are designed based on the average residual energy of network, integrating factors such as energy information, transmission delay and link success rate to better balance transmission quality and lifetime. In addition, a holding time mechanism for packet forwarding is developed according to the priority of nodes. The simulation results show that compared to DBR and QLFR algorithms, this algorithm can effectively reduce transmission delay and prolong network lifetime.","ordsQ-learning ,  reinforcement learning ,  routing selection ,  underwater wireless sensor network "
Reinforcement-Learning-Based Solutions to Power Issues in Wireless IoT System,https://ieeexplore.ieee.org/document/9403837/,0,Conference Paper,IEEE,2020,"With the combination of Internet and Things, people's life become more efficient and convenient, which leads to the explosive growth of data and the consumption of resources as well. Hence, in an IoT (Internet of Things) system, it is an emergent problem to optimize the strategy of resource allocation, which will help to maximize the resources utilization. In the mean time, it is becoming more and more difficult to deal with the skyrocketing data by using traditional routing protocols. In recent years, deep learning also develops dramatically, which is applied in many industries and fields. This paper concentrates on summarizing reinforcement-learning-based existing solutions and proposing a comprehensive solution, which optimizes the traditional structure and strategy of wireless internet of things system.","Internet Of Things ,  Internet Of Things Systems ,  Resource Consumption ,  Learning Process ,  Learning Models ,  Value Function ,  Survival Time ,  Power Consumption ,  Wireless Networks ,  Root Node ,  Wireless Sensor ,  Radio Frequency Identification ,  Reward Function ,  Markov Decision Process ,  Wireless Sensor Networks ,  Q-learning ,  Bellman Equation ,  Task Scheduling ,  State Transition Probability ,  Action-value Function ,  Internet Of Things Nodes ,  State-value Function ,  Cumulative Return ,  Objective Function ,  Optimal Control Problem ,  Power Efficiency ,  Dynamic Programming ,  Transition Probabilities ,  Sink Node ,  Network Topology "
ECORS: Energy consumption-oriented route selection for wireless sensor network,https://ieeexplore.ieee.org/document/7819318/,7,Conference Paper,IEEE,2016,"Automated metering infrastructure is employed widely in scientific fields as well as in industrial and commercial areas due to the development of wireless sensor network (WSN) technology. WSNs provide important features such as wireless multi-hop communication and they are easy to install everywhere; thus, extending the lifetime of WSNs is highly desirable. All WSN nodes consume a limited amount of energy from the battery during operations such as sensing, calculating, control, and communication and most of the power consumption is attributable to wireless communication. In this study, we propose energy consumption-oriented route selection (ECORS), which is a route selection algorithm that focuses on the remaining energy and energy consumption by WSN nodes. In ECORS, a sink node calculates all of the routes in the system by using the route lifetime (RL) as a metric according to the minimum residual energy (MRE) and the expected route cost (ERC). The route with the longest RL is selected by the proposed algorithm. By changing the route periodically using ECORS, the WSN system lasts 1.14 times longer as compared to that when the routes are fixed. We evaluated the performance of ECORS using an original WSN simulator. In realistic simulations, we measured the distance-packet error rate, current consumption, and discharge characteristic of a battery using actual sensor nodes assembled with an Arduino micro controller, XBee ZigBee wireless module, and lithium-polymer battery.","Wireless Sensor ,  Wireless Sensor Networks ,  Route Selection ,  Energy Consumption ,  Selection Algorithm ,  Current Consumption ,  Residual Energy ,  Sink Node ,  Aggregate Data ,  Shortest Path ,  Base Station ,  Topological Changes ,  Monitoring Applications ,  Total Energy Consumption ,  Data Packets ,  Wireless Devices ,  Loss Ratio ,  Destination Node ,  Battery Lifetime ,  System Lifetime ,  Network Lifetime ,  Sleep Mode ,  Battery Level ,  Topology Control ,  Cluster Head "
A Taxonomy of Machine-Learning-Based Intrusion Detection Systems for the Internet of Things: A Survey,https://ieeexplore.ieee.org/document/9610131/,35,Journal Article,IEEE,2022,"The Internet of Things (IoT) is an emerging technology that has earned a lot of research attention and technical revolution in recent years. Significantly, IoT connects and integrates billions of devices and communication networks around the world for several real-time IoT applications. On the other hand, cybersecurity attacks on the IoT are growing at an alarming rate since these devices are vulnerable because of their limited battery life, global connectivity, resource-constrained nature, and mobility. When attacks on IoT networks go undetected within a speculated period, such security attacks may prompt severe threats and disruptive behavior inside the network and make the network unavailable to the end user. Hence, it is quintessential to design an intelligent and robust security approach that promptly detects potential attack surfaces in a dynamic IoT network. This article investigates a comprehensive survey of machine learning, deep learning, and reinforcement learning-based intelligent intrusion detection techniques for securing IoT. Also, this article thoroughly illustrates the implementation of various categories of security threats in IoT with a neat diagram. Significantly, we classify the threats into two broad categories: 1) wireless sensor networks (WSNs) inherited security attacks and 2) routing protocol for low power and lossy networks (RPL) specific security attacks in IoT. Finally, we present potential research opportunities and challenges in intelligent intrusion detection approaches in future IoT security.","Internet Of Things ,  Intrusion Detection ,  Intrusion Detection System ,  Machine Learning ,  Deep Learning ,  Machine Learning Techniques ,  Detection Techniques ,  Deep Learning Techniques ,  Security Threats ,  Wireless Sensor Networks ,  Global Connectivity ,  Potential Attacks ,  Internet Of Things Networks ,  Specific Attack ,  Security Attacks ,  Internet Of Things Security ,  Intelligent Detection ,  Convolutional Neural Network ,  Hidden Layer ,  Types Of Attacks ,  Malicious Nodes ,  Restricted Boltzmann Machine ,  Sybil Attack ,  Deep Belief Network ,  Recurrent Neural Network ,  Anomaly Detection ,  Malware Detection ,  Internet Of Things Devices ,  Unsupervised Learning "
Learning to Predict Consequences as a Method of Knowledge Transfer in Reinforcement Learning,https://ieeexplore.ieee.org/document/7902152/,29,Journal Article,IEEE,2018,"The reinforcement learning (RL) paradigm allows agents to solve tasks through trial-and-error learning. To be capable of efficient, long-term learning, RL agents should be able to apply knowledge gained in the past to new tasks they may encounter in the future. The ability to predict actions' consequences may facilitate such knowledge transfer. We consider here domains where an RL agent has access to two kinds of information: agent-centric information with constant semantics across tasks, and environment-centric information, which is necessary to solve the task, but with semantics that differ between tasks. For example, in robot navigation, environment-centric information may include the robot's geographic location, while agent-centric information may include sensor readings of various nearby obstacles. We propose that these situations provide an opportunity for a very natural style of knowledge transfer, in which the agent learns to predict actions' environmental consequences using agent-centric information. These predictions contain important information about the affordances and dangers present in a novel environment, and can effectively transfer knowledge from agent-centric to environment-centric learning systems. Using several example problems including spatial navigation and network routing, we show that our knowledge transfer approach can allow faster and lower cost learning than existing alternatives.","Knowledge Transfer ,  Knowledge Transfer Method ,  Semantic ,  Environmental Effects ,  Affordances ,  Learning System ,  Spatial Navigation ,  Sensor Readings ,  Learning Agent ,  Robot Navigation ,  Network Routing ,  Reinforcement Learning Agent ,  Future Encounters ,  Trial-and-error Learning ,  Learning Algorithms ,  Prediction Error ,  State Space ,  Types Of Problems ,  Transfer Learning ,  Test Environment ,  Source Task ,  Markov Decision Process ,  Markov Decision Process Model ,  Simulated Robot ,  Q-learning ,  Negative Transfer ,  Learning Cost ,  Transition Function ,  Distance Sensor ,  Shared Features "
Energy Conservation in Wireless Body Area Network Using Optimal Route Selection and Node Configuration,https://ieeexplore.ieee.org/document/10245674/,0,Conference Paper,IEEE,2023,"Wireless body area networks (WBAN) are becoming increasingly popular nowadays due to their wide range of applications, particularly in the field of healthcare systems. In the medical field, a WBAN is frequently used to collect biomedical signals and monitor vital signals from a patient on whose body sensors are placed at points of interest. In WBAN applications such as disease analysis, diagnostic monitoring and tracking, a number of hardware and software factors must be considered. Optimization of energy consumed by a WBAN is a significant problem that should be addressed especially when its application is in mobile or outdoor environments where batteries are the main source of power. In this paper, an optimal route selection and node configuration method (ORS-NCM) is proposed to reduce energy consumption. It finds an optimal route by considering all the related metrics and also maintains the link stability to prolong the network lifetime. The proposed ORS-NCM scheme is implemented using MATLAB simulation tool, and its results are compared to the state-of-the-art Energy Optimized Congestion Control Based Temperature Aware Routing Algorithm (EOCC-TARA). In terms of energy consumption, latency, throughput, and hop count, simulation results show that ORS-NCM exhibits better performance than EOCC-TARA in delivering packets from source to the destination.","Energy Conservation ,  Optimal Selection ,  Pathfinding ,  Body Area Networks ,  Optimal Node ,  Wireless Body Area Networks ,  Optimal Route Selection ,  Energy Consumption ,  Throughput ,  Optimization Method ,  Reduce Energy Consumption ,  Routing Algorithm ,  Network Lifetime ,  Body Sensor ,  Hop Count ,  Deep Learning ,  Service Quality ,  Energy Minimization ,  Energy Efficiency ,  Wearable ,  Intelligent Reflecting Surface ,  Deep Reinforcement Learning ,  Cost-effective Route ,  Energy Usage ,  Minimum Energy Consumption ,  Residual Energy ,  Wireless Sensor ,  Encryption ,  Shortest Distance "
A System Based on Deep-Learning for Dynamic Routing problems,https://ieeexplore.ieee.org/document/9773930/,3,Conference Paper,IEEE,2022,"This paper analyzes the use of reinforcement learning with the Proximal Policy Optimization algorithm (PPO) in the context of the Dynamic Travelling Repairman Problem (DTRP). DTRP are routing problems in which one or multiple agents needs to optimize the processing time of dynamically generated requests. The study case of this paper is of a Unmanned Aerial Vehicle with no motion constraints and unlimited sensing that needs to service multiple targets in bounded environments, while minimizing the waiting time of each target. We analyze the performance of two different types of neural networks architecture, a feed-forward network and convolutional neural network (CNN). The performance of each network is analyzed in terms of the number of targets serviced and the average waiting time. Two heuristic policies, ‘Nearest-first’ (NF) and ‘First Generated First Served’ (FGFS), are used as baselines to compare the performance of the neural networks. The results show that CNNs perform better than a feed forward network. Differently from the feed forward network, the CNN network is able to capture the spatial features of the environment reducing the average waiting times of the targets. The CNN architecture also shows potential to perform as well as the heuristics. Further work is necessary to extend the proposed solution to other situations.","Deep Learning ,  Routing Problem ,  Neural Network ,  Convolutional Neural Network ,  Optimization Algorithm ,  Network Performance ,  Feed-forward Network ,  Unmanned Aerial Vehicles ,  Optimal Policy ,  Convolutional Neural Network Architecture ,  Proximal Policy Optimization ,  Motion Constraints ,  Time Step ,  Value Function ,  Convolutional Layers ,  Poisson Distribution ,  Target Location ,  Workspace ,  Types Of Networks ,  Markov Decision Process ,  Actor Network ,  Position Of Agent ,  Optimal Value Function ,  Episode Length ,  Critic Network ,  Reward Function ,  Markov Property ,  Feed-forward Architecture "
"A Centralized Cross-Layer Protocol for Joint Power Control, Link Scheduling, and Routing in UWSNs",https://ieeexplore.ieee.org/document/10327721/,1,Journal Article,IEEE,2024,"The characteristics of volatile ocean environments and complex acoustic communication channels have posed great difficulties to the design of real-time data transmission in underwater wireless sensor networks (UWSNs). In this article, we develop a centralized cross-layer protocol that mitigates network interference and maximizes concurrent transmissions to reduce end-to-end delay. Instead of optimizing individual layers separately, we blend the traditional layered architecture and combine the physical layer, medium access control (MAC) layer, and network layer functions together. Specifically, we optimize the power control in the physical layer, link scheduling in the MAC layer, and routing in the network layer jointly to achieve a global optimization of end-to-end delay. First, the joint design problem is formulated as a mixed-integer linear programming (MILP) problem, which is an NP-hard problem and hard to solve mathematically. Then, we propose a bio-inspired-algorithm-based solution, namely, the discrete improved artificial bee colony (DIABC) algorithm, aiming at finding an approximate optimal cross-layer scheduling scheme. To further reduce end-to-end delay, we optimize the uplink frame structure and routing metric in the centralized cross-layer framework. The simulation results show that the proposed protocol achieves network performance improvement in terms of end-to-end delay, service rate, and energy consumption.","Power Control ,  Underwater Wireless Sensor Networks ,  Link Scheduling ,  Cross-layer Protocol ,  Simulation Results ,  Network Layer ,  Data Transmission ,  Linear Programming ,  Access Control ,  Service Rate ,  Bee Colonies ,  Mixed-integer Programming ,  NP-hard Problem ,  Physical Layer ,  Wireless Sensor Networks ,  Mixed Integer Linear Programming ,  Scheduling Scheme ,  Joint Design ,  Medium Access Control ,  Mixed-integer Programming Problem ,  Data Packets ,  Nectar Sources ,  Transmission Link ,  Time Slot ,  Reinforcement Learning Algorithm ,  Average Energy Consumption ,  Relay Nodes ,  Propagation Delay ,  Joint Optimization Problem ,  Underwater Acoustic "
Towards In-Band Telemetry for Self Driving Wireless Networks,https://ieeexplore.ieee.org/document/9162923/,4,Conference Paper,IEEE,2020,"Self-driving network is an emerging network automation design principle for building next generation autonomous networked systems based on machine learning algorithms trained on real-time experiences, i.e., network state measurements. However, existing network measurement techniques are designed on centralized architecture leading to considerable control overheads in wireless networks. In this work, we designed and implemented a distributed In-band network telemetry system (S-INT) and Wireless Network Operating System (WINOS) for self-driving wireless networks. On one hand, our proposed S-INT system significantly reduces network measurement overhead by embedding telemetry into flowing data traffic with a specialized packet header. WINOS system, on the other hand, seamlessly integrates programmable measurement, i.e., the proposed S-INT framework, with the programmable network control, while providing rich APIs to facilitate fast implementation of machine learning algorithms for intelligent and distributed network control. To show the effectiveness of our proposed system design, we implemented a multi-agent reinforcement routing as a traffic engineering application to optimize end-to-end delay performance. To the best of our knowledge, our implementation is the first one in the literature that enables multi-agent reinforcement learning algorithm to run on an actual physical wireless multihop network.","Wireless Networks ,  Learning Algorithms ,  Control Network ,  Network State ,  Reinforcement Learning Algorithm ,  Telemetry System ,  Multi-agent Reinforcement Learning ,  Delay Performance ,  Traffic Engineering ,  Packet Header ,  Throughput ,  Network Topology ,  Local Policy ,  Traffic Flow ,  Data Packets ,  Network Management ,  Mesh Network ,  Average Delay ,  Packet Loss ,  Control Decisions ,  Control Plane ,  Datapath ,  Telemetry Data ,  Flow Table ,  Hop Count ,  Routing Algorithm ,  Field Of Networks ,  Traffic Load ,  Flow Statistics ,  Forward Activity "
Machine Learning Techniques and A Case Study for Intelligent Wireless Networks,https://ieeexplore.ieee.org/document/8961909/,42,other,IEEE,2020,"With the widespread deployment of wireless technologies and IoT, 5G wireless networks will support various communication connectivity and services for the huge number of wireless smart/ intelligent devices and machines. The challenge lies in assisting wireless networks to intelligently learn experience, autonomously optimize network configurations and smartly make decisions to support massive wireless smart devices with minimum human intervention, so the diverse and colorful service requirements can be satisfied with the optimum performance. Machine learning, as one of the powerful artificial intelligence tools, is capable of efficiently supporting wireless smart devices by assisting them to smartly observe the environment, analyze data and make decisions with the intelligence. Hence, in this article, we briefly review the major concepts of common machine learning techniques and present their potential applications in intelligent wireless networks, including spectrum sensing, channel estimation, device clustering, behavior prediction, position tracking, data demission reduction, adaptive routing, energy harvesting/efficiency, resource management, and so on. Furthermore, we propose deep reinforcement learning for intelligent resource management in intelligent wireless networks in an exemplary case study. Simulation results demonstrate the effectiveness and advance of machine learning in intelligent wireless networks.","Machine Learning ,  Machine Learning Techniques ,  Wireless Networks ,  Deep Learning ,  Resource Management ,  Predictor Of Behavior ,  Learning Network ,  Smart Devices ,  Wireless Technologies ,  Deep Reinforcement Learning ,  Channel Estimation ,  Wireless Devices ,  Service Requirements ,  Position Tracking ,  Intelligent Management ,  Minimal Human Intervention ,  Support Vector Machine ,  Value Function ,  Supervised Learning ,  Unsupervised Learning ,  Future Wireless Networks ,  Markov Decision Process ,  Support Vector Regression ,  Mobility Prediction ,  Transmission Scheduling ,  Spectrum Access ,  Q-function ,  Kriging ,  Reinforcement Learning Algorithm ,  Isometry "
TFACR: A Novel Topology Control Algorithm for Improving 5G-Based MANET Performance by Flexibly Adjusting the Coverage Radius,https://ieeexplore.ieee.org/document/10261987/,1,Journal Article,IEEE,2023,"Topology control in next-generation wireless networks has recently attracted the interest of several researchers. The network performance is significantly affected by the topology. Therefore, creating an optimal topology is essential, particularly in fifth-generation (5G) networks, where latency, throughput, energy efficiency, and other performance metrics are highly stringent. In this study, we investigated topology control algorithms in 5G-based mobile ad-hoc networks (MANET). A novel algorithm, namely Topological control by Flexibly Adjusting the Coverage Radius (TFACR) was proposed to improve network performance. The main idea of the TFACR algorithm is to adjust the communication range flexibly to obtain the desired degree of nodes. The degree constraint of the neighboring nodes is considered each time a node adjusts the communication area to ensure node degree balancing throughout the network topology. The TFACR algorithm is implemented in the OMNET++ and INET frameworks using the Reinforcement Learning-based routing protocol (RLRP), Ad-hoc On-demand Distance Vector (AODV) and Destination Sequenced Distance Vector (DSDV) routing protocols to evaluate its performance. The simulation results proved that the proposed algorithm outperformed well-known topology control algorithms in terms of the average node degree, quality of transmission, and energy consumption. This is suitable for 5G-based MANET.","Ad Hoc Networks ,  Topology Control ,  Coverage Radius ,  Topology Control Algorithm ,  Energy Consumption ,  Simulation Results ,  Energy Efficiency ,  Performance Metrics ,  Network Topology ,  Network Performance ,  Wireless Networks ,  Average Degree ,  Neighboring Nodes ,  Network Algorithm ,  Well-known Algorithms ,  Communication Range ,  5G Networks ,  Topology Optimization ,  Distance Vector ,  Average Node Degree ,  Wireless Link ,  Spanning Tree ,  Pause Time ,  Network Load ,  Local Algorithm ,  Traffic Load ,  Path Loss ,  Simulation Scenarios ,  Routing Table ,  Wireless Sensor Networks "
RL-Budget: A Learning-Based Cluster Size Adjustment Scheme for Cognitive Radio Networks,https://ieeexplore.ieee.org/document/8119944/,15,Journal Article,IEEE,2018,"Cognitive radio (CR) enables unlicensed users to sense for and access underutilized licensed channels (or white spaces) owned by the licensed users in an opportunistic manner. Clustering segregates nodes in a network into logical groups called clusters. In CR networks (CRNs), larger cluster size improves network scalability thereby contributing to reduced routing overhead; however, it reduces cluster stability as the number of available common channels in a cluster reduces resulting in increased number of re-clusterings and clustering overhead. This paper presents our proposed first-of-its-kind cluster size adjustment scheme based on an artificial intelligence approach called reinforcement learning. The proposed scheme adapts the cluster size with the amount of white spaces as time goes by in order to improve network scalability and cluster stability in CRNs. Due to the lack of progress in the investigation of cluster size adjustment schemes in the literature, this paper also analyzes their attributes, and then presents such schemes investigated in various kinds of distributed wireless networks. Simulation results show that our proposed scheme improves network scalability by creating larger clusters, and improves cluster stability by reducing the number of re-clusterings (i.e., the number of cluster splits) and clustering overhead, while reducing interference between licensed and unlicensed users in CRNs.","Cluster Size ,  Cognitive Networks ,  Cognitive Radio ,  Large Clusters ,  Network Clustering ,  Stable Clusters ,  White Space ,  Common Channel ,  Number Of Splits ,  Channel Clustering ,  Larger Cluster Sizes ,  Schemes In The Literature ,  Energy Consumption ,  Small Clusters ,  Cluster Formation ,  Open Channel ,  Base Station ,  Neighboring Nodes ,  Successful Delivery ,  Cluster Nodes ,  Channel Network ,  Small Cluster Sizes ,  Wireless Sensor Networks ,  Ad Hoc Networks ,  Neighbor Clustering ,  OFF Periods ,  Channel Capacity ,  Single Hop ,  Cluster Size Threshold ,  Packet Size "
Adaptive Parametric Routing Based on Dynamic Metrics for Wireless Sensor Networks,https://ieeexplore.ieee.org/document/5683608/,1,Conference Paper,IEEE,2010,"Designing a QoS-aware, yet energy-saving routing protocol for WSNs is a notoriously hard problem. However, the outstanding interest for this technology, and the growing number of envisioned applications, motivate the need to introduce the notion of Quality of Service (QoS) in these networks. This paper introduces EDEAR (Energy and Delay Efficient Adaptive Routing), an adaptive routing algorithm based on route exploration and reinforcement learning. We evaluate EDEAR with simulations, under various network mobility conditions. Our results show that EDEAR outperforms any other routing protocol, delivering packets with the shortest delay, while reducing energy consumption. As a result, EDEAR's features allow to increase the network lifetime by 9-18%.","dsPeer to peer computing ,  Routing ,  Delay ,  Routing protocols ,  Quality of service ,  Energy consumption "
A Novel CCAP Protocol to Increase Security with Energy Efficiency for Wireless Sensor Networks,https://ieeexplore.ieee.org/document/10395236/,0,Conference Paper,IEEE,2023,"The need to save energy in Wireless Sensor Network (WSN) systems is now widely recognized as an important design goal. The Sensor Nodes (SNs) within a WSN network run on onboard batteries, which deplete over time. Therefore, increasing the length of the life span of sensors through optimizing data depletion in a cost-effective and long-lasting manner concerning energy consumption remains a difficulty. Despite its convenience, WSNs are vulnerable to a broad range of threats from both within and beyond the network, particularly attacks by insiders being particularly challenging to identify and counter. Most typically, hackers pose an insider attack on clustered WSNs by selectively discarding incoming information packets. This research presents the implementation of a Compact Crypto Authenticating Policy (CCAP) to provide highly confidential data aggregation from Member Node (MN) to Cluster Head (CH) along with from CHs to Sink Node (SiN). Intending to set up highly effective and secure paths for communication in WSNs, it takes into account the dynamics of traffic and the challenges connected with resource constraints. The proposed CCAP aims to achieve an equilibrium between energy efficiency and communication throughput, and it does so by providing a suitable cryptographic technique that guarantees safe communication. This study extends the generalization to demonstrate the viability of the proposed secured protocol for routing despite a wide range of unexpected challenges. According to the evaluation methods, the proposed CCAP protocol offers better security than the existing “Hashing Signature Code (HSC)” protocol based on Security Ratio, Energy Consumption Ratio, Computation Time, and Key Generation Time.","Energy Efficiency ,  Wireless Sensor Networks ,  Energy Consumption ,  Computation Time ,  Aggregate Data ,  Authentication ,  Sink Node ,  Input Parameters ,  Computational Resources ,  Discovery Process ,  Communication Process ,  Time Slot ,  Deep Reinforcement Learning ,  Secure Communication ,  Data Packets ,  Security Requirements ,  Parity-check ,  Key Size ,  Routing Information ,  Security Solutions ,  Multi-hop Communication ,  Encryption Process ,  Encryption And Decryption ,  Secure Link ,  Presence Of Attacks ,  Control Messages ,  Key Security ,  Energy Requirements ,  Communication Links "
A Novel Reinforcement Learning Framework for Adaptive Routing in Network-on-Chips,https://ieeexplore.ieee.org/document/9781172/,0,Conference Paper,IEEE,2021,"Adaptive routing is crucial to the overall performance of network-on-chips (NoCs), and still faces great challenges, especially when emerging applications on many-core architecture exhibit complicated and time-varying traffic patterns. When witnessing most existing heuristic adaptive routing algorithms fail to address multi-objective optimization for complex traffic well, we decide to try and explore a new approach of thinking and extracting insights from network behaviors. Reinforcement learning methods have demonstrated promising opportunity applied to architecture design exploration, however not been well applied on adaptive routing design. We make the first attempt to propose a novel and comprehensive reinforcement learning framework for adaptive routing on NoCs, called RELAR. RELAR is suitable for diversified traffic patterns and resolve multi-objective optimization simultaneously. It is able to effectively isolate endpoint congestion when facing adversary hot-spot and bursty traffic, and achieve dynamic load-balancing and mitigate network congestion when meeting heavy uniform traffic. We utilize state-of-the-art high-performance interconnection benchmark, GPCNeT, as traffic generators to generate rich network congestion workloads and thus enhance online-training efficiency of RELAR. We conduct extensive experiments against state-of-the-art routing algorithms to evaluate our design. The results show that RELAR achieves 14.82% and 9.86% reduction in packet latency on average, and reduces packet latency by up to 34.24% and 16.82% under heavy synthetic traffic workload and high-performance interconnection benchmark, respectively. We also perform cost analysis to validate potential implementation of RELAR on NoCs with low computation, storage and power.","Adaptive Routing ,  Adaptive Algorithm ,  Multi-objective Optimization ,  Heuristic Algorithm ,  Heavy Workload ,  Network Behavior ,  Low Computation ,  Traffic Patterns ,  Network Congestion ,  Latency Reduction ,  Routing Algorithm ,  Neural Network ,  Footprint ,  Batch Size ,  Performance Gap ,  Communication Patterns ,  Congested ,  Load Balancing ,  Injection Rate ,  Output Ports ,  Replay Memory ,  Greedy Policy ,  Average Latency ,  Benchmark Suite ,  Buffer State ,  Degree Of Congestion ,  Packet Size ,  Synthetic Benchmark ,  Memory Size ,  Deep Q-network "
