title,link,number_of_citation,article_type,publisher,publication_date,abstract,keyword
Networked Control of Nonlinear Systems under Partial Observation Using Continuous Deep Q-Learning,https://ieeexplore.ieee.org/document/9029214/,1,Conference Paper,IEEE,2019,"In this paper, we propose a design of a model-free networked controller for a nonlinear plant whose mathematical model is unknown. In a networked control system, the controller and plant are located away from each other and exchange data over a network, which causes network delays that may fluctuate randomly due to network routing. So, in this paper, we assume that the current network delay is not known but an estimated maximum value of fluctuating network delays is known beforehand. Moreover, we also assume that the sensor cannot observe all state variables of the plant. Under these assumption, we apply continuous deep Q-learning to the design of the networked controller. Then, we introduce an extended state consisting of a sequence of past control inputs and outputs as inputs to the deep neural network. By simulation, it is shown that, using the extended state, the controller can learn a control policy robust to the fluctuation of the network delays under the partial observation.","Nonlinear Systems ,  Control Network ,  Partial Observation ,  Deep Q-learning ,  Mathematical Model ,  Deep Neural Network ,  Control Design ,  Control Input ,  Input Sequence ,  Output Sequence ,  Output Control ,  Extended State ,  Networked Control Systems ,  Network Delay ,  Model-free Control ,  Past Inputs ,  Optimal Control ,  Hidden Layer ,  Morphine ,  Control Problem ,  Deep Reinforcement Learning ,  Deep Reinforcement Learning Algorithm ,  Positive Definite Matrix ,  Q-learning Algorithm ,  Status Of Plants ,  Long-term Reward ,  Function Approximation ,  Target Network ,  Digital Control ,  Optimal Control Policy "
Cooperative Data Collection for UAV-Assisted Maritime IoT Based on Deep Reinforcement Learning,https://ieeexplore.ieee.org/document/10473119/,0,Journal Article,IEEE,2024,"In maritime data collection scenarios, achieving the rapid delivery of data from buoy sensor nodes to the shipboard station is a challenging issue. Utilizing unmanned aerial vehicles (UAVs) technology to facilitate the transfer of data from buoy sensor nodes, it becomes feasible to significantly reduce the latency generated in the transmission process. Therefore, we introduce a UAV-assisted maritime Internet of Things (MIoT) data collection mechanism based on relay cooperation. In this mechanism, through relay transmissions among UAVs, it avoids UAVs located distant from the shipboard station from having to traverse extensive distances in order to offload data to the shipboard station. Based on this, we propose a deep reinforcement learning-based cooperative data collection (DCDC) scheme. In this scheme, firstly, we select the convergence node in charge of forwarding the data from buoy sensor nodes to the passing UAVs. Next, to achieve dynamic adaptation of the task areas for UAVs, we propose an adaptive partition algorithm based on virtual moving points. Subsequently, to establish relay transmission links between UAVs, we present a routing algorithm based on matching game theory. Finally, to reduce time costs in delivering collected data to the shipboard station, we utilize a deep reinforcement learning algorithm based on multi-agent deep deterministic policy gradient (MADDPG) plan the flight paths of UAVs. Additionally, we introduce virtual waypoints in the path planning algorithm, which enables that paired UAVs can high-efficiently perform data forwarding through encounter opportunities. Extensive simulation experiments have demonstrated that the proposed scheme outperforms existing schemes in terms of system Age of Information (AoI).","Deep Learning ,  Deep Reinforcement Learning ,  Age Of Information ,  Unmanned Aerial Vehicles ,  Path Planning ,  Collection Strategy ,  Reinforcement Learning Algorithm ,  Flight Path ,  Policy Gradient ,  Deterministic Policy ,  Deep Reinforcement Learning Algorithm ,  Opportunities For Encounters ,  Optimization Algorithm ,  Changes In Position ,  Time-of-flight Mass Spectrometry ,  Data Transmission ,  Time Slot ,  Actor Network ,  Node Positions ,  Markov Decision Process ,  Number Of Sensor Nodes ,  Critic Network ,  Data Packets ,  Unmanned Ground Vehicles ,  Suitable Opportunities ,  Signaling Overhead ,  Round Of Data Collection ,  Task Allocation ,  Training Episodes ,  Ant Colony Optimization "
Machine Learning based Vehicle-to-Infrastructure Communication in VANETs,https://ieeexplore.ieee.org/document/9691730/,2,Conference Paper,IEEE,2021,"Vehicular network plays a major role in understanding the detail study of vehicle communications. Multiple vehicles in local communication range need to exchange the safety and infotainment information via common roadside infrastructure in Vehicular Ad hoc Networks (VANETs). Vehicle-to-Infrastructure (V2I) communication model help to improve the efficiency of intelligent transport system by providing safety warnings and reducing vehicle collisions. Machine learning is an artificial intelligence component that gives the machine an ability to automatically learn without being expressly trained to improve from experience. Since VANET is imprecise and uncertain in nature, Machine Learning (ML) and Software Agents (SAs) combining approaches resolve the issues of V2I communication challenges in VANETs. This paper proposes ML based V2I Communication in VANETs using software agent approach. The proposed agent-based model is made up of both static and mobile agents. Proposed model executes decision tree algorithm and Q-Learning algorithm to identify the event as non critical or critical and the destination vehicle respectively to improve bandwidth utilization, packet delivery ratio and end-to-end delay.","Machine Learning ,  Vehicular Ad Hoc Networks ,  Infrastructure ,  Decision Tree ,  Multi-agent ,  Intelligent Transportation Systems ,  Decision Tree Algorithm ,  Ad Hoc Networks ,  Vehicular Networks ,  Mobile Agents ,  Bandwidth Utilization ,  Packet Delivery Ratio ,  Software Agents ,  V2I Communication ,  Knowledge Base ,  Performance Metrics ,  Global Positioning System ,  Critical Information ,  Information Gain ,  Traffic Congestion ,  Roadside Units ,  Cognitive Agents ,  Sensor Output ,  Deep Reinforcement Learning ,  Dedicated Short Range Communication ,  Greedy Policy ,  Gini Coefficient ,  Mobile Information ,  Action-value Function ,  Network Environment "
Adversarial RL-Based IDS for Evolving Data Environment in 6LoWPAN,https://ieeexplore.ieee.org/document/9916285/,6,Journal Article,IEEE,2022,"Low-power and Lossy Networks (LLNs) comprise nodes characterised by constrained computational power, memory, and energy resources. The LLN nodes empower ubiquitous connections amongst numerous devices (e.g. temperature, humidity, and turbidity sensors, together with motors, valves and other actuators) to sense, control and store properties of their environments. They are often deployed in hostile, unattended, and unfavourable conditions. Securing them often becomes very challenging. The extent of interconnected LLN devices poses a series of routing threats (e.g. wormhole, grayhole, DIO suppression, and increase rank attacks). Consequently, an efficient and effective intrusion detection system (IDS) is of utmost importance in identifying anomalous activities in the IPv6 over Low-powered Wireless Personal Area Networks (6LoWPAN). This article proposes a robust Adversarial Reinforcement Learning (ARL) framework to generate efficient IDSs for evolving data environments. The integration of ARL and incremental machine-learning facilitates the generation of resource-efficient and robust IDS detectors. We demonstrate in particular how such an approach, leveraging notions of ‘concept drift’ detection and adaptation, can handle inevitable changes in the environment, giving the IDS best chances of detecting attacks in the current profile. The range of routing attacks considered is the most comprehensive to date. For the first time, Black-box and Grey-box ML-based adversaries aiming to destabilise the 6LoWPAN are distinguished and addressed.","Intrusion Detection System ,  Intrusion ,  Generative Adversarial Networks ,  Humidity Sensor ,  Intrusion Detection ,  Wormhole ,  Concept Drift ,  Major Classes ,  Data Streams ,  Linear Time ,  Black Hole ,  Imbalanced Data ,  Initiation Phase ,  Types Of Attacks ,  Minority Class ,  Adversarial Attacks ,  Literature Articles ,  Positive Reward ,  Legitimate Actors ,  Deep Q-network ,  Control Packets ,  Double Deep Q-network ,  Sinkhole ,  Malicious Nodes ,  Non-stationary Environments ,  Levels Of Drift ,  Catastrophic Forgetting ,  Imbalanced Datasets ,  Malicious Activities ,  Large Amount Of Data "
Decentralized Task Assignment for Mobile Crowdsensing With Multi-Agent Deep Reinforcement Learning,https://ieeexplore.ieee.org/document/10122773/,5,Journal Article,IEEE,2023,"Task assignment is a fundamental research problem in mobile crowdsensing (MCS) since it directly determines an MCS system’s practicality and economic value. Due to the complex dynamics of tasks and workers, task assignment problems are usually NP-hard, and approximation-based methods are preferred to impractical optimal methods. In the literature, a graph neural network-based deep reinforcement learning (GDRL) method is proposed in Xu and Song (2022) to solve routing problems in MCS and shows high performance and time efficiency. However, GDRL, as a centralized method, has to cope with the limitation in scalability and the challenge of privacy protection. In this article, we propose a multi-agent deep reinforcement learning-based method named communication-QMIX-based multi-agent DRL (CQDRL) to solve a task assignment problem in a decentralized fashion. The CQDRL method not only inherits the merits of GDRL over handcrafted heuristic and metaheuristic methods but also exploits computation potentials in mobile devices and protects workers’ privacy with a decentralized decision-making scheme. Our extensive experiments show that the CQDRL method can achieve significantly better performance than other traditional methods and performs fairly close to the centralized GDRL method.","Deep Reinforcement Learning ,  Multi-agent Deep Reinforcement Learning ,  Mobile Crowdsensing ,  Privacy ,  Heuristic Method ,  Central Method ,  Routing Problem ,  Deep Reinforcement Learning Method ,  Neural Network ,  Computational Resources ,  Number Of Workers ,  Network Parameters ,  Travel Time ,  State Value ,  Joint Action ,  Weight Training ,  Local Observations ,  Coverage Ratio ,  Total Profit ,  Task Allocation ,  Vector Of Node ,  Network Of Agents ,  Worker Nodes ,  Profit Ratio ,  Graph Attention Network ,  Mixed Network ,  Learning Layer ,  Reinforcement Learning Task ,  Problem Instances ,  NP-hard Problem "
Security threats in military cognitive radio networks,https://ieeexplore.ieee.org/document/7158714/,5,Conference Paper,IEEE,2015,"The emergence of new wireless services and the growing demand for wireless communications are creating a spectrum shortage problem. Moreover, the current technique of static frequency allocation leads to inefficiency utilization of the available spectrum. Cognitive radio (CR) and dynamic spectrum management (DSM) concepts, aim to solve this imbalance between scarcity and under utilization of the spectrum by dynamically using the free frequency bands. However, this technology introduces new vulnerabilities and opportunities for malicious users compared to traditional wireless networks due to its intrinsic characteristics. In this paper, we present a comprehensive review of common CR attacks and their potential countermeasures with projection on military radio networks. We classify the attacks based on the four main functions of the cognitive radio, not according to the layers of the OSI model as usually done. Through this classification, we tried to provide directions for related researches to discern which cognitive functionality has to be insured against each threat.","Wireless Networks ,  Cognitive Networks ,  Cognitive Radio ,  Frequency Band ,  Unlicensed Spectrum ,  Wireless Services ,  Dynamic Spectrum ,  Malicious Users ,  Common Attacks ,  Learning Algorithms ,  Military Service ,  Spectral Bands ,  Game Theory ,  Commons ,  Set Of Frequencies ,  Control Channel ,  Signal-to-interference-plus-noise Ratio ,  Legitimate Users ,  Routing Information ,  Control Messages ,  Jamming Attacks ,  Spectrum Access ,  Malicious Nodes ,  Frequency Hopping ,  Military Communications ,  Spread Spectrum ,  Spectrum Channel ,  Multi-agent Reinforcement Learning ,  Cluster Head ,  Hash Function "
Improving Energy Efficiency and QoS of LPWANs for IoT Using Q-Learning Based Data Routing,https://ieeexplore.ieee.org/document/9542930/,16,Journal Article,IEEE,2022,"Recent proliferation of Internet of Things (IoT) demands large scale connectivity among smart IoT devices over a vast geographical area. However, limited radio range and lack of scalability of conventional wireless sensor networks do not allow a wide area connectivity among IoT devices. To address these challenges, Low-Power Wide-Area Networks (LPWANs) are emerging to provide long-range communication capability with low-power consumption of the end devices. Nevertheless, given the demand in delivering an increasingly large volume of data generated by IoT devices, the direct data transmission model is not suitable due to its poor network lifetime. Therefore, in this work, a multi-hop data routing method is proposed for LPWANs. Since multi-hop data transmission faces several challenges such as increased data latency, higher interference, and reduced data throughput (i.e., poor bandwidth utilization), we propose a reinforcement learning method to address those challenges. The proposed method updates the Q-matrix of the network at varying discrete time instants and selects relay devices in such a way that maximizes the cumulative reward value between selected device-gateway pairs. The applicability and effectiveness of the proposed method are illustrated over both simulated LPWAN testbed and real field data sets. The obtained results clearly demonstrate the improved network performance in terms of energy efficiency and QoS of the proposed method as compared to various existing methods.","Service Quality ,  Energy Efficiency ,  Internet Of Things ,  Improve Energy Efficiency ,  Low Power Wide Area Networks ,  Data Transmission ,  Wide Area ,  Direct Transmission ,  Internet Of Things Devices ,  Cumulative Values ,  Real Field ,  Reinforcement Learning Methods ,  End Devices ,  Data Throughput ,  Improve Network Performance ,  Network Lifetime ,  Bandwidth Utilization ,  Energy Consumption ,  Measurement Model ,  Shortest Path ,  Data Packets ,  Throughput Performance ,  Optimal Path ,  Residual Energy ,  Data Transfer ,  State Of The Device ,  Received Signal Strength Indicator ,  Queue Size ,  Network Energy ,  Transmission Method "
Multi-Agent Reinforcement Learning for Urban Crowd Sensing with For-Hire Vehicles,https://ieeexplore.ieee.org/document/9488713/,13,Conference Paper,IEEE,2021,"Recently, vehicular crowd sensing (VCS) that leverages sensor-equipped urban vehicles to collect city-scale sensory data has emerged as a promising paradigm for urban sensing. Nowadays, a wide spectrum of VCS tasks are carried out by for-hire vehicles (FHVs) due to various hardware and software constraints that are difficult for private vehicles to satisfy. However, such FHV-enabled VCS systems face a fundamental yet unsolved problem of striking a balance between the order-serving and sensing outcomes. To address this problem, we propose a novel graph convolutional cooperative multi-agent reinforcement learning (GCC-MARL) framework, which helps FHVs make distributed routing decisions that cooperatively optimize the system-wide global objective. Specifically, GCC-MARL meticulously assigns credits to agents in the training process to effectively stimulate cooperation, represents agents’ actions by a carefully chosen statistics to cope with the variable agent scales, and integrates graph convolution to capture useful spatial features from complex large-scale urban road networks. We conduct extensive experiments with a real-world dataset collected in Shenzhen, China, containing around 1 million trajectories and 50 thousand orders of 553 taxis per-day from June 1st to 30th, 2017. Our experiment results show that GCC-MARL outperforms state-of-the-art baseline methods in order-serving revenue, as well as sensing coverage and quality.","Multi-agent Reinforcement Learning ,  Spatial Features ,  Sensor Data ,  Road Network ,  Baseline Methods ,  Graph Convolution ,  Global Objective ,  Routing Decisions ,  State Space ,  Multilayer Perceptron ,  Time Slot ,  Joint Action ,  Training Algorithm ,  Number Of Agents ,  Graph Convolutional Network ,  Local Observations ,  Node Features ,  System Utility ,  Road Segments ,  Policy Gradient ,  Credit Assignment ,  State St ,  Intrinsic Rewards ,  Route Choice ,  Graph Attention Network ,  Road Characteristics ,  Breadth-first Search ,  Replay Buffer ,  Training Center ,  Set Of Segments "
Large-Scale Mixed Traffic Control Using Dynamic Vehicle Routing and Privacy-Preserving Crowdsourcing,https://ieeexplore.ieee.org/document/10324334/,0,Journal Article,IEEE,2024,"Controlling and coordinating urban traffic flow through robot vehicles (RVs) is emerging as a novel transportation paradigm for the future. While this approach garners growing attention from researchers and practitioners, effectively managing and coordinating large-scale mixed traffic remains a challenge. We introduce an effective framework for large-scale mixed traffic control via privacy-preserving crowdsourcing and dynamic vehicle routing. Our framework consists of three modules: 1) a privacy-protecting crowdsensing method; 2) a graph propagation-based traffic forecasting method; and 3) a privacy-preserving route selection mechanism. We evaluate our framework using a real-world road network. The results show that our framework accurately forecasts traffic flow, efficiently mitigates network-wide RV shortage issue, and coordinates large-scale mixed traffic. Compared to other baseline methods, our framework not only reduces the RV shortage issue up to 69.4% but also reduces the average waiting time of all vehicles in the network up to 27%.","Traffic Control ,  Vehicle Routing ,  Dynamic Vehicle Routing ,  Road Network ,  Autonomous Vehicles ,  Traffic Flow ,  Baseline Methods ,  Real-world Networks ,  Route Selection ,  Vehicle Network ,  Traffic Forecasting ,  Mean Absolute Error ,  Intersectional ,  Entire Network ,  Light Signal ,  Coordinating Center ,  Directed Graph ,  Traffic Light ,  Traffic Conditions ,  Mean Absolute Percentage Error ,  Road Segments ,  Internet Of Vehicles ,  Traffic Information ,  Traffic Efficiency ,  Route Planning ,  Rate Of Segments ,  Routing Algorithm ,  Privacy Preservation ,  Rush Hour ,  Traffic Data "
"Model, Data and Reward Repair: Trusted Machine Learning for Markov Decision Processes",https://ieeexplore.ieee.org/document/8416249/,3,Conference Paper,IEEE,2018,"When machine learning (ML) models are used in safety-critical or mission-critical applications (e.g., self driving cars, cyber security, surgical robotics), it is important to ensure that they provide some high-level guarantees (e.g., safety, liveness). We introduce a paradigm called Trusted Machine Learning (TML) for making ML models more trustworthy. We use Markov Decision Processes (MDPs) as the underlying dynamical model and outline three TML approaches: (1) Model Repair, wherein we modify the learned model directly; (2) Data Repair, wherein we modify the data so that re-learning from the modified data results in a trusted model; and (3) Reward Repair, wherein we modify the reward function of the MDP to satisfy the specified logical constraint. We show how these repairs can be done efficiently for probabilistic models (e.g., MDP) when the desired properties are expressed in some appropriate fragment of logic such as temporal logic (for example PCTL, i.e., Probabilistic Computation Tree Logic), first order logic or propositional logic. We illustrate our approaches on case studies from multiple domains, e.g., car controller for obstacle avoidance, and a query routing controller in a wireless sensor network.","Machine Learning ,  Markov Decision Process ,  Health-related Quality Of Life ,  Learning Models ,  Machine Learning Models ,  Probabilistic Model ,  Reward Function ,  Wireless Sensor Networks ,  Obstacle Avoidance ,  First-order Logic ,  Temporal Logic ,  Propositional Logic ,  Logical Constraints ,  Order Logic ,  Mission-critical Applications ,  Optimization Problem ,  Learning Algorithms ,  Transition Probabilities ,  Markov Decision Process Model ,  Inverse Reinforcement Learning ,  Self-driving ,  Optimal Policy ,  Safety Properties ,  S2 State ,  Safety Constraints ,  Weight Vector ,  Corrupted Data ,  Temporal Constraints "
IoVSSA: Efficient Mobility-Aware Clustering Algorithm in Internet of Vehicles Using Sparrow Search Algorithm,https://ieeexplore.ieee.org/document/10012622/,11,Journal Article,IEEE,2023,"Internet of Vehicles (IoV), a branch of Internet of Things utilized for vehicle-to-vehicle communication, is attracting attention from both academia and industry. Vehicle nodes are thought to be constantly moving at high speeds, and as a result, IoV faces major challenges, including scalability, rapid topology changes, and shortest routing path. Vehicle clustering is an effective way to enhance IoV communication performance in a large network setting with complicated road conditions and huge number of vehicles. At the same, minimal clusters and selection of stable cluster heads (CHs) reinforce the cluster structure stability. In this sight, we propose a new clustering algorithm based on the recent nature-inspired metaheuristic IoV clustering using sparrow search algorithm (IoVSSA). IoVSSA incorporates mobility metrics along the cluster distance to construct the fewest clusters with stable CHs. Through simulation studies, the effectiveness of the proposed IoVSSA algorithm is assessed and is found to perform better than the state-of-the-art algorithms when it comes to the number of vehicle clusters and average cluster lifetime. Factors, including the network grid size, average cluster lifespan, and node transmission range, are considered for optimal clustering and the experiments make use of a variety of scenarios to compare the effectiveness of each algorithm.","Clustering Algorithm ,  Efficient Clustering ,  Internet Of Vehicles ,  Sparrow Search Algorithm ,  Internet Of Things ,  Shortest Path ,  Grid Size ,  Average Lifetime ,  Stable Clusters ,  Optimal Clustering ,  Distance Clustering ,  Cluster Head ,  Objective Function ,  Fitness Function ,  Multi-objective Optimization ,  Cluster Membership ,  Network Clustering ,  Clustering Techniques ,  Deep Reinforcement Learning ,  Complex Communication ,  Roadside Units ,  Direction Of The Vehicle ,  Ad Hoc Networks ,  Grey Wolf Optimizer ,  Vehicle Network ,  Ant Colony Optimization ,  On-board Unit ,  Cluster Count ,  Cluster Management ,  Multi-objective Genetic Algorithm "
Mitigating Sensor Attacks Against Industrial Control Systems,https://ieeexplore.ieee.org/document/8758093/,17,Journal Article,IEEE,2019,"This paper describes how to design and implement a mechanism that helps to mitigate sensor attacks on industrial control systems. The proposed architecture is based on concepts from fault-tolerant control techniques. This short note explains how a Kalman filter can be used simultaneously with optimal disturbance decoupling observers to improve the performance of the mitigation mechanism for sensor attacks in cyber-physical control systems. Our proposal mitigates attacks by generating a signal that compensates the change provoked by the attacker, while at the same time reducing the number of false alarms. We demonstrate the effectiveness of our proposal using a three tanks control simulation.","Control System ,  Industrial Systems ,  Industrial Control Systems ,  Sensor Attacks ,  Kalman Filter ,  Fault-tolerant Control ,  Linear Model ,  Model System ,  Active Control ,  Actuator ,  Sensory Systems ,  System Output ,  Sensory Signals ,  Anomaly Detection ,  Optimal Estimation ,  Remote Control ,  Denial Of Service ,  Communication Delay ,  Effects Of Attacks ,  Sensor Information ,  False Data Injection Attacks ,  Impact Of Attacks ,  Multi-input Multi-output Systems ,  Kinds Of Attacks ,  Attack Duration ,  Injection Attacks ,  Optimal Control ,  False Data Injection ,  Transmission Network ,  Operating System "
DQN-Based Routing Resources Optimization in UAV Swarm Communication System,https://ieeexplore.ieee.org/document/10404924/,0,Conference Paper,IEEE,2023,"Unmanned Aerial Vehicles (UAVs) can collect a wide variety of data in the air and then transmit them to the ground stations, because of the limited capability of a single UAV, the application of UAV swarm communication system is becoming more and more widespread. Two data communication modes are included, the UAV-to-base station (U2B) link and the UAV-to-UAV (U2U) link. According to the principles of deep Q learning networks(DQN), treated as an agent the U2U link could interact with the UAV swarm communication system to select appropriate routing nodes for data transmission and channel attention(CA) is introduced to further improve system performance. The simulation data shows that the network based on reinforcement learning can obtain higher data transmission capacity with fewer routing hops.","Unmanned Aerial Vehicles ,  Unmanned Aerial Vehicle Swarm ,  Routing Resources ,  Swarm Communication ,  Data Transmission ,  Q-learning ,  Channel Attention ,  Improve System Performance ,  Deep Q-learning ,  Air Data ,  Sigmoid Function ,  Current Position ,  Shortest Path ,  Global Positioning System ,  Base Station ,  Time Slot ,  Inertial Measurement Unit ,  Successful Transmission ,  Current Speed ,  Flight Path ,  Packet Forwarding ,  Unmanned Aerial Vehicle Flies ,  Network Width ,  Unmanned Aerial Vehicle System ,  ReLU Function ,  Ground Base Stations ,  Channel Attention Module ,  Ad Hoc Networks ,  Successful Transmission Probability ,  Routing Path "
AUV-Assisted Node Repair for IoUT Relying on Multiagent Reinforcement Learning,https://ieeexplore.ieee.org/document/10193767/,2,Journal Article,IEEE,2024,"In recent years, the Internet of Underwater Things (IoUT) has garnered significant attention owing to its potential in ocean exploration and monitoring. However, environmental erosion and limited energy can cause node failures, leading to routing voids, communication congestion, and even IoUT breakdowns. Addressing these challenges, this work considers a node repair scheme for multiple autonomous underwater vehicles (AUVs) to search and repair faulty nodes to ensure the stable operation of the IoUT networks. Moreover, AUVs should adapt automatically to the unknown environment, working in cooperative or separative modes to balance repair efficiency and coverage. We propose a multiagent reinforcement learning-based AUV-assisted node repair (RANR) scheme, which considers limited underwater communication and scheduling between AUVs. To further enhance work efficiency, we introduce area information entropy to reduce redundant coverage among AUVs. Simulation results demonstrate that the RANR scheme is highly applicable to different working conditions.","Multi-agent Reinforcement Learning ,  Node Repair ,  Information Entropy ,  Work Efficiency ,  Autonomous Underwater Vehicles ,  Node Failure ,  Underwater Communication ,  Optimization Problem ,  Objective Function ,  Value Function ,  State Space ,  Angular Velocity ,  Coverage Rate ,  Time Task ,  Path Planning ,  Actor Network ,  Time Stamp ,  Reward Function ,  Markov Decision Process ,  Safe Distance ,  Critic Network ,  Formulated Optimization Problem ,  Repair Rate ,  Undersea ,  Proximal Policy Optimization ,  Crown-of-thorns Starfish ,  Policy Improvement ,  Optimal Objective Function ,  Emergency Rescue ,  Environmental Noise "
Indoor AR Navigation and Emergency Evacuation System Based on Machine Learning and IoT Technologies,https://ieeexplore.ieee.org/document/9776502/,20,Journal Article,IEEE,2022,"In order to evacuate people safely and quickly in indoor disaster environments, it is necessary to estimate the current location of the individuals, detect disaster situations, predict disaster propagation, derive optimal individual escape paths, and implement a user-friendly and intuitive guidance system. In this study, we propose a machine-learning-based indoor augmented reality (AR) navigation and emergency evacuation system that can guide an optimal escape path for individual users. To detect emergency events and deliver sensing data, an Internet of Things (IoT)-enabled ad hoc network is considered. To deliver the sensing data safely and reliably to the server, we present a hybrid reinforcement-learning-based routing algorithm that combines direct and indirect 
 $Q$ 
-learning methods. Prediction of disaster propagation at multiple time scales is important to prevent dangerous situations. We propose a simple disaster area prediction method that ensembles elementary component gradient boosting machine models. User location is estimated by a deep neural network using the received signal strength from beacon nodes. To derive the optimum evacuation path for each individual, we propose a novel model-based 
 $Q$ 
-learning method, in which we consider the building structural model and disaster context information. The performance of the proposed system is experimentally evaluated for various disaster scenarios.","Machine Learning ,  Internet Of Things ,  E-learning ,  Navigation System ,  Machine Learning Technology ,  Internet Of Things Technology ,  Emergency Evacuation ,  Augmented Reality Navigation ,  Augmented Reality Navigation System ,  Time Scale ,  Deep Neural Network ,  Sensor Data ,  Current Position ,  Individual Users ,  Building Structures ,  Gradient Boosting ,  Optimal Path ,  User Location ,  Environmental Disasters ,  Component Elements ,  Edge Devices ,  Received Signal Strength Indicator ,  Pathfinding ,  Routing Path ,  Shortest Path ,  Learning Algorithms ,  Escape Route ,  Bluetooth Low Energy ,  Smartphone Users ,  Dijkstra’s Algorithm "
Lightweight P2P-RPL for Efficient P2P Communication in 6TiSCH Networks,https://ieeexplore.ieee.org/document/9829565/,0,Conference Paper,IEEE,2022,"With the emergence of various IoT applications, P2P functional support in the network is essential. RPL is a routing protocol for low-power loss wireless networks, but there is an inefficient aspect of P2P communication. Although P2P-RPL has been proposed to support P2P of RPL, it is inappropriate to apply it to 6TiSCH networks as it is due to excessive overhead. So, we propose Lightweight P2P-RPL and applied to 6TiSCH Networks. Lightweight P2P-RPL includes five techniques for reducing overhead, and the performance was measured using a 6TiSCH simulator. As a result of the simulation, there was no performance reduction despite providing P2P function.","P2P Communication ,  6TiSCH Network ,  Wireless Networks ,  Energy Consumption ,  Network Performance ,  Network Size ,  Root Node ,  Time Slot ,  Pair Of Nodes ,  Direct Transmission ,  Child Nodes ,  Early Decisions ,  Target Node ,  Received Signal Strength Indicator ,  Routing Path ,  Network Energy Consumption "
Differentially Private Malicious Agent Avoidance in Multiagent Advising Learning,https://ieeexplore.ieee.org/document/8685696/,31,Journal Article,IEEE,2020,"Agent advising is one of the key approaches to improve agent learning performance by enabling agents to ask for advice between each other. Existing agent advising approaches have two limitations. The first limitation is that all the agents in a system are assumed to be friendly and cooperative. However, in the real world, malicious agents may exist and provide false advice to hinder the learning performance of other agents. The second limitation is that the analysis of communication overhead in these approaches is either overlooked or simplified. However, in communication-constrained environments, communication overhead has to be carefully considered. To overcome the two limitations, this paper proposes a novel differentially private agent advising approach. Our approach employs the Laplace mechanism to add noise on the rewards used by student agents to select teacher agents. By using the differential privacy technique, the proposed approach can reduce the impact of malicious agents without identifying them. Also, by adopting the privacy budget concept, the proposed approach can naturally control communication overhead. The experimental results demonstrate the effectiveness of the proposed approach.","Malicious Agents ,  Learning Performance ,  Agent System ,  Communication Overhead ,  Impact Of Agents ,  Differential Privacy ,  Time Step ,  Dynamic Environment ,  Base Station ,  Development Assistance ,  Sensor Networks ,  Number Of Agents ,  Multi-agent Systems ,  Defection ,  Markov Decision Process ,  Environmental Agents ,  Scale-free Networks ,  Static Environment ,  Network Of Agents ,  Greedy Approach ,  Regularization Approach ,  Neighboring Agents ,  Multi-agent Reinforcement Learning ,  Multicast ,  Reward Of Agent ,  Average Reward ,  Average Return ,  Problem Scenario ,  Learning Algorithms ,  Multi-armed Bandit "
Neural-Network-Assisted Packet Accelerators for Internet of Things Network Systems,https://ieeexplore.ieee.org/document/10094235/,1,Journal Article,IEEE,2023,"Major device nodes within the Internet of Things (IoT) system collects and store information in bit forms of 0’s and 1’s regardless of its repetition. The nodes do not possess the capability of processing redundant data information except for outright rejection/replacement of packets of similar sizes. This becomes a research problem since high volumes of packet redundancy are prevalent owing to repetitive information. Many optimal solutions have been provided to reprocess redundant packets and to store them in edge server for accessibility by other connected IoT systems and networks servers. To do so, major IoT platforms implements tier-based network layers which primarily aid seamless communication among nodes. These network layers perform near-similar tasks of guaranteeing packet sensing and exchange although at often-higher energy requirement. To mitigate the energy concerns, packets are clustered and compressed, allowing exchange of essential information only. But the approach continues to present heavy packet-losses and/or redundancies. In this article, two-tier layered network—where packet exchange is conducted at the top layer in order to lower energy consumption and promote system-reliability is investigated. All packets are first segregated into multiple clusters using the Voronoi cell-based correlation cluster formation (VC3F) technique. Cluster heads (CHs) are identified by their multipath (M-Score) value, thus, assuming sole responsibility of redundant packet removal within each cluster. The redundant packets are then moved to the edge-tier layer using optimized multiobjective flower pollination (MO-FPO) routing, and finally processed using hybrid models of novel fast-fully connected neural network (F2CNN) accelerator and Lempel–Ziv–Welch (LZW) data compression. The F2CNN and LZW models are harmonized to further collectively explore potential benefits of both models. These benefits include the neural capability to work on the sensitivity level of the pac...","Internet Of Things ,  Internet Of Things Networks ,  Energy Consumption ,  Source Code ,  System Reliability ,  Cluster Formation ,  Redundant Data ,  System Throughput ,  Internet Of Things Systems ,  Edge Server ,  Redundancy Removal ,  Internet Of Things Platform ,  Packet Delivery Ratio ,  Energy Efficiency ,  Local Search ,  Data Transmission ,  Sensitive Data ,  Pathfinding ,  Internet Of Things Devices ,  Internet Of Things Nodes ,  Edge Computing ,  Global Search ,  Data Packets ,  Edge Nodes ,  Internet Of Things Technology ,  Route Selection ,  Specific Connections ,  Levy Flight ,  Deep Reinforcement Learning "
A Reinforcement Learning-Based Trust Model for Cluster Size Adjustment Scheme in Distributed Cognitive Radio Networks,https://ieeexplore.ieee.org/document/8533448/,22,Journal Article,IEEE,2019,"Cognitive radio enables secondary users (SUs) to explore and exploit the underutilized licensed channels (or white spaces) owned by the primary users. To improve the network scalability, the SUs are organized into clusters. This article proposes a novel artificial intelligence-based trust model approach that uses reinforcement learning (RL) to improve traditional budget-based cluster size adjustment schemes. The RL-based trust model enables the clusterhead to observe and learn about the behaviors of its SU member nodes, and revoke the membership of malicious SUs in order to ameliorate the effects of intelligent and collaborative attacks, while adjusting the cluster size dynamically according to the availability of white spaces. The malicious SUs launch attacks on clusterheads causing the cluster size to become inappropriately sized while learning to remain undetected. In any attack and defense scenario, both the attackers and the clusterhead adopt RL approaches. Simulation results have shown that the single-agent RL (SARL) attackers have caused the cluster size to reduce significantly; while the SARL clusterhead has slightly helped increase its cluster size, and this motivates a rule-based approach to efficiently counterattack. Multi-agent RL attacks have shown to be less effective in an operating environment that is dynamic.","Cluster Size ,  Cognitive Networks ,  Cognitive Radio ,  Trust Model ,  Scalable ,  Outdoor Environments ,  Availability Of Space ,  Effects Of Attacks ,  White Space ,  Rule-based Approach ,  Attack Scenarios ,  Multi-agent Reinforcement Learning ,  Secondary Users ,  Time Slot ,  Neighboring Nodes ,  Types Of Attacks ,  Cluster Nodes ,  Data Packets ,  OFF State ,  Network Of Agents ,  Attack Intensity ,  Random Attack ,  Malicious Nodes ,  Probability Of Attack ,  Downstream Nodes ,  Neighboring Agents ,  Trust Value ,  Nodes In Order ,  Transmission Range ,  Non-cooperative Game "
Destination-Oriented Data Collection and Uploading for Mobile Crowdsensing With Multiagent Deep Reinforcement Learning,https://ieeexplore.ieee.org/document/10266845/,0,Journal Article,IEEE,2024,"Data collection and uploading are among the most fundamental problems in an mobile crowdsensing (MCS) system and involve complicated interactions among the system’s platform, mobile users, data collection tasks, and data relaying devices. In the article, we propose a destination-oriented data collection and uploading (DDCU) problem in MCS to facilitate cooperation among various entities. In DDCU, mobile device users are recruited as workers to complete data collection tasks and aim to reach their destinations after collecting the required data. At the same time, edge servers are recruited as data relaying devices to share their idle network resources and gain extra profit. The DDCU problem aims to help an MCS platform plan efficient sensing paths for workers to maximize the platform’s total profit. We further prove the DDCU problem to be NP-hard and thus require a time-efficient approximation-based method to solve the problem. In Xu and Song (2022), we proposed communication-QMIX-based multiagent deep reinforcement learning (CQDRL) as a decentralized method for an MCS routing problem. Although CQDRL was proven effective with high performance, it explicitly targets graph-based problems with two types of nodes and requires considerable effort to be extended to more heterogeneous graph problems. In this article, we propose CQDRL-S by simplifying the graph processing part of CQDRL to solve the DDCU problem with three types of nodes. More importantly, CQDRL-S can potentially be extended to other heterogeneous graph problems with moderate modifications. Extensive experiments further justify the effectiveness, efficiency, and simplicity of CQDRL-S in dealing with the DDCU problem.","Deep Reinforcement Learning ,  Data Upload ,  Multi-agent Deep Reinforcement Learning ,  Mobile Crowdsensing ,  Task Completion ,  Network Resources ,  Mobile Users ,  Types Of Nodes ,  Total Profit ,  Routing Problem ,  Edge Server ,  Problem Of Heterogeneity ,  Graph Processing ,  Heterogeneous Graph ,  Graph Problems ,  Usage Of Mobile Devices ,  Computational Resources ,  Number Of Workers ,  Storage Capacity ,  Nodes In The Graph ,  Network Of Agents ,  Heuristic Method ,  Problem Instances ,  Mixed Network ,  Local Observations ,  Different Types Of Nodes ,  Profit Ratio ,  Vector Of Node ,  Knapsack Problem ,  Amount Of Tasks "
FL_GIoT: Federated Learning Enabled Edge-Based Green Internet of Things System: A Comprehensive Survey,https://ieeexplore.ieee.org/document/10323400/,2,Journal Article,IEEE,2023,"In today’s world, the importance of the Green Internet of Things (GIoT) in the transformed sustainable smart cities cannot be overstated. For a variety of applications, the GIoT may make use of advanced machine learning (ML) methodologies. However, owing to high processing costs and privacy issues, centralized ML-based models are not a feasible option for the large data kept at a single cloud server and created by multiple devices. In such circumstances, edge-based computing may be used to increase the privacy of GIoT networks by bringing them closer to users and decentralizing them without requiring a central authority. Nonetheless, enormous amounts of data are stored in a distribution mechanism, and managing them for application purposes remains a difficulty. Hence, federated learning (FL) is one of the most promising solutions for bringing learning to end devices through edge computing without sharing private data with a central server. Therefore, the paper proposes a federated learning-enabled edge-based GIoT system, which seeks to improve the communication strategy while lowering liability in terms of energy management and data security for data transmission. The proposed model uses FL to produce feature values for data routing, which could aid in sensor training for identifying the best routes to edge servers. Furthermore, combining FL-enabled edge-based techniques simplifies security solutions while also allowing for a more efficient computing system. The experimental results show an improved performance against existing models in terms of network overhead, route interruption, energy consumption, and end-to-end delay, route interruption.","Internet Of Things ,  Federated Learning ,  Internet Of Things Systems ,  Green Internet Of Things ,  Energy Consumption ,  Cloud Computing ,  Data Transmission ,  Privacy Issues ,  Smart City ,  Edge Computing ,  Central Server ,  Sustainable Cities ,  Edge Server ,  End Devices ,  Network Overhead ,  Deep Learning ,  Data Storage ,  Global Model ,  Internet Of Things Devices ,  Federated Learning Model ,  Edge Devices ,  Edge Nodes ,  Industrial Internet Of Things ,  Internet Of Things Data ,  Virtual Network Functions ,  Mobile Edge Computing ,  Cloud Providers ,  Deep Reinforcement Learning ,  Heterogeneous Devices "
Obstacle Avoidance in Unmanned Aerial Vehicles Using Image Segmentation and Deep Learning,https://ieeexplore.ieee.org/document/9932865/,0,Conference Paper,IEEE,2022,"Machine learning is a branch of artificial intelligence based on the idea that systems can learn to identify patterns and make decisions with a minimum of human intervention. In this study, demonstration learning will be used, using neural networks in a prototype of a drone built to perform trajectories in controlled environments. To accelerate the training convergence process, a new training data selection approach has been introduced, which picks data from the experience pool based on priority instead of randomness. An autonomous maneuver strategy for dual-UAV olive formation air warfare is provided, which makes use of UAV capabilities such as obstacle avoidance, formation, and confrontation to maximize the effectiveness of the attack.","Image Segmentation ,  Unmanned Aerial Vehicles ,  Obstacle Avoidance ,  Neural Network ,  Machine Learning ,  Use Of Data ,  Imitation ,  Artificial Neural Network ,  Hidden Layer ,  Excellent Example ,  Trajectory Planning ,  Vertical Error ,  Horizontal Error ,  Inverse Reinforcement Learning ,  Imitation Process ,  Human Pilot ,  Unmanned Aerial Vehicle Model "
BTS: A Blockchain-Based Trust System to Deter Malicious Data Reporting in Intelligent Internet of Things,https://ieeexplore.ieee.org/document/9444338/,17,Journal Article,IEEE,2022,"Recent developments in collection, computation and communication have expanded the way of data reporting in intelligent Internet of Things (IoT). However, diversity and complexity of data sources also impose new trust challenge in data collection process since untrust reporters tend to report false or even malicious data, which highlights the need to develop a novel methodology to solve such challenge. Thus, based on this domain, inspired by deterrence theory, this article proposes a blockchain-based trust system with assistant of drones to deter malicious data reporting in intelligent IoT. Specifically, to deter malicious data reporting, based on the blockchain technology, the data sensed by fully trusted drones is public published on blockchain showing participants the data standards, named as malicious deterrence scheme. This scheme provides a barrier for malicious reporters to arbitrarily publish false data to blockchain, since the false data can be easily detected while they cannot deny. Second, to further reduce malicious data reporting, a strict penalty mechanism is proposed to punish malicious reporters who have reported false data to blockchain to reduce the malicious data reporting in the following task through punishment. Third, note that the sensing of data standard generates additional costs, therefore, a drone flight route scheme based on a simper deep reinforcement learning with multihead attention mechanism (MA-DRL) is designed to reduce the flight distance for drones. Finally, extensive experiments demonstrate efficiency of our proposed system in terms of reducing malicious data reporting in advance as well as reducing drone flight distance.","Malicious Data ,  Punishment ,  Time-of-flight Mass Spectrometry ,  Attention Mechanism ,  Deep Reinforcement Learning ,  False Data ,  Routing Scheme ,  Deterrence Theory ,  Multi-head Attention Mechanism ,  Normal Range ,  Small Region ,  Sensor Data ,  Recurrent Neural Network ,  Regional Data ,  Smart City ,  Markov Decision Process ,  Randomization List ,  Task Duration ,  End Of The Task ,  Baseline Schemes ,  Mobile Edge Computing ,  Fake Data ,  Dynamic Elements ,  Crowdsourcing ,  Number Of Efforts ,  Service Platform ,  Eristalis ,  Flight Plan "
Trajectory Synthesis for a UAV Swarm Based on Resilient Data Collection Objectives,https://ieeexplore.ieee.org/document/9928375/,12,Journal Article,IEEE,2023,"The use of Unmanned Aerial Vehicles (UAVs) for collecting data from remotely located sensor systems is emerging. The data can be time-sensitive and require to be transmitted to a data processing center. However, planning the trajectory for a swarm of UAVs depends on multi-fold constraints, such as data collection requirements, UAV maneuvering capacities, and budget limitations. Since a UAV may fail or be compromised, it is important to provide necessary resilience to such contingencies, thus ensuring data security. It is important to provide the UAVs with efficient spatio-temporal trajectories so that they can efficiently cover necessary data sources. In this work, we present Synth4UAV, a formal approach for automated synthesis of efficient trajectories for a UAV swarm by logically modeling the aerial space and data point topology, UAV moves, and associated constraints in terms of the turning and climbing angle, fuel usage, data collection point coverage, data freshness, and resiliency properties. We use efficient, logical formulas to encode and solve the complex model. The solution to the model provides the routing and maneuvering plan for each UAV, including the time to visit the points on the paths and corresponding fuel usage such that the necessary data points are visited while satisfying the resiliency requirements. We evaluate the proposed trajectory synthesizer, and the results show that the relationship among different parameters follows the requirements while the tool scales well with the problem size.","Unmanned Aerial Vehicles ,  Unmanned Aerial Vehicle Swarm ,  Limited Budget ,  Problem Size ,  Model Formulation ,  Percentage Points ,  Points In Space ,  3D Space ,  Base Station ,  Point Source ,  Path Planning ,  Deep Reinforcement Learning ,  Wireless Sensor Networks ,  Synthesis Time ,  Trajectory Planning ,  Mobile Edge Computing ,  Fuel Consumption ,  Constraint Satisfaction Problem ,  Destination Point ,  Trajectory Generation ,  Unmanned Aerial Vehicle Trajectory ,  Trajectory Design ,  CPU Usage ,  Increase In Execution Time ,  Markov Decision Process ,  Ant Colony Optimization ,  Boolean Variable ,  Increase In Time ,  Research Problem ,  Number Of Data Points "
Time-Constrained Task Allocation and Worker Routing in Mobile Crowd-Sensing Using a Decomposition Technique and Deep Q-Learning,https://ieeexplore.ieee.org/document/9474442/,8,Journal Article,IEEE,2021,"Mobile crowd-sensing (MCS) is a data collection paradigm, which recruits mobile users with smart devices to perform sensing tasks on a city-wide scale. In MCS, a key challenge is task allocation, especially when MCS applications are time-sensitive, and the platform needs to consider task completion order (since a worker may perform multiple tasks and different task completion orders lead to different travel costs and response times, i.e., the times needed to arrive at the task venues), requirements of tasks (such as deadline and required sensor) and workers heterogeneity. In other words, the task allocation problem consists of multiple task completion order problems, which is challenging to solve due to the large solution space. Therefore, in this paper, we first formulate the considered problem into two related integer linear programming problems (i.e., assignment and task completion order problems) using a decomposition technique in order to reduce the problem size and enable the use of diverse searching strategies. Then, a deep Q-learning (DQN)-based algorithm, namely assignment DQN with a local search (A-DQN w/ LS), is proposed to determine the task-worker assignments, which iteratively employs an asymmetric traveling salesman (ATSP) heuristic to find the task completion orders of the workers. The local optimizer is applied at the end of the A-DQN algorithm to deal with the computation time and local optima. Simulation results show that the proposed method outperforms existing approaches under different sensing dynamics in terms of total cost.","Decomposition Technique ,  Task Allocation ,  Deep Q-learning ,  Mobile Crowdsensing ,  Total Cost ,  Local Search ,  Local Optimum ,  Solution Space ,  Linear Problem ,  Multiple Tasks ,  Travel Costs ,  Problem Size ,  Mobile Users ,  Smart Devices ,  Work Assignments ,  Integer Linear Programming Problem ,  Neural Network ,  Number Of Workers ,  Type Of Work ,  Unmanned Aerial Vehicles ,  Assignment Problem ,  Fitting Solution ,  Tabu Search ,  Local Search Algorithm ,  Different Types Of Work ,  Hamiltonian Path ,  Local Workers ,  CPU Time ,  Lowest Cost ,  Localization Task "
