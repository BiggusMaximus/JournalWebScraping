title,link,number_of_citation,article_type,publisher,publication_date,abstract,keyword
A Data-Driven Reinforcement Learning Based Multi-Objective Route Recommendation System,https://ieeexplore.ieee.org/document/9356093/,8,Conference Paper,IEEE,2020,"Driving route recommendation systems have been becoming popular due to high demands on such systems and their high socio-economic impacts. Existing route recommendation systems cannot provide a well-balanced route by considering the user preference on multiple criteria or make route recommendation in a short time. This paper presents a multi-objective route recommendation system considering three different attributes (i.e., fuel consumption, travel time, and air quality). The proposed route recommendation system uses the Q-learning based reinforcement learning algorithm to leverage the available datasets to make route recommendations in a timely manner. First, we build a road network graph using a publicly available map service (i.e., OpenStreetMap) and other real-world datasets on traffic, weather, and air substances. Second, we utilize the existing predictors for air quality, travel time, and fuel consumption estimations to update the road network graph periodically. Third, we design the route recommendation system using the Q-learning reinforcement learning approach considering the given user's preference for travel time, fuel consumption, and air quality. To evaluate the proposed approach's performance, we conduct experimental evaluations based on the real-world datasets with publicly available map service.","Recommender Systems ,  Route Recommendation ,  Multi-objective Routing ,  Air Quality ,  Travel Time ,  Road Network ,  Real-world Datasets ,  Multiple Criteria ,  User Preferences ,  Web Map ,  Fuel Consumption ,  Air Pollution ,  Systemic Administration ,  Shortest Path ,  Light Signal ,  Multi-objective Optimization ,  Optimum Solution ,  Pathfinding ,  Edge Length ,  Multi-objective Optimization Problem ,  Road Segments ,  Q-learning Algorithm ,  Edge Attributes ,  Preference Weights ,  Source Node ,  Destination Node ,  Routing Problem ,  Directional Distance ,  Speed Profile ,  Total Computation Time "
Q-Learning Based Multi-Objective Clustering Algorithm for Cognitive Radio Ad Hoc Networks,https://ieeexplore.ieee.org/document/8932525/,13,Journal Article,IEEE,2019,"Cognitive radio (CR) is an adaptive radio technology that can automatically detect available channels in a wireless spectrum and change transmission parameters to improve radio operating behavior. Due to the dynamic nature of spectrum availability and wireless channel condition, it is very hard to maintain reliable network connectivity. Cluster-based CR ad-hoc networks (CRAHN) arrange CR nodes into groups to effectively maintain reliable autonomous networks. Clustering in CRAHN supports cooperative tasks such as spectrum sensing and channel managements and achieves network scalability and stability. In this paper, we proposed a Q-learning based cluster formation approach in CRAHN, in which Q-value is used to evaluate each node's channel quality. To form a distributed cluster network, channel quality, residual energy and neighbor node/network conditions are considered. By exchanging each node's status information in terms of channels and neighbors, each node knows neighboring topology and which node is the best candidate for cluster head (CH). Distributed CH selection, the optimum common active data channel decision, and gateway node selection procedures are presented in this paper. The proposed mechanism can extend the network lifetime, enhance the reachability not only between member nodes but also with other cluster networks, it can also provide stable and reliable service using the selected data channel and avoid possible interference between neighboring ad-hoc clusters.","Clustering Algorithm ,  Cognitive Networks ,  Ad Hoc Networks ,  Cognitive Radio ,  Multi-objective Clustering ,  Channel Activity ,  Cluster Formation ,  Common Data ,  Residual Energy ,  Channel Quality ,  Common Channel ,  Cluster Head ,  Network Lifetime ,  Average Energy ,  Single Channel ,  Quality Metrics ,  Neighboring Nodes ,  K-means Algorithm ,  Primary Signal ,  Request Message ,  Neighbor Clustering ,  Channel Clustering ,  Secondary Users ,  Cluster Nodes ,  Secondary Nodes ,  Routing Algorithm ,  Medium Access Control ,  Idle Time ,  Potential Rewards "
Field Trial of Privacy-preserving Resource Allocation in Multi-domain Optical Networks Based on Federated Reinforcement Learning,https://ieeexplore.ieee.org/document/10369176/,0,Conference Paper,IEEE,2023,"We propose and demonstrate federated reinforcement learning enabled multi-domain optical networks resource allocation in China's national network across over 2420 km, saving 30% decision time and obtaining even better optimal configuration without sensitive information disclosure.","Resource Allocation ,  Field Trials ,  Optical Networks ,  Federated Reinforcement Learning ,  Information Disclosure ,  National Network ,  Decision Time ,  Service Providers ,  Network Topology ,  Data Privacy ,  Global Status ,  Global Optimization ,  Network Size ,  Network State ,  Privacy Protection ,  Location Decisions ,  Communication Cost ,  Public Network ,  Edge Nodes ,  Service Requests ,  Block Ratio ,  Network In China ,  Routing Path ,  Nationwide Network ,  Raw Information ,  Destination Node "
A Q-Learning-Based Approach for Enhancing Energy Efficiency of Bluetooth Low Energy,https://ieeexplore.ieee.org/document/9328753/,4,Journal Article,IEEE,2021,"Bluetooth low energy (BLE) is a promising candidate technology for use in the Internet of Things (IoT) because of its ultra-low-power communication. Although BLE devices are designed to run on a small battery for a few years, several attempts have been made to extend BLE lifetime through various techniques. In particular, emerging approaches such as artificial intelligence (AI) can be utilized to further improve the BLE energy efficiency. For this purpose, this article proposes a Q-learning-based scheduling algorithm for BLE. The proposed scheduling algorithm dynamically adjusts the key parameters that govern the operation of the BLE transmission scheme. These key parameters, namely, the length of connection interval and the number of packets to transmit during the interval, have a profound effect on energy efficiency and the quality of service (QoS) specified in terms of maximum latency. According to the framework of reinforcement learning, our Q-learning-based scheduling algorithm is appropriately constructed to simultaneously provide a longer network lifetime and satisfy the QoS requirement. The numerical results show that the proposed Q-learning-based approach significantly increases the network lifetime compared to alternative methods while meeting QoS requirements.","Energy Efficiency ,  Service Quality ,  Internet Of Things ,  Interval Length ,  Longer Lifetime ,  Scheduling Algorithm ,  Quality Of Service Requirements ,  Maximum Latency ,  Network Lifetime ,  Model System ,  Optimization Algorithm ,  Wireless Networks ,  Duty Cycle ,  Reward Function ,  Data Packets ,  Unit Energy ,  Reinforcement Learning Algorithm ,  Sleep Period ,  Arrival Rate ,  Transmission Parameters ,  Transmission Ratio ,  Packet Arrival ,  Battery Level ,  Packet Loss ,  Network Devices ,  Greedy Policy ,  Routing Algorithm ,  State-action Pair ,  Average Reward "
SOMACA: A New Swarm Optimization-Based and Mobility-Aware Clustering Approach for the Internet of Vehicles,https://ieeexplore.ieee.org/document/10122916/,9,Journal Article,IEEE,2023,"The Internet of Vehicles (IoV) has evolved from the classic Vehicular Ad-hoc NETworks (VANETs) as a result of the emergence of the Internet of Things (IoT). IoV is used for communication among vehicles in real-time with their drivers, other vehicles, pedestrians, fleet management systems, and roadside infrastructure. High vehicular speeds and frequent network topology changes make vehicle communication extremely difficult on the IoV network. More constraints are imposed on IoV communication performance in a huge network environment due to the difficult road conditions and the enormous quantity of vehicles. A promising approach to improve the IoV communication performance is through vehicle clustering. Minimizing the number of clusters and identifying a reliable Cluster head (CH) are some of the most challenging tasks. In this paper, we propose a Swarm optimization-based and mobility-aware clustering method termed SOMACA. SOMACA consists of two phases clustering phase and the routing phase. During the clustering phase, we combine mobility measures and cluster distance to generate the minimum number of clusters having stable CHs and employ the Sparrow Search algorithm (SSA) for CH selection. The routing phase consists of two steps (1) Route Formation and (2) Route Upkeep. The main target for route formation step is to build a secure routing path between IoV nodes and base station (BS) by establishing an optimal list of links that are ordered from high to low, and in each round, it selects the best one. Moreover, the Upkeep step aims to update and maintain the existing connection. The performance of SOMACA is assessed using simulation experiments with various metrics including average cluster lifetime, transmission range, and network grid size. The simulation results show that SOMACA reduces the average number of clusters by 
 $42\%, 48\%, 47\%, 9\%$ 
, 22%,31%, 16%, and 43% less than CAVDO, GOA, GWOCNET, MFCA-IOV, MOGA-AWCP, HHOCNET, AMONE, and p-WOA algorithms respec...","Internet Of Vehicles ,  High Speed ,  Clustering Method ,  Internet Of Things ,  Network Topology ,  Grid Size ,  Network Clustering ,  Average Lifetime ,  Topological Changes ,  Transmission Range ,  Vehicle Communication ,  Clustering Phase ,  Vehicular Ad Hoc Networks ,  Cluster Head ,  Changes In Network Topology ,  Objective Function ,  Optimization Algorithm ,  Random Number ,  Clustering Algorithm ,  Cloud Computing ,  Routing Algorithm ,  Roadside Units ,  Efficient Clustering ,  Optimal Clustering ,  Intelligent Transportation Systems ,  Trust Value ,  Deep Reinforcement Learning ,  On-board Unit ,  Malicious Nodes ,  Deep Reinforcement Learning Agent "
Energy-Efficient and QoS-Aware Data Transfer in Q-Learning-Based Small-World LPWANs,https://ieeexplore.ieee.org/document/10214496/,1,Journal Article,IEEE,2023,"The widespread use of the Internet of Things (IoT) necessitates large-scale communication among smart IoT devices (IoDs) across a wide geographical area. However, due to the limited radio range and scalability issues of traditional wireless sensor networks, wide-area communication among IoDs is not feasible. As a solution, a low-power wide-area network (LPWAN) is emerging as one of the techniques that can provide long-range communication with minimal power consumption. Nevertheless, the direct data transmission approach will no longer be viable due to its short network lifetime. As such, multihop data routing strategies for LPWANs are proposed in the literature. However, multihop data transmission has several challenges, including increased data latency, energy imbalance, poor bandwidth utilization, and low data throughput. To address these challenges, we propose a novel method that uses the machine learning technique for an energy-efficient and Quality-of-Service (QoS)-aware data transfer based on a recent breakthrough in social networks known as small-world characteristics (SWC). The network having SWC (i.e., low average path length and high average clustering coefficient) uses long-range links to reduce the number of intermediate hops for data transmission. In particular, a 
 $Q$ 
-learning framework is utilized for introducing optimal long-range links between the selected IoDs, resulting in the development of a small-world LPWAN (SW-LPWAN). Furthermore, the performance of the proposed method is computed in terms of energy efficiency and QoS. Moreover, the results are compared with existing data routing techniques, such as low-energy adaptive clustering hierarchy (LEACH), modified LEACH, conventional multihop, and direct data transmission. Specifically, the proposed method maintains 29% more alive nodes, 18% higher residual energy, and 22% higher data throughput compared to the second-best-performing method. As such, the obtained experimental results validate tha...","Data Transfer ,  Low Power Wide Area Networks ,  Energy Consumption ,  Performance Of Method ,  Energy Efficiency ,  Internet Of Things ,  Data Transmission ,  Wide Area ,  Direct Transmission ,  Internet Of Things Devices ,  Wireless Sensor Networks ,  Average Path Length ,  Residual Energy ,  Wide Geographical Area ,  Data Throughput ,  Wide Area Network ,  Network Lifetime ,  Bandwidth Utilization ,  Small-world Characteristics ,  Measurement Model ,  Data Packets ,  Average Latency ,  Total Delay ,  Reinforcement Learning Techniques ,  Conventional Network ,  Small World ,  Small-world Network ,  Energy Requirements ,  Transmission Delay ,  Processing Delay "
Curious SDN for network attack mitigation,https://ieeexplore.ieee.org/document/9742225/,1,Conference Paper,IEEE,2021,"The increasing number of connected IoT devices in recent years has led to a significant growth in the volume of cyber attack instances. Since the IoT devices include home automation sensors, medical equipment, vehicular sensors, nuclear reactors and life-critical real-time sensing devices, lack of security in IoT can pose a risk to human lives. In this study, we focus on the problem of attack detection and mitigation with the help of recently emerging reinforcement machine learning which has already demonstrated excellent suitability for several cyber security applications. In particular, we are implementing an intelligent agent which manipulates network security policies depending on the current state of the environment. These manipulations include pushing software-defined networking flows to the network controller as well as adjusting detection sensitivity of security appliances used for intrusion and anomaly detection. To encourage the environment exploration, the agent is provided with an intrinsic curiosity reward signal based on how hard it is for the agent to predict the consequences of its own actions. We evaluate the resulting framework against several attack scenarios using realistic network traffic datasets and the simulation results confirmed the viability of the approach proposed.","Attack Mitigation ,  Machine Learning ,  Simulation Results ,  Nuclear Reactors ,  Intelligence Agencies ,  Anomaly Detection ,  Internet Of Things Devices ,  Volume Growth ,  Suitability For Applications ,  Attack Detection ,  Lack Of Security ,  Reward Signal ,  Intrinsic Rewards ,  Attack Scenarios ,  Objective Function ,  Functional Networks ,  Machine Learning Models ,  Recurrent Neural Network ,  Traffic Flow ,  Reward Function ,  Virtual Network Functions ,  Proximal Policy Optimization ,  Reinforcement Learning Agent ,  Flow Routing ,  Reinforcement Learning Approach ,  Deep Reinforcement Learning ,  Parallel Environment ,  Actual Probability ,  Self-organizing Map ,  Reinforcement Learning Algorithm "
Adaptive Forwarding Delay Control for VANET Data Aggregation,https://ieeexplore.ieee.org/document/5740863/,38,Journal Article,IEEE,2012,"In-network data aggregation is a useful technique to reduce redundant data and to improve communication efficiency. Traditional data aggregation schemes for wireless sensor networks usually rely on a fixed routing structure to ensure data can be aggregated at certain sensor nodes. However, they cannot be applied in highly mobile vehicular environments. In this paper, we propose an adaptive forwarding delay control scheme, namely Catch-Up, which dynamically changes the forwarding speed of nearby reports so that they have a better chance to meet each other and be aggregated together. The Catch-Up scheme is designed based on a distributed learning algorithm. Each vehicle learns from local observations and chooses a delay based on learning results. The simulation results demonstrate that our scheme can efficiently reduce the number of redundant reports and achieve a good trade-off between delay and communication overhead.","Aggregate Data ,  Adaptive Control ,  Vehicular Ad Hoc Networks ,  Learning Algorithms ,  Number Of Reports ,  Sensor Networks ,  Communication Overhead ,  Adaptive Control Scheme ,  Aggregation Scheme ,  Distributed Learning ,  Learning Process ,  Local Knowledge ,  Traffic Congestion ,  Function Approximation ,  Propagation Distance ,  Markov Decision Process ,  Reinforcement Learning Algorithm ,  Road Segments ,  Fuzzy Rules ,  Optimal Action ,  Vehicle Density ,  Markov Decision Process Model ,  Q-function ,  Traffic Information ,  Total Delay ,  Aggregation Operators ,  Ad Hoc Networks ,  State Transition Model ,  Dedicated Short Range Communication ,  Straight Road "
SARSA-Based CoAP Mode and Route Selection Joint Optimization in Power Underground Pipe Gallery,https://ieeexplore.ieee.org/document/9617767/,0,Conference Paper,IEEE,2021,"With the rigid quality of service (QoS) requirements of electricity services, wired communication networks in the urban power underground pipe gallery is facing many challenges. Traditional communication protocol and route selection can no longer supply the differentiated QoS demand of electricity services. This paper proposes a state-action-reward-state-action (SARSA)-based constrained application protocol (CoAP) mode and route selection joint optimization algorithm. The optimization objective is to jointly minimize the transmission delay and packet loss under the electromagnetic interference. Then, the proposed algorithm has been compared with shortest route selection (SRS)-based confirmed and non-confirmed mode algorithms through simulations. The simulation results demonstrate that the proposed algorithm can satisfy differentiated QoS requirements for urban power underground pipe gallery data transmission.","Selective Modulators ,  Joint Optimization ,  Route Selection ,  Constrained Application Protocol ,  Pipe Gallery ,  Service Quality ,  Data Transmission ,  Electromagnetic Interference ,  Communication Protocol ,  Transmission Delay ,  Service Requirements ,  Packet Loss ,  Quality Of Service Requirements ,  Electricity Services ,  Transmission Mode ,  Transmission Routes ,  Feasible Solution ,  Time Slot ,  Optimal Selection ,  Optimal Decision ,  Markov Decision Process Model ,  Data Packets ,  Wireless Sensor Nodes ,  Optimal Probability ,  Markov Decision Process ,  Wireless Sensor Networks ,  Real-time Transmission ,  Deep Reinforcement Learning ,  Wireless Sensor ,  Sum Of Weights "
Maximum End-to-End Latency Minimization in UAV-Assisted IoT Networks,https://ieeexplore.ieee.org/document/10008634/,0,Conference Paper,IEEE,2022,"With the advancement in wireless communications and smart device technologies, the Internet of Things (IoT) will make future services and applications more automatic and intelligent. However, the transmission rate and range of IoT devices are restricted by the limited battery power, which makes it challenging to provide satisfying services for delay-sensitive applications. Thanks to the high flexibility of unmanned aerial vehicles (UAVs), we propose a UAV-assisted IoT network model, where the UAV acts as the relay to help IoT nodes transmit their packets to the access point to prevent the network from overloading. With the aim of minimizing the maximum endto-end latency, a joint UAV trajectory design and IoT device scheduling problem is formulated. As the problem cannot be formulated with explicit expressions, it is intractable to solve the problem with traditional model-driven optimization algorithms. Therefore, we adopt deep reinforcement learning to solve this problem, and propose a soft actor-critic (SAC) based algorithm for its high sampling efficiency. Numerical results demonstrate that the maximum network end-to-end latency is substantially reduced with the assistance of the UAV. Moreover, the proposed SAC algorithm is shown to possess higher sampling efficiency than the deep Q-network","Internet Of Things ,  Internet Of Things Networks ,  Latency Minimization ,  Transmission Rate ,  Unmanned Aerial Vehicles ,  Sampling Efficiency ,  Explicit Expression ,  Internet Of Things Devices ,  Deep Reinforcement Learning ,  Deep Q-network ,  Unmanned Aerial Vehicle Trajectory ,  Internet Of Things Nodes ,  Trajectory Design ,  Benchmark ,  Neural Network ,  Loss Of Generality ,  Time Slot ,  Channel Model ,  Path Loss ,  Training Step ,  Internet Of Things Sensors ,  Ground Nodes ,  Temperature Coefficient ,  Reward Function ,  Power Nodes ,  Policy Network ,  Routing Scheme ,  Circularly Symmetric Complex Gaussian ,  Channel Gain ,  Policy Improvement "
Dynamic Multihop Routing in Terahertz Flow-Guided Nanosensor Networks: A Reinforcement Learning Approach,https://ieeexplore.ieee.org/document/10021306/,4,Journal Article,IEEE,2023,"The Internet of Nano-Things (IoNT) is an emerging paradigm in which devices sized to the nanoscale (nanonodes) and transmitting in the terahertz (THz) band can become decisive actors in future medical applications. Flow-guided nanonetworks are well-known THz networks aimed at deploying the IoNT inside the human body, among other issues. In these networks, nanonodes flowing through the bloodstream monitor-sensitive biological/physical parameters and dispatch these data via electromagnetic (EM) waves to a nanorouter implanted in human tissue, which operates as a gateway to external Internet connectivity devices. Under these premises, two shortcomings arise. First, the use of the THz band greatly limits the nanonode’s communication range. Second, the nanonodes lack resources for processing, memory, and batteries. To minimize the impact of these concerns in EM nanocommunications, a novel dynamic multihop routing scheme is proposed to model in-body, flow-guided nanonetwork architecture. To this end, a reinforcement learning-based framework is conceived, combining the features of EM nanocommunications and hemodynamics or fluid dynamics applied to the bloodstream. A generic Markov decision process (MDP) approach is derived to maximize the throughput metric, analytically modeling: 1) the movement of the nanonodes in the bloodstream as laminar flow; 2) energy consumption (including energy-harvesting issues); and 3) prioritized events. A thoroughly THz flow-guided nanonetwork case of study is also defined. Under the umbrella of this case, diverse testbeds are planned to create a procedure of evaluation, validation, and discussion. Results reveal that multihop scenarios obtain better performance than direct nanonode-nanorouter communication, specifically, the two-hop scenario, which, for instance, quadrupled the throughput in a hand vein without sharply penalizing other aspects such as energy consumption.","Dynamic Routing ,  Multi-hop Routing ,  Human Tissue ,  Bloodstream ,  Energy Consumption ,  Medical Applications ,  Laminar Flow ,  Energy Harvesting ,  Dynamic Strategy ,  Markov Decision Process ,  External Devices ,  Communication Range ,  Routing Scheme ,  Nanonetwork ,  Model Analysis ,  Cardiovascular System ,  Molecular Machinery ,  Optimal Policy ,  Vein Diameter ,  Markov Decision Process Model ,  Successful Transmission ,  Dynamic Path ,  Parabolic Profile ,  Effects Of Different Types ,  Coverage Range ,  Ad Hoc Networks ,  Battery Level "
Artificial Intelligence-Based Intrusion Detection and Prevention in Edge-Assisted SDWSN With Modified Honeycomb Structure,https://ieeexplore.ieee.org/document/10375497/,0,Journal Article,IEEE,2024,"The software-defined wireless sensor network (SDWSN) has the potential to improve flexibility, scalability, and network performance, but security and quality of service (QoS) are major challenges due to attackers, poor network management, and inefficient route selection. Several existing works for intrusion detection had drawbacks like poor security, inefficient network management, higher energy consumption and latency, and lesser throughput. A modified honeycomb structure-based intrusion detection system for SDWSN is proposed to address these challenges, which includes secure authentication using the 3D cube algorithm, modified honeycomb-based network partitioning, clustering, reinforcement learning-based intelligent routing with a transfer learning-based deep Q network (TLDQN), and a hybrid intrusion detection system. The latter detects malicious nodes using a driver training-based optimization (DTO) algorithm and intrusions with a bidirectional generative adversarial network (Bi-GAN). The results show that the proposed system outperforms existing solutions in terms of security, network performance, and efficiency. The simulation of this research is conducted by NS-3.26 Network Simulator, and the performances are evaluated based on various performance metrics (with respect to the total number of nodes) like energy consumption, latency, throughput, packet delivery ratio, network lifetime, computation overhead, detection accuracy, packet drop ratio, and control overhead, which proved that the proposed work achieves superior performance compared to existing works. The evaluation also includes a total simulation period during which the system’s real-time performance was conducted. Time-based metrics such as precision, recall, and F1-score, as well as confusion matrices, are utilized to analyze the system’s effectiveness in real-time in response to dynamic network threats.","Honeycomb Structure ,  Intrusion Detection ,  Energy Consumption ,  Scalable ,  Optimization Algorithm ,  Service Quality ,  Detection Accuracy ,  Performance Metrics ,  Confusion Matrix ,  Network Performance ,  High Energy Consumption ,  Computational Overhead ,  Wireless Sensor Networks ,  Network Management ,  Route Selection ,  Intrusion Detection System ,  Network Partitioning ,  Packet Delivery ,  Network Lifetime ,  Malicious Nodes ,  Physical Unclonable Functions ,  Pathfinding ,  Discriminator Network ,  Secret Key ,  Encoder Network ,  Internet Of Things ,  Real Samples ,  Sink Node ,  High Latency ,  Packet Loss "
Vehicular Communication Systems in Internet of Vehicles based on Machine Learning with Enhanced Security,https://ieeexplore.ieee.org/document/9835772/,0,Conference Paper,IEEE,2022,"The increase in number of vehicles results in complication and overcrowding, and introduction to electrical vehicles, rises the need to intelligent driver less decision-making systems that use vehicular technology to increase protection and transport performance. The advancement of enhanced movement of advanced networks will increase assistance through highly dynamic heterogeneous networks for linked vehicles and 5G implementation brings with it a slew of new challenges. The cutting-edge technologies that allow operators to take use of newly available organization facilities. Machine Learning (ML), which is strong paradigm developing dynamic and forecasting systems, arisen in various fields such as academia, industry and so on. By studying driving behaviour and the surrounding environment using data from sensors, ML utilized to reduce accidents. Machine learning techniques defined with change in time slot which is essential for in-vehicle channel modelling. Vehicle-to-vehicle and traditional wireless networks, the machine learning address highly dynamic vehicular network concerns as conventional control design in loop and data-centric methods by using data-centric methods strategies for optimization. In vehicular networks, machine learning applications focus on multi-agent cooperative methodologies and cumulative difficulty decrease achieved employing supporting tools like mobile edge computing for practical everyday demands.","Machine Learning ,  Internet Of Vehicles ,  Vehicular Communication Systems ,  Machine Learning Techniques ,  Wireless Networks ,  Time Slot ,  Edge Computing ,  Decision-making System ,  Mobile Edge Computing ,  Vehicular Networks ,  Deep Learning ,  Resource Allocation ,  Support Vector Machine ,  Artificial Intelligence ,  Service Quality ,  Resource Management ,  Large Amount Of Data ,  Internet Of Things ,  Long Short-term Memory ,  Intelligent Systems ,  Roadside Units ,  Vehicle Network ,  Deep Reinforcement Learning ,  Edge Caching ,  Computing Devices ,  Markov Decision Process ,  Unmanned Aerial Vehicles ,  Pseudo-random Binary Sequence ,  Intelligent Transportation Systems ,  Quality Of Experience "
Secure Data Transmission Based on Reinforcement Learning and Position Confusion for Internet of UAVs,https://ieeexplore.ieee.org/document/10443277/,0,Journal Article,IEEE,2024,"Ensuring the stability and security of unmanned aerial vehicle (UAV) communication, especially during long-distance missions, is essential for safeguarding against potential attacks. Large-scale UAV communication faces challenges, including eavesdropping threat, data tampering, replay threat, and man-in-the-middle threat. We propose a security information transmission solution based on reinforcement learning and location confusion algorithm (RLPC-SIT) to achieve a secure data transmission between UAVs. First, we leverage the principles of reinforcement learning to identify the most stable transmission routes. Second, we employ location confusion techniques to blur each location of the transmitting UAV with respect to other UAVs. Furthermore, we utilize the concept of message authentication to encrypt the transmitted data, thus making it inaccessible to malicious nodes and preventing forgery. The results of our theoretical analysis and simulation-based experiments indicate that our approach outperforms other security schemes.","Data Transmission ,  Unmanned Aerial Vehicles ,  Learning Algorithms ,  Information Transmission ,  Message Authentication ,  Stable Transmission ,  Malicious Nodes ,  Unmanned Aerial Vehicles Communication ,  Decoding ,  Data Privacy ,  Base Station ,  Delivery Rate ,  Privacy Protection ,  Neighboring Nodes ,  Pathfinding ,  Secret Key ,  Wireless Sensor Networks ,  Data Packets ,  Public Key ,  Destination Node ,  Nodal Coordinates ,  Unmanned Aerial Systems ,  Location Privacy ,  Blockchain Technology ,  Unmanned Aerial Vehicle Position ,  Dynamic Topology ,  Unmanned Aerial Vehicle System ,  Computation Offloading ,  Signature Scheme "
Connectivity Enhancement of E-VANET Based on QL-mRSU Self-Learning Energy-Saving Algorithm,https://ieeexplore.ieee.org/document/10012390/,1,Journal Article,IEEE,2023,"With the development of smart cities and smart electric vehicles (EVs), the problem of improving the performance of Vehicular Ad-hoc Networks (VANETs) is gradually being emphasized. To improve the network performance of VANETs, some scholars have considered parked vehicles as roadside units, but have not paid attention to the energy consumption characteristics of vehicles, especially electric vehicles. Therefore, in this paper, we propose a QL-mRSU series artificial intelligence energy saving method to optimize the energy consumption of parked electric vehicles during communication. The method is based on electric vehicle self-organizing networks (E-VANETs), which dynamically cluster electric vehicles parked in parking lots by parameters such as traffic flow, number of service demands, and charging index in reinforcement learning, select the most suitable vehicles as mobile roadside units (mRSUs), and adjust the working mode according to environmental changes such as the number of service demands to achieve the effects of self-learning and energy saving. The simulation experimental results show that compared with other energy-based routing algorithms, the method is able to make optimal choices through self-learning with guaranteed communication quality and is more adaptable to traffic flow changes on the road, thus ensuring the stability of energy-saving efficiency. In addition, the method significantly improves the energy structure of electric vehicle parking clusters.","Energy Conservation ,  Environmental Changes ,  Energy Consumption ,  Electric Vehicles ,  Network Performance ,  Demand For Services ,  Traffic Flow ,  Working Mode ,  Routing Algorithm ,  Vehicle Characteristics ,  Roadside Units ,  Number Of Demands ,  Vehicular Ad Hoc Networks ,  Consumption Of Vehicles ,  Smart City Development ,  External Environment ,  Energy Efficiency ,  Nighttime ,  Operation Mode ,  Duty Cycle ,  Q-learning Algorithm ,  Wireless Sensor Networks ,  Horizontal Coordinates ,  Time Slot ,  Peak Period ,  Continuous Operation ,  Dedicated Short Range Communication ,  Relay Nodes ,  Certain Times Of The Day ,  Packet Loss Rate "
Beyond Sensors: IntelliSignal’s Map-Integrated Intelligence in Traffic Flow Optimization,https://ieeexplore.ieee.org/document/10464272/,1,Journal Article,IEEE,2024,"The burgeoning growth of vehicular traffic, fuelled by rapid urbanization and an ever-expanding population, has resulted in congested road networks. Traditional and sensor-based adaptive traffic light management systems have shown commendable progress in some scenarios, but they suffer from inherent disadvantages that hinder their effectiveness and scalability. To combat these challenges, a dynamic and adaptable traffic control system is imperative to optimize traffic flow. The present paper explores the limitations of sensor-based adaptive traffic light management and advocates for integrating a novel algorithm to overcome the existing drawbacks. It proposes an intelligent traffic management algorithm called IntelliSignal that leverages the map service for fetching real-time traffic information to calculate the optimal green time and a penalty-based road selection to optimize traffic flow. The proposed IntelliSignal is designed to provide equal chances for all roads while prioritizing higher-density roads with more green time, effectively mitigating traffic congestion and improving overall transportation efficiency. It incorporates Q-learning, a reinforcement learning technique that enables the system to adapt and learn from traffic patterns. The proposed IntelliSignal’s performance is assessed through rigorous evaluations conducted on the simulation platform SUMO. The acquired results demonstrate substantial enhancements across various crucial metrics, including average waiting time, vehicle density, travel time, CO2 emissions, and queue length. Furthermore, the simulation results demonstrate that the proposed IntelliSignal algorithm exhibits a remarkable 30.52% increment in system throughput compared to the traditional approach. This significant enhancement underscores the efficacy of the proposed IntelliSignal in optimizing system performance and merits consideration for practical implementation.","Traffic Flow ,  Traffic Flow Optimization ,  Urbanization ,  Greenhouse Gas ,  Adaptive System ,  Travel Time ,  Adaptive Control ,  Road Network ,  Traffic Congestion ,  Waiting Time ,  Traffic Light ,  Intelligence Algorithms ,  Traffic Control ,  Traffic System ,  Traffic Management ,  Traffic Patterns ,  Network Congestion ,  Traffic Information ,  Queue Length ,  Reinforcement Learning Techniques ,  Penalty Value ,  Throughput Improvement ,  Real-time Data ,  Light Signal ,  Traffic Conditions ,  Traffic Data ,  Fuel Consumption ,  Vehicular Ad Hoc Networks ,  Optimal Signal ,  Routing Model "
Dynamic Optimisation of Heavy Road Traffic,https://ieeexplore.ieee.org/document/10060096/,0,Conference Paper,IEEE,2022,"In India, the road traffic problem is taking serious shape, roads here and there, vehicles everywhere! But not a little place for your vehicle to reach the destination. The key issue that most megapolises face is traffic congestion even after dealing with the many techniques to reduce it. Traffic congestion has become one of the major challenges for engineers, planners, and policymakers in urban areas. An increase in traffic congestion has an impact on the air quality of the urban area. In this project, we study traffic congestion in urban. The proposed work aims at comparing the efficiency of the routing algorithm used as a traffic network. A central traffic management system is used in which routes of all the vehicles are determined centrally and a simulation of real-world traffic light controls the vehicle movement based on traffic density. In a static time-dependent network, routing techniques are assessed based on the shortest path algorithm. The effect of the routing method is analyzed based on the overall amount of travel time. The efficiency of the algorithms is compared with the help of simulation of real-world traffic. A* tends to perform better in all parameters when subjected to large landscapes and the A3C algorithm is most suitable for traffic light control.","Efficient Algorithm ,  Travel Time ,  Shortest Path ,  Traffic Congestion ,  Traffic Light ,  Urban Network ,  Routing Algorithm ,  Help Of Simulations ,  Convolutional Neural Network ,  Average Speed ,  Light Signal ,  Sensor Networks ,  Waiting Time ,  Vertices ,  OpenStreetMap ,  Q-learning ,  Dijkstra’s Algorithm ,  Asterids ,  Deep Q-network ,  Reinforcement Learning Agent ,  Traffic Simulation ,  Dynamic Routing ,  Dynamic Assignment ,  Traffic Assignment "
MobiCharger: Optimal Scheduling for Cooperative EV-to-EV Dynamic Wireless Charging,https://ieeexplore.ieee.org/document/9864082/,0,Journal Article,IEEE,2023,"With the advancement of dynamic wireless charging for Electric Vehicles (EVs), Mobile Energy Disseminator (MED), which can charge an EV in motion, becomes available. However, existing wireless charging scheduling methods for wireless sensors, which are the most related works to MED deployment, are not directly applicable for city-scale EV-to-EV dynamic wireless charging. We present 
MobiCharger
: a 
Mobi
le wireless 
Charger
 guidance system that determines the number of serving MEDs, and their optimal routes. We studied a metropolitan-scale vehicle mobility dataset, and found: most vehicles have routines, and the number of driving EVs changes over time, which means MED deployment should adaptively change as well. We combine EVs’ current trajectories and routines to estimate EV density and the cruising graph for MED coverage. Then, we develop an offline MED deployment method that utilizes multi-objective optimization to determine the number of serving MEDs and the driving route of each MED, and an online method that utilizes Reinforcement Learning to adjust the MED deployment when the real-time vehicle traffic changes. Our trace-driven experiments show that compared with previous methods, 
MobiCharger
 increases the medium State-of-Charge of all EVs by 50% during all time slots, and the number of charges of EVs by almost 100%.","Wireless Charging ,  Dynamic Wireless Charging ,  Electric Vehicles ,  Multi-objective Optimization ,  Time Slot ,  Pathfinding ,  Online Methods ,  Number Of Charges ,  Current Trajectory ,  Guidance System ,  Scheduling Method ,  Energy Consumption ,  Optimization Problem ,  Density Estimation ,  Travel Time ,  Current Position ,  Road Network ,  Wireless Sensor Networks ,  Autoregressive Integrated Moving Average ,  Battery Capacity ,  Road Segments ,  Vehicle Density ,  Electric Vehicles Charging ,  Reinforcement Learning Model ,  Mobile Information ,  Vehicle Trajectory ,  Taxicab ,  Historical Trajectory ,  Routing Method ,  Long-term Information "
A novel efficient task-assign route planning method for AUV guidance in a dynamic cluttered environment,https://ieeexplore.ieee.org/document/7743858/,15,Conference Paper,IEEE,2016,"Increasing the level of autonomy facilitates a vehicle in performing long-range operations with minimum supervision. This paper shows that the ability of Autonomous Underwater Vehicles (AUVs) to fulfill mission objectives is directly influenced by route planning and task assignment system performance. This paper proposes an efficient task-assign route-planning model in a semi-dynamic network, where the location of some waypoints can change over time within a target area. Two popular meta-heuristic algorithms, biogeography-based optimization (BBO) and particle swarm optimization (PSO), are adapted to provide real-time optimal solutions for task sequence selection and mission time management. To examine the performance of the method in a context of mission productivity, mission time management and vehicle safety, a series of Monte Carlo simulation trials are undertaken. The results of simulations demonstrate that the proposed methods are reliable and robust, particularly in dealing with uncertainties and changes in the operations network topology. As a result, they can significantly enhance the level of vehicle's autonomy, enhancing its reactive nature through its capacity to provide fast feasible solutions.","Route Planning ,  Autonomous Underwater Vehicles ,  Monte Carlo Simulation ,  Network Topology ,  Time Management ,  Particle Swarm Optimization ,  Vehicle Safety ,  Terrain ,  Superior Performance ,  Performance Of Algorithm ,  Travel Time ,  Multi-objective Optimization ,  Nodes In The Graph ,  Path Planning ,  Wireless Sensor ,  Candidate Solutions ,  Routing Problem ,  Task Allocation ,  Vehicle Routing ,  Immigration Rates ,  Feasible Route ,  Knapsack Problem ,  Multi-agent Reinforcement Learning ,  Routing Cost ,  Emigration Rates ,  Adjacency Relationship ,  Destination Point ,  Fitting Solution ,  Superior Capability ,  Performance Metrics "
Trajectory Design in UAV-Aided Mobile Crowdsensing: A Deep Reinforcement Learning Approach,https://ieeexplore.ieee.org/document/9500579/,7,Conference Paper,IEEE,2021,"Mobile crowdsensing (MCS) is a method of data collection by recruiting mobile devices to accomplish various sensing tasks. The mobility and intelligence of mobile devices enable an efficient solution to large-scale sensing, e.g., smart city. Unmanned aerial vehicles (UAVs), as mobile devices, can be used in MCS to perform many sensing tasks (e.g., monitoring). In addition, UAVs provide new business opportunities (e.g., package delivery) with its rapid increasing number. We aim to leverage the package delivery activities of UAVs to solve the task allocation problem of MCS. In the package delivery activities, UAVs must deliver the assigned packages to their destinations. During the package delivery, UAVs travel around to perform sensing tasks with time windows. In this case, the task allocation problem of MCS is considered as a trajectory design problem of UAVs. To plan the trajectories of UAVs, we propose a deep reinforcement learning approach, specifically, double deep Q-network with prioritized experience replay (DDQN-PER). Finally, the results of our numerical simulations show that our proposed solution outperforms two baseline solutions in terms of profit and number of completed tasks.","Deep Learning Approaches ,  Deep Reinforcement Learning ,  Deep Reinforcement Learning Approach ,  Mobile Crowdsensing ,  Time Window ,  Mobile Devices ,  Unmanned Aerial Vehicles ,  Deep Q-network ,  Package Delivery ,  Double Deep Q-network ,  Baseline Solution ,  Energy Cost ,  Mobile Users ,  Markov Decision Process ,  Target Network ,  Battery Capacity ,  Policy Network ,  User Equipment ,  Vehicle Routing ,  Replay Memory ,  Small Profit "
Multiagent-based cooperative vehicle routing using node pressure and auctions,https://ieeexplore.ieee.org/document/8317671/,4,Conference Paper,IEEE,2017,"Traffic congestion is a menace in the society with serious economic implications. Pressure based routing systems are known to be effective in wireless sensor networks, however rarely applied to transportation systems due to the nature of interactions between vehicles. This paper aims to alleviate the traffic congestion by adapting the node pressure concept into the traffic management system. In particular, we propose a Multi-Agent System (MAS) with vehicle agents and infrastructure agents, which can collaborate to provide static and dynamic solutions for reducing the node pressure. Pertaining to the static solution, the infrastructure agents rely on a reinforcement learning method to calculate the optimal routes for vehicle agents. Pertaining to the dynamic solution, the infrastructure agents dynamically adjust and re-route vehicle agents based on a novel multi-unit combinatorial auctioning system proposed in this paper. Extensive experiments on realistic traffic simulation platform have proven our methods, especially the dynamic solution, to achieve significant improvement in the reduction of node pressure and travel-times for the vehicle agents in comparison to others.","Vehicle Routing ,  Traffic Congestion ,  Multi-agent Systems ,  Wireless Sensor Networks ,  Improvement In Reduction ,  Reinforcement Learning Methods ,  Traffic Management System ,  Travel Time ,  Dynamic Approach ,  Road Network ,  Optimal Policy ,  Types Of Agents ,  Free Flow ,  Speed Limit ,  Traffic Light ,  Traffic Conditions ,  Markov Decision Process ,  Mixed Integer Linear Programming ,  Road Segments ,  Major Nodes ,  Vehicle Network ,  Traffic Scenarios ,  Network Of Agents ,  Downstream Nodes ,  Road Intersections ,  Multiset ,  Capacity Of Nodes ,  Network Flow ,  Linear Problem ,  Transportation Network "
Distributed Data Collection in Age-Aware Vehicular Participatory Sensing Networks,https://ieeexplore.ieee.org/document/9316802/,16,Journal Article,IEEE,2021,"The advent of vehicle-to-everything communication facilitates the emergence of vehicular sensing networks, where vehicles equipped with advanced sensors continuously sample informative status updates of its surroundings and forward the sampled data to roadside infrastructure based on a certain routing strategy. The collected data is analyzed to obtain real-time situational awareness to impose certain behaviors on the vehicles. In such networked control systems, the timeliness of collected data is of critical importance to system performance, which can be quantified by the concept of Age of Information. Note that to obtain timely perception of its surroundings, each vehicle tends to sample status updates at the maximum frequency, which may congest the network due to limited communication resource. Moreover, the highly dynamic nature of vehicular network poses a great challenge in finding a reliable route for timely data forwarding. Therefore, the data collection scheme should be carefully designed to balance the timeliness of collected information and network stability. In this article, we study an age optimization problem by jointly considering the data sampling at source vehicles and the data forwarding process for multiple information flows across the network. We employ the Lyapunov optimization technique to develop a distributed age-aware data collection scheme consists of a threshold-based sampling strategy at source vehicles and a learning-based data forwarding strategy. Simulation results show that our proposed scheme outperforms existing strategies in collecting status updates in a timely manner.","Participatory Sensing ,  Information Flow ,  Age Of Information ,  Status Updates ,  Networked Control Systems ,  Vehicular Networks ,  Multiple Flow ,  Routing Scheme ,  Lyapunov Optimization ,  Control Strategy ,  Stability Of System ,  Decrease In Values ,  Age Of The Sample ,  Tuning Parameter ,  Network Topology ,  Time Slot ,  Lyapunov Function ,  Data Packets ,  Vehicle Position ,  Source Node ,  Set Of Vehicles ,  Vehicle Network ,  Multi-hop Networks ,  Adaptive Sampling ,  Queue Length ,  Network Congestion ,  Ad Hoc Networks ,  Packet Delivery ,  Relay Selection ,  Buffer Size "
AirScope: Mobile Robots-Assisted Cooperative Indoor Air Quality Sensing by Distributed Deep Reinforcement Learning,https://ieeexplore.ieee.org/document/9123492/,19,Journal Article,IEEE,2020,"Indoor air pollution has become a growing health risk, but it is challenging to provide low-cost air quality monitoring for the indoor environment. In this article, we present “AirScope,” a mobile sensing system that employs cooperative robots to monitor the indoor air quality. Since the wireless coverage can be incomplete in some indoor areas, AirScope allows the robots to defer uploading the data to the central server by utilizing their own data buffers. In order to guarantee the timeliness of the data in the server, AirScope aims to minimize the average data latency by properly planning the routes of the robots. Such a route planning strategy has to be implemented in a distributed way since the robots that are out of wireless coverage can only make plans on their own. In addition, the cooperation of the robots is also necessary because the aggregation of the robots in a small area increases the average data latency of the other unattended areas. To solve this distributed and cooperative routing planning problem, we propose a solution based on distributed deep Q-learning (DDQL). We evaluate the system performance by simulations and real-world experiments. The results show that AirScope is effective to reduce data latency, where the proposed DDQL is 8% better than the greedy algorithm and 24% better than the random strategy.","Air Quality ,  Indoor Air ,  Deep Reinforcement Learning ,  Indoor Air Quality ,  Distributed Deep Reinforcement Learning ,  Indoor Environments ,  Service Data ,  Route Planning ,  Indoor Air Pollution ,  Central Server ,  Wireless Coverage ,  Deep Neural Network ,  Global Status ,  Time Slot ,  Access Points ,  Reward Function ,  Mobile Robot ,  Distribution Strategy ,  Cooperative Strategy ,  Adjacent Positions ,  Belief State ,  Robot Movement ,  Position Of The Robot ,  Connectivity States ,  Heuristic Strategy ,  Behavior Policy ,  Partial Observation ,  State Transition Matrix ,  Monitoring Area ,  Incomplete Coverage "
A Resilient and Robust Edge-Cloud Network System Supporting CPS,https://ieeexplore.ieee.org/document/9637734/,0,Conference Paper,IEEE,2021,"Many outages of cloud computing services are caused by the natural disasters or common causes such as software failure, hardware failure, cyber attacks, and power outage. As a result, it is critical to develop resilient and robust cyber-physical system (CPS) to support continuity of service for smart and connected communities (S&CC). In spite of considerate research efforts on virtual machine (VM) migration for enhancing failure-resilience of datacenters, one issue still needs to be effectively addressed: how to determine the best destination for VM migration to avoid the influence from a given failure and enable edge nodes to connect to the VMs continuously. In this paper, we aim to handle these important issues to build a resilient and robust edge-cloud (or fog) network system supporting CPS for S&CC. We propose a machine learning based method for VM migration destination determination for the VMs in the predicted failure domains. We also propose a continuous edge-cloud connection method in wireless network component that enables edge nodes to continuously connect with the VMs through intermediate edge nodes when they cannot directly connect to their original VMs due to VM migration. Our experimental results show our proposed system reduces the number of job failures by 1.8 times and reduces the total job completion time by 48% for completed jobs compared to the case without our system.","Network System ,  Robust System ,  System Resilience ,  Edge Cloud Network ,  Machine Learning ,  Disaster ,  Wireless Networks ,  Virtual Machines ,  Power Outages ,  Cyber-physical Systems ,  Software Defect ,  Edge Nodes ,  Migration Destination ,  Hardware Failure ,  Continuous Connection ,  Total Completion Time ,  Job Completion Time ,  Support Vector Machine ,  Routing Path ,  Reinforcement Learning Model ,  Predictors Of Failure ,  Path Nodes ,  Probability Of Failure ,  Wireless Sensor Networks ,  Job Training ,  Occurrence Of Failure ,  Cloud Environment ,  Long Short-term Memory "
Explore the Use of the Network and Mobile Terminal in Solving the Psychological Problem,https://ieeexplore.ieee.org/document/7384054/,0,Conference Paper,IEEE,2015,"The application of the network and the intelligent terminal opens a new mode of medical treatment, in the diagnosis and treatment of mental disease, how to build a smart, efficient model is a major issue in front of scientific research. In this paper, the energy consumption of the mobile terminal is reduced based on the Q learning network and the wireless body area network routing method, improve the accuracy of data reception and the battery life. Dynamic data obtained by real-time data exchange, BP Adaboost strong classifier algorithm is used to accurately model the psychological problems of patients.","Psychological Problems ,  Use Of Networks ,  Mobile Terminals ,  Wireless Networks ,  Learning Network ,  Network Applications ,  AdaBoost ,  Q-learning ,  Strong Classifier ,  Treatment Of Mental Illness ,  Body Area Networks ,  Wireless Body Area Networks ,  Wearable Devices ,  Heart Rate Variability ,  Sample Matrix ,  Input Matrix ,  Outer Space ,  Secondary Vectors ,  Matrix Reinforcement ,  Cumulative Return "
