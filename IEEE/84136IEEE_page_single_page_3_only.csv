title,link,number_of_citation,article_type,publisher,publication_date,abstract,keyword
RPSO Optimization with machine learning in WSN,https://ieeexplore.ieee.org/document/9315774/,2,Conference Paper,IEEE,2020,"This work emphasizes to increase the network lifetime by using an appropriate data collection scheme and machine learning technique. The routing mechanism is one of the best approaches to decrease energy consumption and increase the lifetime of the network as well. We have used PSO with an updated scheme where we are selecting the random values to find best fitness value then the final route will be calculated. Genetic methods like mutation and crossover are implemented over the final routes to get alternate routes and then performance will be calculated. We have compared the lifetime and stability of network with existing protocols like Low Energy Adaptive Clustering Hierarchy (LEACH), Power-Efficient Gathering in Sensor Information Systems (PEGASIS), and Ant Colony Routing (ACR). In this work, we have added active-sleep feature with our network to enhance the network lifetime and the machine learning technique is used to predict the data of the network in sleep state. MATLAB is used to validate our mathematical framework; we have performed analytical simulations by choosing the network area, the number of nodes in each cluster. The lifetime and stability period is analyzed and compared with other optimization methods.","Machine Learning ,  Machine Learning Techniques ,  Genetic Methods ,  Stable Network ,  Ant Colony ,  Cluster Nodes ,  Network Lifetime ,  Routing Mechanism ,  Learning Algorithms ,  Supervised Learning ,  Power Consumption ,  Regression Method ,  Unsupervised Learning ,  Sensor Data ,  Wireless Networks ,  Life Time ,  Base Station ,  Particle Swarm Optimization ,  Sensor Networks ,  Node Status ,  Wireless Sensor Networks ,  Intelligence Methods ,  Artificial Intelligence Methods ,  Number Of Sensor Nodes ,  Artificial Intelligence Techniques ,  Network Time ,  Direct Transmission ,  Data Packets ,  Data Transmission ,  Neural Network "
Optimal Wireless Charging Inclusive of Intellectual Routing Based on SARSA Learning in Renewable Wireless Sensor Networks,https://ieeexplore.ieee.org/document/8721665/,55,Journal Article,IEEE,2019,"The next generation’s sensor nodes will be more intelligent, energy conservative, and perpetual lifetime in the set-up of wireless sensor networks (WSNs). These sensors nodes are facing the overwhelming challenge of energy consumption which gradually decreases the lifetime of overall network. The wireless power transfer (WPT) is one of the most emerging technologies of energy harvesting that deploys at the heart of sensor nodes for efficient lifetime solution. A wireless portable charging device (WPCD) is drifting inside the WSN to recharge all the nodes which are questing for the eternal life. In this paper, we aspire to optimize a multi-objective function for charging trail of WPCD, and self-learning algorithm for data routing jointly. We formulated that the objective functions can optimize the fair energy consumption as well as maximize the routing efficiency of WPCD. The fundamental challenge of the problem is, to integrate the novel path for WPCD by applying the Nodal A* algorithm. We proposed a novel method of sensor node’s training for intellectual data transmission by using of clustering and reinforcement learning (SARSA) defined as clustering SARSA (C-SARSA) along with an optimal solution of objective functions. The whole mechanism outperforms in terms of trade-off between energy consumption and stability (fair energy consumption among all nodes) of the WSN; moreover, it prolongs the lifetime of the WSN. The simulated results demonstrate that our proposed method did better than compared literature in terms of energy consumption, stability, and lifetime of the WSN.","Sensor Networks ,  Wireless Sensor Networks ,  Wireless Charging ,  SARSA Learning ,  Intelligence ,  Energy Consumption ,  Objective Function ,  Energy Conservation ,  Data Transmission ,  Energy Harvesting ,  Power Transfer ,  Wireless Power Transfer ,  Network Lifetime ,  Time Step ,  Network Performance ,  Base Station ,  Node Status ,  Reduce Energy Consumption ,  Optimal Path ,  Charge Discharge Cycles ,  Energy Of Nodes ,  Residual Energy ,  Node Distance ,  Node Deployment ,  Routing Scheme ,  Vacation Time ,  Reinforcement Learning Agent ,  Heuristic Value ,  Destination Node ,  Rate Of Nodes "
A Comprehensive Study on Routing Protocol for IoT-enabled WSNs using Deep Reinforcement Learning Strategy,https://ieeexplore.ieee.org/document/10058657/,1,Conference Paper,IEEE,2022,"Internet of Things enabled Wireless Sensor Networks (IoT-enabled WSNs) rely heavily on routing protocols because of the importance of various system performance parameters, such as end-to-end delay, system capacity, data delivery rate, and energy efficiency. As a result of this, sensor nodes may have a detrimental effect on the routing protocol's reliability and power tolerance when compared to other nodes in the network. As a result, the IoT-enabled WSNs' wide-field applications necessitate a self-driven energy intelligent routing protocol. Reinforcement Learning (RL) strategy has recently been used to support the development of an intelligent routing protocol that has a high potential for energy conservation while also increasing system performance above the typically achieved target. Deep Reinforcement Learning (DRL) routing protocols for IoT-enabled WSNs have been studied in this paper, and the current state-of-the-art algorithms have been compared. It is the purpose of this study to evaluate the operational characteristics and key features of the current DRL algorithms. In addition, the practical difficulties of routing protocol design and implementation were discussed.","Deep Reinforcement Learning ,  Reinforcement Learning Scheme ,  Deep Reinforcement Learning Strategy ,  Energy Efficiency ,  Energy Conservation ,  Internet Of Things ,  Capacity Of System ,  Wireless Sensor Networks ,  Learning Rate ,  Data Transmission ,  Traffic Congestion ,  Neighboring Nodes ,  Reward Function ,  Data Packets ,  Transmission Delay ,  Source Node ,  Node Information ,  Residual Energy ,  Quality Of Service Requirements ,  Loyalty Programs ,  Mobile Agents ,  Sink Node ,  Routing Table ,  Packet Delivery Ratio ,  Reward Of Agent ,  Network Lifetime ,  State-value Function ,  Policy Rule ,  Traffic Conditions ,  Node Failure "
Energy-Efficient Intelligent Routing Scheme for IoT-Enabled WSNs,https://ieeexplore.ieee.org/document/9324772/,70,Journal Article,IEEE,2021,"Recently, the Internet of Things (IoT) has attracted much interest in its wide applications, such as smart healthcare, home automation, transportation, and smart city. In these IoT-based systems, wireless sensor networks (WSNs) are highly used to gather information needed by smart environments. However, due to huge heterogeneous data coming from different sensing devices, IoT-enabled WSNs face different challenges, such as high communication delay, low throughput, and poor network lifetime. In this article, a deep-reinforcement-learning (DRL)-based intelligent routing scheme is proposed for IoT-enabled WSNs that significantly reduce delay and increase network lifetime. The proposed algorithm divides the whole network into different unequal clusters depending on the current data load present in the sensor node that significantly prevents immature death of the network. An extensive experiment on the proposed algorithm is performed using ns3. The experimental results are compared with the state-of-the-art algorithms to demonstrate the efficiency of the proposed scheme in terms of the number of alive nodes, packet delivery, energy efficiency, and communication delay in the network.","Wireless Sensor Networks ,  Routing Scheme ,  Intelligent Routing ,  IoT-enabled Wireless Sensor Networks ,  High Throughput ,  Internet Of Things ,  Smart City ,  Communication Delay ,  Number Of Deliveries ,  Network Delay ,  Home Automation ,  Packet Delivery ,  Network Lifetime ,  Energy Consumption ,  Simulation Results ,  Total Energy ,  Service Quality ,  Convolutional Layers ,  Cluster Formation ,  Multi-objective Optimization ,  State-action Value Function ,  Cluster Radius ,  Hop Count ,  Optimal Path ,  Residual Energy ,  Markov Decision Process ,  Load Balancing ,  Routing Algorithm ,  Cluster Nodes ,  Response Message "
A Modified Multi-Agent Reinforcement Learning Protocol Based on Prediction for UAANETs,https://ieeexplore.ieee.org/document/9348732/,2,Conference Paper,IEEE,2020,"In Unmanned Aeronautical Ad hoc Networks (UAANETs), it is challenging for routing protocols such as ad hoc on-demand distance vector (AODV) routing and improved protocols to provide reliable communications due to limited wireless resources and high mobility. This paper proposes a modified AODV protocol applying multi-agent Q-learning(Modified-QLAODV) based on mobility prediction and load sensing. This protocol is a distributed multi-agent reinforcement routing strategy, which employs reinforcement learning algorithm. It introduces mobility prediction and node relative load to infer link state on the purpose of enhancing robustness of UAANETs. In the learning strategy, mobility prediction based on Kalman filter algorithm combined with Gaussian filter algorithm, and load sensing will have impacts on Q-values. The destination obtains routes with different Q-values and returns the one with the maximum average Q-value to the source, which realizes to select the optimal route from a global view. The simulation results demonstrate that Modified-QLAODV can outperform the Q-learning routing protocol(QLAODV) and AODV on network performance in UAANETs.","Multi-agent Reinforcement Learning ,  Network Performance ,  Kalman Filter ,  Gaussian Filter ,  Global View ,  Pathfinding ,  Filtering Algorithm ,  Ad Hoc Networks ,  Kalman Filter Algorithm ,  Mobility Prediction ,  Learning Rate ,  Low Speed ,  Increase In Speed ,  Unmanned Aerial Vehicles ,  Sensor Networks ,  Model-based Methods ,  Multi-agent Systems ,  Reward Function ,  Markov Decision Process ,  Load Balancing ,  Model-free Methods ,  Update Strategy ,  Routing Table ,  Q-learning Algorithm ,  Node Update ,  Packet Loss ,  Dynamic Topology ,  Route Selection ,  Improve Network Performance ,  Neighboring Agents "
A Comprehensive Study Based on Routing Protocols and Data Transmission in M-WSN Environment,https://ieeexplore.ieee.org/document/10425050/,0,Conference Paper,IEEE,2023,"With the advancements in technology, various kinds of physical actions may now be digitally operated with the click of a button. This has given rise to the concept of IoT to strengthen the MANET-WSN (M-WSN) in a creative perspective. To find the appropriate path, several routing methods transmit control packets and transmitting unwanted network information consume the battery and raise the issue of packet overhead which reduces then network lifespan. Among various issues, high latency, energy consumption, packet drop, network lifetime and insecure data delivery were to name a few. Moreover, a highly reliable, and adaptive routing is lacking that could provide efficient data transmission in mobile node environment. Therefore, in this research, important protocols for routing supported by M-WSN and game theory methodology, with various route discovery algorithms and secure data transmission from source to destination are discussed. This systematic review considers the last 15 years' studies which were found from highly credible sources. This paper presents a comprehensive study of routing algorithms in mobile and static WSN architectures with an emphasis on using game theory as a decision-making tool. The paper begins with a summary of the modern facilities in routing algorithms and then delves into the many game theory-based strategies that have been put forth for this field. The paper concludes with a discussion of the advantages and challenges of using game theory in the context of routing algorithms, and provides recommendations for future research directions. The idea is expanded to include the performance metrics, security measures, and privacy considerations that surround the secure transmission of data packets between different nodes. The comprehensive analysis provides potential solutions proposed by different researchers that can help for future studies aimed at enhancing network information sharing. A number of routing designs were studied from an analytica...","Data Transmission ,  Energy Consumption ,  Performance Metrics ,  Data Security ,  Game Theory ,  Decision-making Tool ,  Security Measures ,  Routing Algorithm ,  Network Lifetime ,  Packet Drop ,  Secure Data Transmission ,  Network Topology ,  Sensor Networks ,  Mobile Network ,  Neighboring Nodes ,  Deep Reinforcement Learning ,  Nash Equilibrium ,  Efficient Route ,  Group Of Nodes ,  Ant Colony Optimization ,  Ad Hoc Networks ,  Static Phase ,  Swarm Intelligence ,  Routing Decisions ,  Packet Delivery Ratio ,  Non-cooperative Game ,  Coalition Formation ,  Network Congestion ,  Packet Delivery ,  Cooperative Game "
LRLRP: A Layer and Reinforcement Learning based Routing Protocol for Underwater Acoustic Networks,https://ieeexplore.ieee.org/document/10426339/,0,Conference Paper,IEEE,2023,"Aiming at the problems of underwater acoustic networks (UANs), such as low bandwidth, long propagation delay, high bit error rate, restricted energy, ""void area"" and the limitations of traditional routing protocols that focus solely on the current state of sensor nodes, lacking the flexibility for comprehensive network control, a Layer and Reinforcement Learning based Routing Protocol for underwater sensor networks(LRLRP) is proposed. The LRLRP protocol uses packet header information to learn or update the layer and the information of its neighbors. Subsequently, using information from the neighbor table regarding the layer, remaining energy, density, and Q-value of neighboring nodes, the reinforcement learning system is employed to determine the next-hop forwarding node. Extensive experiments were conducted by the NS3 network simulator to evaluate the performance of the LRLRP protocol. The simulation results demonstrate that the RLHRP routing protocol not only effectively mitigates the ""void area"" issue, but also exhibits commendable performance in terms of energy consumption, end-to-end delay, and packet delivery rate.","Underwater Acoustic Networks ,  Energy Consumption ,  Delivery Rate ,  Neighboring Nodes ,  Bit Error Rate ,  Bit Error ,  Most Significant Bit ,  Packet Delivery ,  Void Area ,  Packet Header ,  State Space ,  Behavioral Strategies ,  Intelligence Agencies ,  Iterative Scheme ,  Reward Function ,  Total Energy Consumption ,  Data Packets ,  Source Node ,  Residual Energy ,  Learning Agent ,  Sink Node ,  Energy Of Nodes ,  Current Node ,  Node Density ,  Receiver Node ,  Packet Forwarding ,  Routing Algorithm ,  Decision-making Strategies ,  Packet Transmission ,  Ground Base Stations "
RRP: A Reliable Reinforcement Learning Based Routing Protocol for Wireless Medical Sensor Networks,https://ieeexplore.ieee.org/document/10060225/,1,Conference Paper,IEEE,2023,"Wireless medical sensor networks (WMSNs) offer innovative healthcare applications that improve patients' quality of life, provide timely monitoring tools for physicians, and support national healthcare systems. However, despite these benefits, widespread adoption of WMSN advancements is still hampered by security concerns and limitations of routing protocols. Routing in WMSNs is a challenging task due to the fact that some WMSN requirements are overlooked by existing routing proposals. To overcome these challenges, this paper proposes a reliable multi-agent reinforcement learning based routing protocol (RRP). RRP is a lightweight attacks-resistant routing protocol designed to meet the unique requirements of WMSN. It uses a novel Q-learning model to reduce resource consumption combined with an effective trust management system to defend against various packet-dropping attacks. Experimental results prove the lightweightness of RRP and its robustness against blackhole, selective forwarding, sinkhole and complicated on-off attacks.","Sensor Networks ,  Resource Consumption ,  Sinkhole ,  Multi-agent Reinforcement Learning ,  Trust Management ,  Unit Time ,  Shortest Path ,  Network Operators ,  Wireless Sensor ,  Optimal Path ,  Wireless Sensor Networks ,  Adjacent Nodes ,  Learning Agent ,  Reinforcement Learning Model ,  Greedy Strategy ,  Trust Value ,  End Of Unit ,  Traffic Rate ,  Literature Protocol ,  Reliable Delivery ,  Number Of Sensor Nodes ,  Delivery Ratio ,  Malicious Nodes ,  Hop Count ,  Field Hospital ,  Reliable Protocol ,  Reward Function ,  Design Requirements ,  Network Topology ,  Misinformation "
Revolutionizing Data Transmission - A Comprehensive Review of Deep Learning-Based Routing Mechanism for 5G Wireless Sensor Networks,https://ieeexplore.ieee.org/document/10544339/,0,Conference Paper,IEEE,2024,"The convergence of 5G technology and Wireless Sensor Networks (WSNs) has lead in a transformative era in wireless communication, demanding intelligent and adaptive routing protocols. This review explores into the monarchy of deep learning-based routing protocols, dissecting their potential applications, challenges, and impact on the efficiency of 5G-enabled WSNs. Lack of understanding and variance, two crucial factors in the details of deep learning-based routing. The review scrutinizes the complexity of routing decisions and explores how deep learning algorithms introduce a layer of adaptability significant of human perception. As we examine the landscape of 5G WSNs, the benefits and challenges of incorporating deep learning into routing practices come to light. Adaptive decision-making, energy efficiency, resilience to dynamic environments, and enhanced data accuracy emerge as promising outcomes. However, the review also sheds light on the computational complexities and potential biases in training data that necessitate careful consideration. This review serves as a compass, navigating through the terrain of deep learning-based routing protocols for 5G WSNs. By sorting out the hints of incomprehension and variance within this context, we aim to provide a comprehensive understanding of the evolving landscape of intelligent routing. As 5G technology continues to redefine connectivity standards, this review contributes to the foundation of knowledge guiding the development and implementation of effective and adaptive routing protocols in the era of wireless sensor networks.","Data Transmission ,  Wireless Sensor ,  Wireless Sensor Networks ,  Routing Mechanism ,  Training Data ,  Deep Learning ,  Energy Efficiency ,  Wireless Networks ,  Data Bias ,  Communication Protocol ,  5G Technology ,  Routing Decisions ,  Neural Network ,  Convolutional Neural Network ,  Long Short-term Memory ,  Recurrent Neural Network ,  Network Performance ,  Deep Learning Approaches ,  Pathfinding ,  Smart City ,  Conventional Protocol ,  5G Networks ,  Long Short-term Memory Network ,  Graph Neural Networks ,  Federated Learning ,  Deep Learning-based Algorithms ,  Deep Reinforcement Learning ,  Wireless Communication Networks ,  Route Choice ,  Complex Patterns In Data "
A Balanced Routing Protocol Based on Machine Learning for Underwater Sensor Networks,https://ieeexplore.ieee.org/document/9605638/,12,Journal Article,IEEE,2021,"An underwater sensor network (UWSN) is a wireless network that is deployed in oceans, seas, and rivers for real-time exploration of environmental conditions. The network is used to measure temperature, pressure, water pollution, oxygen level, volcanic activity, floods, and water streams. Although radio frequency (RF) is widely utilized in wireless networks, it is incompatible with the UWSN environment; therefore, other communication mechanisms have been employed to manage the underwater wireless communication among sensors, such as acoustic channels, optical waves, or magnetic induction (MI). Unlike terrestrial wireless sensor networks, UWSNs are dynamic, and sensors move according to water activity. Therefore, the network topology changes rapidly. One of the most critical challenges in UWSNs is how to collect and route the sensed data from the distributed sensors to the sink node. Unfortunately, the direct application of efficient and well-established terrestrial routing protocols is not possible in UWSNs. In this work, a balanced routing protocol based on machine learning for underwater sensor networks (BRP-ML) is proposed that considers the UWSN environmental characteristics, such as power limitations and latency, while considering the void area issue. It is based on reinforcement learning (Q-learning), which aims to reduce the network latency and energy consumption of UWSNs. The communication technique in the proposed protocol is based on the MI technique, which has many advantages, such as steady and predictable channel response and low signal propagation delay. The simulation findings validated that BRP-ML reduced latency by 18% and increased energy efficiency by 16% compared to QELAR.","Machine Learning ,  Sensor Networks ,  Underwater Sensor ,  Underwater Sensor Networks ,  Energy Consumption ,  Energy Efficiency ,  Sensor Data ,  Wireless Networks ,  Acoustic Waves ,  Volcanic Activity ,  Wireless Sensor Networks ,  Sink Node ,  Void Area ,  Underwater Communication ,  Learning Algorithms ,  Delivery Rate ,  Clustering Process ,  Reward Function ,  Markov Decision Process ,  Data Packets ,  Cluster Head ,  Residual Energy ,  Edge Nodes ,  Autonomous Underwater Vehicles ,  Network Lifetime ,  Normal Nodes ,  Source Node ,  Edge Clustering ,  Delay Cost ,  All-to-all Communication "
Aggregator election in wireless sensor networks: A distributed reinforcement learning approach,https://ieeexplore.ieee.org/document/6675637/,0,Conference Paper,IEEE,2013,"Nowadays, artificial intelligence techniques are used in various fields of wireless sensor networks. Due to resource constraints in these types of networks, many studies focus on minimizing energy consumption and increasing the lifetime of the networks. Data aggregation is a powerful technique that it reduces the energy consumption in the network. In this paper, we've provided a distributed approach based on reinforcement learning and using learning automata for solving the problem of selection of aggregator in wireless sensor networks. We compared our method with DRLR and ECHSSDA algorithms. The results show that the proposed method significantly reduces energy consumption in DRLR and outperforms ECHSSDA, especially when the environment has low density.","Sensor Networks ,  Wireless Sensor Networks ,  Distributed Reinforcement Learning ,  Low Density ,  Energy Consumption ,  Aggregate Data ,  Wireless Networks ,  Reduce Energy Consumption ,  Minimum Energy Consumption ,  Energy Levels ,  Average Energy ,  Neighboring Nodes ,  Data Packets ,  Reinforcement Learning Algorithm ,  Independent Learning ,  Reinforcement Learning Methods ,  Learning Agent ,  Sink Node ,  Setup Phase ,  Popular Protocols "
Including artificial intelligence in a routing protocol using Software Defined Networks,https://ieeexplore.ieee.org/document/7962735/,82,Conference Paper,IEEE,2017,"Software defined network (SDN) is one of the most interesting research topic that is currently being investigated. The inclusion of artificial intelligence (AI) can improve the performance of routing protocols. Nowadays the application of AI over routing protocols is only applied to real devices, especially in wireless sensor nodes. In this paper, we present a new proposal to implement an intelligent routing protocol in a SDN topology. The intelligent routing protocol is based on the reinforcement learning process that allows choosing the best data transmission paths according to the best criteria and based on the network status.","Artificial Intelligence ,  Artificial Intelligence Applications ,  Reinforcement Learning Process ,  Wireless Sensor Nodes ,  Service Quality ,  Intelligence Algorithms ,  Packet Loss ,  Traditional Routes ,  Routing Algorithm ,  Routing Decisions ,  Packet Loss Rate ,  Routing Table ,  Packet Delivery Ratio "
Efficient Routing Protocol Based on Reinforcement Learning for Magnetic Induction Underwater Sensor Networks,https://ieeexplore.ieee.org/document/8737960/,33,Journal Article,IEEE,2019,"In recent research on 3D underwater wireless sensor network (UWSN), magnetic induction communication is a promising candidate, thanks to several unique features, such as small transmission delay, constant channel behavior, and adequate long communication range. However, designing a routing protocol that prolongs the network lifetime and reduces the transmission delay has been still a challenge for a 3D UWSN. In this paper, we propose an efficient routing protocol based on reinforcement learning, in particular, the Q-learning that aims to investigate the resource management in the hierarchical networks. Through defining the single hopping bonus metrics of distance and energy, we deduce the updating formula of the routing algorithm and derive the relationship between energy priority and distance priority. In addition, we set up a regulatory factor to adjust the proportion between energy saving and low delay, and thus, it can meet different needs. The simulation results show that the proposed routing approach outperforms the conventional protocol in extending the network lifetime and reducing the transmission delay.","Underwater Sensor ,  Underwater Sensor Networks ,  Wireless Sensor Networks ,  Transmission Delay ,  Communication Range ,  Routing Algorithm ,  Network Lifetime ,  Single Hop ,  Energy Consumption ,  Performance Metrics ,  Maximum Distance ,  Shortest Path ,  Base Station ,  Path Loss ,  Bit Error Rate ,  Nodes In Layer ,  Network Throughput ,  Propagation Delay ,  Undersea ,  Magnetic Coil ,  Autonomous Underwater Vehicles ,  Cluster Head ,  Energy Of Nodes ,  Nodal Coordinates ,  Data Chunks ,  Omnidirectional Antenna ,  Maximum Reward ,  Acoustic Communication ,  Communication Distance ,  Operating Frequency "
Deep Q-Network-Based Intelligent Routing Protocol for Underwater Acoustic Sensor Network,https://ieeexplore.ieee.org/document/10012647/,8,Journal Article,IEEE,2023,"This article proposes a deep Q-network (DQN)-based intelligent routing (DQIR) protocol for the underwater acoustic sensor networks (UASNs). The routing decision problem is modeled as a Markov decision process (MDP). The DQN is applied to solve the MDP, in which the agent is trained to select the forwarder with the highest reward as the next hop. The optimal policy for the agent is to choose a routing that balances the residual energy of different nodes while minimizing the routing distance, thereby improving the network lifetime and decreasing the average time delay. To evaluate its performance, we developed the proposed algorithm on an Aqua-Sim Next Generation (Aqua-Sim NG) platform and using the artificial intelligence (AI) framework. According to the simulation results, DQIR consumes less energy than both the depth-based routing (DBR) protocol and DQN-based energy and latency-aware routing (DQELR). Furthermore, compared with DBR and DQELR, DQIR increases the network lifetime and reduces the average time delay.","Underwater Acoustic ,  Intelligent Routing ,  Simulation Results ,  Optimal Policy ,  Markov Decision Process ,  Average Delay ,  Residual Energy ,  Deep Q-network ,  Network Lifetime ,  Energy Of Nodes ,  Routing Decisions ,  Average Delay Time ,  Neural Network ,  Energy Consumption ,  Time Slot ,  Fully-connected Layer ,  Reward Function ,  Deep Reinforcement Learning ,  Longer Lifetime ,  Data Packets ,  Sink Node ,  Source Node ,  Markov Decision Process Model ,  Undersea ,  Current Node ,  Route Selection ,  Greedy Strategy ,  State Transition Probability ,  Network Routing ,  Additional Metrics "
An Energy-Efficient Distributed Adaptive Cooperative Routing in Wireless Multimedia Sensor Networks,https://ieeexplore.ieee.org/document/8905401/,2,Conference Paper,IEEE,2019,"Since WMSN is rich in perceptual data, complex in processing tasks and powerful in network functions, it also puts forward higher requirements for QoS of WMSN. However, since WMSN is heterogeneous and the energy distribution is not uniform, many existing routing protocols do not take energy consumption into account while ensuring QoS. Therefore, how to make energy distributed more efficiently while ensuring QoS has become a challenge. This paper proposes an energy-efficient distributed adaptive cooperative routing to guarantee QoS and balance energy consumption in WMSN. By adaptively selecting some nodes for reinforcement learning to acquire their performance knowledge of reliability and delay, an optimal alternative path can be created to ensure both the QoS and balanced energy distribution. The simulation results show that the energy consumption is reduced by 20% while ensuring QoS compared with the traditional cooperative protocol and the distributed adaptive cooperative routing protocol.","Sensor Networks ,  Wireless Sensor ,  Wireless Sensor Networks ,  Cooperative Routing ,  Wireless Multimedia Sensor Networks ,  Energy Consumption ,  Energy Distribution ,  Version Of Protocol ,  Perception Data ,  Quality Of Service Requirements ,  Energy Efficiency ,  Additive Noise ,  Adaptive Algorithm ,  Traffic Flow ,  Reduce Energy Consumption ,  Types Of Nodes ,  Efficient Route ,  Optimal Action ,  Residual Energy ,  Traditional Routes ,  Energy Of Nodes ,  Relay Nodes ,  Capability Of Nodes ,  Network Lifetime ,  Routing Scheme ,  Reliable Route ,  Cooperative Communication ,  Routing Algorithm ,  Maximum Ratio Combining ,  Internet Of Vehicles "
Performance Analysis of Deep Learning-Based Routing Protocol for an Efficient Data Transmission in 5G WSN Communication,https://ieeexplore.ieee.org/document/9676565/,49,Journal Article,IEEE,2022,"For the past few years, huge interest and dramatic development have been shown for the Internet of Things (IoT) based constrained Wireless sensor network (WSN) to achieve efficient resource utilization and better service delivery. IoT requires a better communication network for data transmission between heterogeneous devices and an optimally deployed energy-efficient WSN. The clustering technique applied for WSN node deployment needs to be efficient; therefore, the entire architecture can obtain a better network lifetime. While clustering, the entire network is partitioned into various clusters. Moreover, the cluster head (CH) selection process also needs proper attention for achieving efficient data communication towards the sink node via selected CH and also for increasing the node reachability within the cluster. In this proposed framework, an energy efficient deep belief network (DBN) based routing protocol is developed, which achieves better data transmission through the selected path. Due to this the packet delivery ratio (PDR) gets improved. In this framework, initially, the nodes in the whole network is grouped as clusters using a reinforcement learning (RL) algorithm, which assigns a reward for the nodes that belong to the particular cluster. Then, the CH required for efficient data communication is selected using a Mantaray Foraging Optimization (MRFO) algorithm. The data is transmitted to the sink node via the selected CH using an efficient deep learning approach. At last, the performance of proposed deep network based routing protocol is evaluated using different evaluation metrics they are network lifetime, energy consumption, number of alive nodes, and packet delivery rate. Finally, the evaluated results are compared with few existing algorithms. Among all these algorithms, the proposed DBN routing protocol has achieved better network lifetime.","Data Transmission ,  Wireless Sensor Networks ,  Data Transmission Protocol ,  Energy Consumption ,  Deep Learning ,  Learning Algorithms ,  Deep Network ,  Optimization Algorithm ,  Energy Efficiency ,  Internet Of Things ,  Wireless Networks ,  Entire Network ,  Deep Learning Approaches ,  Sensor Networks ,  Network Efficiency ,  Reinforcement Learning Algorithm ,  Deep Belief Network ,  Sink Node ,  Cluster Head ,  Network Lifetime ,  Restricted Boltzmann Machine ,  Hidden Neurons ,  Hidden Layer ,  Multilayer Perception ,  Data Packets ,  Efficient Route ,  Deep Neural Network ,  Time Complexity ,  Space Complexity ,  Markov Decision Process "
Multi-Agent Reinforcement Learning-Based Routing Protocol for Underwater Wireless Sensor Networks With Value of Information,https://ieeexplore.ieee.org/document/10376403/,1,Journal Article,IEEE,2024,"Efficient data transmission plays a crucial role in the applications of underwater wireless sensor networks (UWSNs). In this article, by considering the differences in transmission requirements for data of varying importance degrees in UWSNs, a multi-agent reinforcement learning-based routing protocol with value of information (MARV) is proposed. First, to distinguish the difference of transmission requirements, we introduce the value of information (VoI) to characterize the importance degree of data to reflect the requirement for the real-time characteristic. Moreover, to ensure the efficient routing for different importance degree of data, we establish a multi-agent reinforcement learning (MARL)-based framework by enabling nodes to learn from the environment and interact with neighbors and elaborately design a reward function by considering the timeliness and energy efficiency of transmission. In addition, to improve the transmission efficiency, we design a packet holding mechanism by designing a priority list and variable holding interval according to transmission requirements. The simulation results show that the proposed protocol performs well for the transmission of different data.","Valuable Information ,  Wireless Sensor Networks ,  Underwater Wireless Sensor Networks ,  Energy Efficiency ,  Data Transmission ,  Transmission Efficiency ,  Reward Function ,  Efficient Route ,  Degree Of Importance ,  Multi-agent Reinforcement Learning ,  Energy Consumption ,  Functional Design ,  Neighboring Nodes ,  Markov Decision Process ,  Transmission Delay ,  Source Node ,  Q-learning ,  Communication Range ,  Node Information ,  Relay Nodes ,  Transmission Path ,  Packet Forwarding ,  Residual Energy ,  Routing Decisions ,  Node Depth ,  Network Lifetime ,  Undersea ,  Underwater Acoustic ,  Energy Of Nodes "
Distributed Routing Optimization Algorithm for FANET Based on Multiagent Reinforcement Learning,https://ieeexplore.ieee.org/document/10574195/,0,Journal Article,IEEE,2024,"Recent advancements in protocol design and optimization for flying ad hoc networks (FANETs) have shown significant progress. However, the existing centralized optimization control algorithms pose conflicts with the distributed nature of these systems. To address this challenge, this article proposes a novel distributed routing optimization algorithm based on multiagent reinforcement learning (MARL), integrated with an adaptive multimode routing framework incorporating multiprotocol cooperation mechanisms. The algorithm adopts the decentralized execution multiagent deep deterministic policy gradient (DE-MADDPG) algorithm framework, enabling individual unmanned aerial vehicles (UAVs) to directly adjust the protocols and protocol parameters of the current node based solely on local network information. This optimization enhances network structure and overall performance without considering the transmission delay of control signals. The ns3-gym simulation platform is employed for performance evaluation, comparing the proposed algorithm with deep Q-network (DQN), multiagent deep deterministic policy gradient (MADDPG), and other algorithms. The experimental results demonstrate that, compared to the routing algorithm optimized based on DQN, the proposed algorithm exhibits the best overall performance, with a 26.31% reduction in energy consumption and a 19.69% decrease in end-to-end delay.","Pathfinding ,  Multi-agent Reinforcement Learning ,  Distribution Routes ,  Routing Optimization Algorithm ,  Energy Consumption ,  Control Signal ,  Unmanned Aerial Vehicles ,  Reduce Energy Consumption ,  Transmission Delay ,  Simulation Platform ,  Policy Gradient ,  Routing Algorithm ,  Deep Q-network ,  Superior Performance ,  Performance Of Algorithm ,  Global Network ,  Network Performance ,  Multi-agent Systems ,  Reward Function ,  Network Environment ,  Critic Network ,  Data Packets ,  Destination Node ,  Complex Neural Network ,  Packet Delivery Ratio ,  Policy Network ,  Reinforcement Learning Algorithm ,  Onboard Computer ,  State Transition Probability ,  Routing Table "
On-demand Intelligent Routing Algorithms for the Deterministic Networks,https://ieeexplore.ieee.org/document/9781082/,1,Conference Paper,IEEE,2021,"The deterministic network is oriented to various services in the network, ensuring the deterministic requirements of different services in terms of delay, packet loss rate, cost overhead, throughput, security, and reliability. This paper proposes an on-demand routing learning model with a three-layer logical plane that can generate on-demand routing strategies with deterministic QoS (Quality of Services) requirements for different traffic flows. With the help of deep reinforcement learning algorithms, the OdR-TD3 and OdR-SAC algorithms are proposed to generate the suitable routing strategies to meet the deterministic QoS requirements of applications' traffic. The experimental evaluation results show the OdR-TD3 and OdR-SAC algorithm have significant advantages over the DV and SPF algorithms, considering the achievement rate of deterministic QoS requirements.","Routing Algorithm ,  Deterministic Network ,  Intelligent Routing ,  Deep Learning ,  Learning Algorithms ,  Service Quality ,  Application Requirements ,  Traffic Flow ,  Network Services ,  Deep Reinforcement Learning ,  Reinforcement Learning Algorithm ,  Packet Loss ,  Dijkstra’s Algorithm ,  Quality Of Service Requirements ,  Deep Reinforcement Learning Algorithm ,  Routing Scheme ,  Packet Loss Rate ,  Machine Learning ,  Mathematical Model ,  Complex Network ,  Critic Network ,  Industrial Internet ,  Reward Function ,  Routing Decisions ,  Network Applications ,  Network Routing ,  Actor Network ,  Delay Requirements ,  Traffic Demand ,  Source Node "
DQR: A Deep Reinforcement Learning-based QoS Routing Protocol in Cognitive Radio Mobile Ad Hoc Networks,https://ieeexplore.ieee.org/document/9369756/,7,Conference Paper,IEEE,2021,"In this paper, we propose a novel deep reinforcement learning-based quality-of-service routing (DQR) protocol to establish the best route with minimum end-to-end queuing delay subject to the number of hops constraint in cognitive mobile ad hoc networks (CRAHNs). In forwarding RREQ process, based on the proposed deep reinforcement learning (DRL) model, the DQR protocol unicasts a RREQ packet to its neighbor with minimum cost-value which avoids the affected region of the primary user to save control overheads, queuing delay and routing delay. The simulation results show that the DQR protocol outperforms the AODV one in terms of control overhead, PDR, and delay, suggesting a real-time protocol in CRAHNs.","Ad Hoc Networks ,  Deep Learning ,  Deep Learning Models ,  Deep Reinforcement Learning ,  Reinforcement Learning Model ,  Deep Reinforcement Learning Model ,  Deep Neural Network ,  Data Transmission ,  Global Positioning System ,  Game Theory ,  Node Size ,  Service Time ,  Reward Function ,  Markov Decision Process ,  Wireless Sensor Networks ,  Source Node ,  Processing Routes ,  Arrival Rate ,  Reinforcement Learning Techniques ,  Packet Delivery Ratio ,  Queue Size ,  Range Of Nodes ,  Neighboring Positions ,  Control Packets ,  Larger Network Size ,  Routing Table "
Energy balancing in multi-hop Wireless Sensor Networks: an approach based on reinforcement learning,https://ieeexplore.ieee.org/document/6880186/,16,Conference Paper,IEEE,2014,"Wireless Sensor Networks (WSNs) are made of spatially distributed autonomous sensors, which cooperate to monitor a certain physical or environmental condition and pass their data through a network to a central data sink. A promising field of application of WSNs is planet exploration, in which a continuous monitoring of the surface is necessary, to have a clear notion of planet conditions and prepare for a future manned mission. The potentially large size of the region to be monitored and the line-of-sight limitations on remote planets (for instance the Moon, as studied in the SWIPE project [1]), impose constraints on the possibility to have 1-hop sensor-sink communication. Therefore, the sensors must be able to create and maintain a multi-hop ad hoc network, to allow sensed data to reach the sink. This paper extends the Q-Routing algorithm, designed for fixed and mobile networks, in order to be applicable in WSNs. The proposed routing algorithm aims at optimizing the network lifetime, by balancing the routing effort among the sensors, taking into account their current residual batteries, while minimizing the control overhead. Simulation results show an increase of performances, in grid-based networks, which are common topologies for WSNs.","Sensor Networks ,  Wireless Sensor ,  Wireless Sensor Networks ,  Multi-hop Wireless Sensor Networks ,  Mobile Network ,  Ad Hoc Networks ,  Routing Algorithm ,  Network Lifetime ,  Human Spaceflight ,  Cost Function ,  Network Topology ,  Optimal Policy ,  Neighboring Nodes ,  State Machine ,  Communication Protocol ,  Bitrate ,  Markov Decision Process ,  Update Rule ,  Energy Depletion ,  Markov Property ,  Action-value Function ,  Greedy Policy ,  Sink Node ,  Planetary Exploration ,  Node Failure ,  Link Failure ,  Previous Node ,  Near-side ,  Dynamic Programming Approach ,  Linear Programming Approach "
BRATRA: Balanced Routing Algorithm With Transmission Range Adjustment for Energy Efficiency and Utilization Balance in WSNs,https://ieeexplore.ieee.org/document/9895273/,4,Journal Article,IEEE,2023,"In traditional wireless sensor networks (WSNs), packets are mainly transmitted in a multihop routing manner. The multihop transmission, however, leads to a hotspot problem in the sink connectivity area (SCA), and the overall network efficiency is reduced due to the quick battery power exhaustion of nodes in that area. This article proposes a novel balanced routing algorithm with transmission range adjustment (BRATRA) to address the network efficiency problem, including the energy efficiency and utilization issues. First, a balanced routing strategy is designed to deal with the SCA load imbalance problem. With the shortest balanced path, the amounts of forwarding packets for the nodes in the SCA and all the other intralayers become more even. From the perspective of power equilibrium in each routing path, each node then determines its accurate transmission radius according to the derived formula and performs power control to realize the even power utilization between interlayers, thereby prolonging the overall network lifetime. Performance evaluation validates that the proposed BRATRA strategy can achieve efficient power utilization in each intralayer and double the network lifetime as compared to the Dijkstra routing strategy. Additionally, it yields better power utilization fairness among nodes, and on average only 5% of battery power is unused for all network nodes, resulting in a network lifespan ten times larger than that using a conventional strategy.","Energy Efficiency ,  Energy Utilization ,  Wireless Sensor Networks ,  Transmission Range ,  Routing Algorithm ,  Balanced Routing ,  Utilization Efficiency ,  Shortest Path ,  Battery Power ,  Imbalance Problem ,  Power Utility ,  Balancing Strategy ,  Routing Scheme ,  Routing Path ,  Network Lifetime ,  Balancing Algorithm ,  Packet Forwarding ,  Load Imbalance ,  Energy Consumption ,  Power Consumption ,  Power Nodes ,  Nodes In Layer ,  Deep Reinforcement Learning ,  Routing Approach ,  Average Energy ,  Non-uniform Distribution ,  Residual Energy ,  Clustering Approach ,  Battery Capacity ,  Average Energy Consumption "
Reinforcement Learning-Based Adaptive Stateless Routing for Ambient Backscatter Wireless Sensor Networks,https://ieeexplore.ieee.org/document/10445292/,0,Journal Article,IEEE,2024,"This paper explores the routing problem in ambient backscatter wireless sensor networks (AB-WSNs) using reinforcement learning approaches. Ambient RF signals serve as the only power source for battery-less sensor nodes and are also leveraged to enable backscatter communication among these nodes. This results in intermittent connection and dynamic topology within AB-WSNs, thereby making it difficult to route data to the sink, e.g., data may not reach the sink in a timely manner. We first introduce a multi-agent network model with two mechanisms to address this issue. We then model the routing problem with the Markov decision process, allowing each node to make informed route decisions based on the current state of its neighbors. With the aim of enabling each node to learn the optimal routing policy and do adaptive stateless routing, we propose two learning algorithms. The first, a value-based learning algorithm, is designed for sparse AB-WSNs. And the second, a policy-based learning algorithm, is intended to tackle the curse of dimensionality in dense AB-WSNs. We analyze the convergence of both learning algorithms and evaluate their performance through extensive experiments. The experiment results validate the convergence and efficiency of the proposed learning algorithms under various conditions.","Sensor Networks ,  Wireless Sensor Networks ,  Adaptive Routing ,  Learning Algorithms ,  Network Model ,  Radiofrequency ,  Optimal Policy ,  Curse Of Dimensionality ,  Markov Decision Process ,  Routing Problem ,  Reinforcement Learning Approach ,  Connection Topology ,  Dynamic Topology ,  Ambient Signals ,  Learning Rate ,  Sensor Data ,  Energy Harvesting ,  Time Slot ,  Bit Error Rate ,  Operation State ,  Electromagnetic Environment ,  Traditional Communication ,  Stochastic Policy ,  Temporal Difference Learning ,  Routing Approach ,  Backscattered Signals ,  Deterministic Policy ,  Capacitor Energy ,  Downstream Nodes ,  State Action Space "
A Survey on Machine Learning Software-Defined Wireless Sensor Networks (ML-SDWSNs): Current Status and Major Challenges,https://ieeexplore.ieee.org/document/9718334/,21,Journal Article,IEEE,2022,"Wireless Sensor Network (WSN), which are enablers of the Internet of Things (IoT) technology, are typically used en-masse in widely physically distributed applications to monitor the dynamic conditions of the environment. They collect raw sensor data that is processed centralised. With the current traditional techniques of state-of-art WSN programmed for specific tasks, it is hard to react to any dynamic change in the conditions of the environment beyond the scope of the intended task. To solve this problem, a synergy between Software-Defined Networking (SDN) and WSN has been proposed. This paper aims to present the current status of Software-Defined Wireless Sensor Network (SDWSN) proposals and introduce the readers to the emerging research topic that combines Machine Learning (ML) and SDWSN concepts, also called ML-SDWSNs. ML-SDWSN grants an intelligent, centralised and resource-aware architecture to achieve improved network performance and solve the challenges currently found in the practical implementation of SDWSNs. This survey provides helpful information and insights to the scientific and industrial communities, and professional organisations interested in SDWSN, mainly the current state-of-art, ML techniques, and open issues.","Current Status ,  Wireless Sensor ,  Wireless Sensor Networks ,  Software-defined Wireless Sensor Networks ,  Machine Learning Techniques ,  Internet Of Things ,  Network Performance ,  Open Issues ,  Improve Network Performance ,  Energy Consumption ,  Learning Algorithms ,  Application Programming Interface ,  Network Resources ,  Semi-supervised Learning ,  Use Of Machine Learning ,  Network Management ,  Network Reliability ,  Reinforcement Learning Approach ,  Network Latency ,  Control Plane ,  Network Lifetime ,  Wireless Sensor Nodes ,  Received Signal Strength Indicator ,  Control Packets ,  Routing Path ,  Mobile Nodes ,  Virtual Network Functions ,  Protocol Stack ,  Network Configuration "
Reinforcement Learning-Based Opportunistic Routing Protocol for Underwater Acoustic Sensor Networks,https://ieeexplore.ieee.org/document/9351791/,60,Journal Article,IEEE,2021,"Due to the problems of high bit error rate and delay, low bandwidth and limited energy of sensor nodes in underwater acoustic sensor network (UASN), it is particularly important to design a routing protocol with high reliability, strong robustness, low end-to-end delay and high energy efficiency which can flexibly be employed in dynamic network environment. Therefore, a reinforcement learning-based opportunistic routing protocol (RLOR) is proposed in this paper by combining the advantages of opportunistic routing and reinforcement learning algorithm. The RLOR is a kind of distributed routing approach, which comprehensively considers nodes’ peripheral status to select the appropriate relay nodes. Additionally, a recovery mechanism is employed in RLOR to enable the packets to bypass the void area efficiently and continue to forward, which improves the delivery rate of data in some sparse networks. The simulation results show that, compared with other representative underwater routing protocols, the proposed RLOR performs well in end-to-end delay, reliability, energy efficiency and other aspects in underwater dynamic network environments.","Sensor Networks ,  Acoustic Networks ,  Opportunistic Routing ,  Opportunistic Routing Protocol ,  Energy Efficiency ,  Dense Network ,  Bit Error Rate ,  Network Environment ,  Bit Error ,  High Energy Efficiency ,  Reinforcement Learning Algorithm ,  Strong Robustness ,  Recovery Mechanisms ,  Most Significant Bit ,  Routing Algorithm ,  Relay Nodes ,  Energy Of Nodes ,  Data Integration ,  Performance Of Algorithm ,  Average Energy ,  Node Information ,  Sink Node ,  Node Deployment ,  Packet Forwarding ,  Sound Transmission ,  Source Node ,  Packet Delivery Ratio ,  Q-learning ,  Underwater Communication ,  Neighboring Nodes "
