title,link,number_of_citation,article_type,publisher,publication_date,abstract,keyword
Determination of Energy Efficient Routing Protocol for Underwater Optical Wireless Sensor Networks Using Reinforcement Learning Algorithm,https://ieeexplore.ieee.org/document/10270231/,1,Conference Paper,IEEE,2023,"underwater optical wireless sensor networks (OWSNs) are rapidly emerging networking technologies due to their quick response and wide transmission range. The light signals in OWSNs can travel through a long distance and result in higher communication reliability and longer-range sensing. In order to support a reliable communication of these networks, efficient routing and resource management schemes, which can adapt dynamically to the changing environment, are of vital importance. Reinforcement learning (RL) provides a versatile framework to optimize the routing and security parameters of OWSNs by learning from the environment and modeling the network. This paper presents an overview of RL-based approaches for routing and security in OWSNs. Various RL strategies have been proposed to address the routing, including Q-learning, SARSA, and double Q-learning. As for security, RL can be used to identify threats, detect anomalies, and reserve resources through the simulated interaction with the environment. The advantages of using the RL framework for underwater optical wireless sensor networks are discussed in this paper.","Learning Algorithms ,  Energy Efficiency ,  Optical Sensors ,  Sensor Networks ,  Wireless Sensor ,  Wireless Sensor Networks ,  Efficient Route ,  Reinforcement Learning Algorithm ,  Optical Networks ,  Environmental Changes ,  Reliable Communication ,  Reinforcement Learning Scheme ,  Deep Learning ,  Internet Of Things ,  Data Transmission ,  Network Performance ,  Harsh Environments ,  False Negative Rate ,  Environmental Model ,  Use Of Learning ,  Diagnostic Odds Ratio ,  Autonomous Underwater Vehicles ,  Markedness ,  Undersea ,  Uncertain Environment ,  Communication Links ,  Environmental Knowledge ,  Routing Decisions ,  Scheduling Decisions ,  Communication Protocol "
Improving Router Cooperation in Mobile Wireless Sensor Networks Using Reinforcement Learning,https://ieeexplore.ieee.org/document/6104544/,1,Conference Paper,IEEE,2011,"This paper proposes to promote cooperative routing for homogeneous mobile wireless sensor networks (mWSNs) using a scalable, distributed incentive-based mechanism with reasonable resource requirements using reinforcement learning (RL). In particular, Q-learning which is a well-known RL method was integrated an existing Continuous Value Cooperation Protocol (CVCP). We also studied their effects on the efficiency in non-cooperative mWSNs and propose a good routing strategy under constrained conditions such as network traffic load, degree of mobility and path loss exponent.","Sensor Networks ,  Wireless Sensor ,  Wireless Sensor Networks ,  Mobile Wireless Sensor Networks ,  Scalable ,  Path Loss Exponent ,  Reinforcement Learning Methods ,  Degree Of Mobility ,  Routing Scheme ,  Time Step ,  Cost Function ,  State Space ,  Online Learning ,  Game Theory ,  Source Node ,  Sleep Cycle ,  Network Load ,  Average Reward ,  Energy Consumption Cost ,  Path Nodes ,  Pause Time ,  Percentage Of Nodes ,  Number Of Credits ,  Success Ratio ,  Random Action ,  Action-value Function ,  Successful Path "
QTSRA: A Q-learning-based Trusted Routing Algorithm in SDN Wireless Sensor Networks,https://ieeexplore.ieee.org/document/10580079/,0,Conference Paper,IEEE,2024,"With the development of wireless communication technology and the Industrial Internet, Software Defined Network (SDN) technology has been introduced to wireless sensor networks due to its agility and flexibility. This meets the potential scalability and flexibility requirements of the Internet of Things. Thus, a new Industrial Internet architecture, called SDN-WSN, was formed. As the scale of SDN-WSN increases, efficient routing protocols with low latency and high security are required, while the standard routing protocol of SDN is still vulnerable to dynamic changes in traffic control rules, especially when the network is under attack. To address the above issues, a network node credibility evaluation model based on D-S evidence theory was constructed to evaluate the trust value of wireless sensor network nodes. A trustworthy secure routing algorithm based on Q-learning (QTSRA) was proposed. This method extracts knowledge from historical traffic demands by interacting with the underlying network environment to evaluate the trustworthiness of network nodes. Simultaneously, it implements dynamic optimising routing strategies based on deep reinforcement learning algorithms. We conducted simulation experiments for several network performance metrics, and the results showed that the proposed QTSRA routing algorithm exhibited good performance. In most of the cases, the QTSRA had an improved relative performance gain as compared to the traditional AODV and OLSR routing algorithms.","Wireless Sensor Networks ,  Routing Algorithm ,  Model Evaluation ,  Simulation Experiments ,  Internet Of Things ,  Wireless Networks ,  Low Latency ,  Value Of Node ,  Deep Reinforcement Learning ,  Reinforcement Learning Algorithm ,  Evidence Theory ,  Traditional Routes ,  Deep Reinforcement Learning Algorithm ,  Industrial Internet ,  Routing Scheme ,  Trust Value ,  Basis Functions ,  Pieces Of Evidence ,  Heterogeneous Network ,  Increase In Period ,  Malicious Nodes ,  Fuzzy Measure ,  Denial Of Service ,  Packet Loss Rate ,  Malicious Attacks ,  Current Node ,  Q-learning Algorithm ,  Highest Confidence ,  Confidence Value ,  Rate Of Nodes "
SDN-QLTR: Q-Learning-Assisted Trust Routing Scheme for SDN-Based Underwater Acoustic Sensor Networks,https://ieeexplore.ieee.org/document/10299669/,1,Journal Article,IEEE,2024,"In underwater acoustic sensor networks (UASNs), the underwater sensors perform underwater data collection tasks, such as data collection and transmission at different locations in the monitoring area. To support cooperative underwater missions among the underwater sensor nodes, such as cooperative data delivery, one of the challenges is how to design smart underwater routing protocols that can guarantee safe, reliable, and energy-efficient data transfer among the underwater sensors. In this article, we introduce the paradigm of software-defined networking (SDN) and propose an SDN-based network framework for UASNs. Based on the proposed network framework, a 
 $Q$ 
-learning-assisted trust routing scheme for SDN-based UASNs (SDN-QLTR) is proposed. The proposed SDN-QLTR aims to seek for a secure routing path for executing underwater data transmission. Note that, in SDN-QLTR, effective trust evaluation methods are designed to resist malicious attacks initiated by nodes in UASNs. And SDN-QLTR integrates the advantages of SDN and reinforcement learning algorithm, can be flexibly applied in UASNs with dynamic features. Simulation results show that SDN-QLTR performs better in network lifetime, latency, and reliability.","Sensor Networks ,  Routing Scheme ,  Acoustic Networks ,  Learning Algorithms ,  Data Transmission ,  Reinforcement Learning Algorithm ,  Malicious Attacks ,  Network Lifetime ,  Dense Network ,  Time Slot ,  Neighboring Nodes ,  Waiting Time ,  Types Of Attacks ,  Source Node ,  Residual Energy ,  Undersea ,  Destination Node ,  Trust Model ,  Trust Value ,  Changes In Network Topology ,  DoS Attacks ,  Energy Of Nodes ,  Malicious Nodes ,  Routing Decisions ,  Autonomous Surface Vehicles ,  Node Depth ,  Behavior Of Nodes ,  Data Trust ,  Wireless Sensor Networks ,  Energy Consumption "
A Multi-Agent Reinforcement Learning Routing Protocol for Underwater Optical Sensor Networks,https://ieeexplore.ieee.org/document/8761441/,30,Conference Paper,IEEE,2019,"Much attention has been paid to underwater optical wireless sensor networks with the characteristics of high transmission rate and low delay for high-bandwidth underwater applications. However, several issues may take place and hinder the routing of underwater optical communication nodes due to the highly dynamic topology caused by the ocean current movement. On the purpose of addressing the problem and enhancing the robustness of dynamic network, in this paper, we propose a novel routing protocol, based on multi-agent reinforcement learning (MARL) for underwater optical sensor networks. The network is firstly modeled as a multi-agent system and the protocol based on reinforcement learning algorithm is designed to realize dynamic route selection by information interacting between adjacent nodes and maximize the network lifetime. The simulation results demonstrate that MARL has lower energy consumption and higher delivery ratio (about 95%) in a dynamic topology than the existing Q-learning, QDTR and AODV routing protocols.","Optical Sensors ,  Sensor Networks ,  Optical Networks ,  Multi-agent Reinforcement Learning ,  Optical Sensor Networks ,  Energy Consumption ,  Dynamic Network ,  Multi-agent Systems ,  Optical Communication ,  Wireless Sensor Networks ,  Reinforcement Learning Algorithm ,  Adjacent Nodes ,  Route Selection ,  Dynamic Topology ,  Delivery Ratio ,  Network Lifetime ,  Underwater Communication ,  Network Topology ,  Long-term Goals ,  Neighboring Nodes ,  Residual Energy ,  Distribution Of Nodes ,  Energy Of Nodes ,  Undersea ,  Reward Function ,  Markov Decision Process ,  Static Network ,  Mobile Nodes ,  Processing Routes ,  Routing Scheme "
Deep-q-Networks-Based Adaptive Dual-Mode Energy-Efficient Routing in Rechargeable Wireless Sensor Networks,https://ieeexplore.ieee.org/document/9745096/,6,Journal Article,IEEE,2022,"In order to enhance the sustainability of rechargeable wireless sensor networks (RWSN), a deep-q-networks (DQN)-based adaptive dual-mode energy-efficient routing is proposed in this paper. Firstly, the life expectancy of each node is calculated based on multiple related factors, and a multi-hop routing based on forward transmission principle is proposed by using the indicator. Then according to the relationship between the life expectancy of a single node and the average life expectancy of the whole network, an adaptive dual-mode energy-efficient routing is proposed, which combines the multi-hop routing and the direct upload routing. Finally, for reducing the requirement of the single node for the network state information in the process of routing mode selection, a reinforcement learning framework based on DQN is designed, enabling the nodes to learn to judge the above relationship of life expectancy based on partial state information of its local network. Simulation results show that dynamic adjustment of the routing mode enables our algorithm to effectively optimize energy efficiency, so that the network lifetime increases obviously. Based on the limited information, the correct rate of routing mode selection can reach 95%, which ensures the applicability of our algorithm.","Wireless Sensor Networks ,  Adaptive Routing ,  Energy-efficient Routing ,  Wireless Rechargeable Sensor Networks ,  Lifespan ,  Energy Efficiency ,  Local Network ,  Network State ,  Partial Information ,  Average Life Expectancy ,  Part Of The State ,  Direct Route ,  Selection Rate ,  Reinforcement Learning Framework ,  Network Lifetime ,  Energy Consumption ,  Network Topology ,  Data Transmission ,  Base Station ,  Side Length ,  Cluster Head ,  Routing Scheme ,  Traffic Load ,  Relay Nodes ,  Correction Module ,  Routing Algorithm ,  Data Packets ,  Longest Lifetime ,  Common Node "
A Deep Learning Enabled Software-Defined Radio based Routing Protocol for Underwater Acoustic Sensor Networks,https://ieeexplore.ieee.org/document/9760848/,8,Conference Paper,IEEE,2022,"Over the recent years, several aquatic applications rely on promising networking techniques like the underwater acoustic sensor network (UWSN) for data exchange. UWSN exhibits certain challenges like high energy consumption, low bandwidth, and high latency while building network protocols. The UWSN routing issue is addressed in this paper by introducing a lifetime aware, energy efficient, adaptive, deep learning enabled software-defined radio-based routing protocol for underwater acoustic sensor networks. The network development risks are largely reduced and the flexibility is increased using a novel paradigm called Software-Defined Networking (SDN). Distribution of the sensor nodes and their residual energy helps in prolonging the network lifetime using generic MAC protocols. An adequate number of nodes are selected for forwarding the packets by calculating the reward function throughout the routing process while distributing the residual energy of each node among a group of nodes. A deep reinforcement learning algorithm is used for optimization of this routing protocol by reducing the throughput and delay. Network lifetime, latency, energy efficiency, and packet delivery rate of the proposed model is compared with the existing models. Simulation is performed on Aqua-sim platform. From the results of simulation, it is evident that the proposed model increases the network lifetime by 15% when compared to the conventional techniques.","Deep Learning ,  Sensor Networks ,  Acoustic Networks ,  Energy Efficiency ,  Delivery Rate ,  Deep Reinforcement Learning ,  Residual Energy ,  Deep Reinforcement Learning Algorithm ,  Network Lifetime ,  Metadata ,  Data Transmission ,  Average Energy ,  Very Low Frequency ,  Wireless Sensor ,  Wireless Sensor Networks ,  Data Packets ,  OpenFlow ,  Acoustic Communication ,  Control Plane ,  Autonomous Underwater Vehicles ,  Virtual Network Functions ,  All-to-all Communication ,  Routing Decisions ,  Control Packets ,  Packet Header ,  Flow Table ,  Payload Data "
Q-Learning-Based Data-Aggregation-Aware Energy-Efficient Routing Protocol for Wireless Sensor Networks,https://ieeexplore.ieee.org/document/9321407/,94,Journal Article,IEEE,2021,"The energy consumption of the routing protocol can affect the lifetime of a wireless sensor network (WSN) because tiny sensor nodes are usually difficult to recharge after they are deployed. Generally, to save energy, data aggregation is used to minimize and/or eliminate data redundancy at each node and reduce the amount of the overall data transmitted in a WSN. Furthermore, energy-efficient routing is widely used to determine the optimal path from the source to the destination, while avoiding the energy-short nodes, to save energy for relaying the sensed data. In most conventional approaches, data aggregation and routing path selection are considered separately. In this study, we consider the degrees of the possible data aggregation of neighbor nodes when a node needs to determine the routing path. We propose a novel Q-learning-based data-aggregation-aware energy-efficient routing algorithm. The proposed algorithm uses reinforcement learning to maximize the rewards, defined in terms of the efficiency of the sensor-type-dependent data aggregation, communication energy and node residual energy, at each sensor node to obtain an optimal path. We used sensor-type-dependent aggregation rewards. Finally, we performed simulations to evaluate the performance of the proposed routing method and compared it with that of the conventional energy-aware routing algorithms. Our results indicate that the proposed protocol can successfully reduce the amount of data and extend the lifetime of the WSN.","Sensor Networks ,  Wireless Sensor ,  Wireless Sensor Networks ,  Energy-efficient Routing ,  Energy Consumption ,  Aggregate Data ,  Sensor Data ,  Wireless Networks ,  Neighboring Nodes ,  Optimal Path ,  Degree Of Aggregation ,  Residual Energy ,  Routing Algorithm ,  Conventional Route ,  Routing Path ,  Network Lifetime ,  Aggregator Node ,  Time Step ,  Energy Efficiency ,  Shortest Path ,  Hop Count ,  Energy Of Nodes ,  Number Of Sensor Nodes ,  Sink Node ,  Model Aggregation ,  Types Of Sensors ,  Vehicular Ad Hoc Networks ,  Ant Colony Optimization Algorithm ,  Actual Reward ,  Unmanned Aerial Vehicles "
Futuristic Analysis of Machine Learning Based Routing Protocols in Wireless Ad Hoc Networks,https://ieeexplore.ieee.org/document/9514998/,6,Conference Paper,IEEE,2021,"With achievements of Machine learning over the past years many computer networks and artificial intelligence actively using Machine learning architecture and its technology to improvise the performance of their approach for effective output. Machine learning plays great role in the field of wireless ad-hoc network as by providing the suitable environment to the routing protocols to make them react accordingly so that will have maximum throughput and parameters such as packet delivery ratio, hop-to-hop count, optimization of quality of service (QoS) will increased. In this paper, various types of Machine learning applied on different wireless Ad-hoc network are studied and how the performance parameters vary accordingly. A systematic approach is used to study all simulators which are utilized and evaluated by different protocols used in MANET, VANET. There is a need of a many other parameters to be studied and simulation used in Ad-hoc network which enables the users to ensure the optimization so that we can minimize the chances of failure of data and maximize the throughput after selecting best model of machine learning. This paper presents the futuristic anatomy of different machine learning models used in various protocols.","Machine Learning ,  Wireless Networks ,  Ad Hoc Networks ,  Service Quality ,  Machine Learning Models ,  Digital Networks ,  Role In The Field ,  Network Throughput ,  Delivery Ratio ,  Packet Delivery Ratio ,  Machine Learning Architectures ,  Learning Algorithms ,  Support Vector Machine ,  Machine Learning Techniques ,  Multinomial Regression ,  Shortest Path ,  Sensor Networks ,  Temporal Differences ,  Open Issues ,  Traffic Prediction ,  Wireless Sensor Networks ,  Future Scope ,  Area Under Receiver Operating Characteristic Curve ,  Reinforcement Learning Algorithm ,  Q-learning ,  Back Propagation Neural Network ,  Destination Node ,  Network Routing ,  Mobile Nodes "
Topology-Aware Reinforcement Learning Routing Protocol in Underwater Wireless Sensor Networks,https://ieeexplore.ieee.org/document/8939720/,5,Conference Paper,IEEE,2019,"Existing reinforcement learning (RL)-based routing protocols in underwater wireless sensor networks (UWSNs) do not consider the network topology when selecting a next-forwarder for packet forwarding. To eliminate resource waste from the forwarding in a wrong direction, this paper proposes a network topology-aware RL routing protocol for UWSNs. Taking the network topology into account, sensor nodes first find next-forwarder candidates and then select a highest-valued one of them to forward data. The simulation result shows that the proposed scheme outperforms QELAR in terms of latency and total energy consumption.","Wireless Sensor Networks ,  Underwater Wireless Sensor Networks ,  Network Topology ,  Total Energy Consumption ,  Wrong Direction ,  Forward Data ,  Packet Forwarding ,  Channel State ,  Battery Power ,  Reward Function ,  Energy Waste ,  Data Packets ,  Residual Energy ,  Amount Of Reward ,  Routing Path ,  Packet Delivery ,  Packet Error "
Latency and Lifetime Enhancements in Industrial Wireless Sensor Networks: A Q-Learning Approach for Graph Routing,https://ieeexplore.ieee.org/document/8839827/,38,Journal Article,IEEE,2020,"Industrial wireless sensor networks usually have a centralized management approach, where a device known as network manager is responsible for the overall configuration, definition of routes, and allocation of communication resources. Graph routing is used to increase the reliability of communication through path redundancy. Some of the state-of-the-art graph-routing algorithms use weighted cost equations to define preferences on how the routes are constructed. The characteristics and requirements of these networks complicate to find a proper set of weight values to enhance network performance. Reinforcement learning can be useful to adjust these weights according to the current operating conditions of the network. In this article, we present the Q-learning reliable routing with a weighting agent approach, where an agent adjusts the weights of a state-of-the-art graph-routing algorithm. The states of the agent represent sets of weights, and the actions change the weights during network operation. Rewards are given to the agent when the average network latency decreases or the expected network lifetime increases. Simulations were conducted on a WirelessHART simulator considering industrial monitoring applications with random topologies. Results show, in most cases, a reduction of the average network latency while the expected network lifetime and the communication reliability are at least as good as what is obtained by the state-of-the-art graph-routing algorithms.","Wireless Sensor ,  Wireless Sensor Networks ,  Industrial Networks ,  Industrial Sensor ,  Industrial Wireless Sensor Networks ,  Graph Routing ,  Network Performance ,  Network Operators ,  Network Management ,  Centralized Approach ,  Random Topology ,  Effect Of Activity ,  Weight Reduction ,  Performance Metrics ,  Learning Curve ,  Network Topology ,  Low Energy Consumption ,  Graph Construction ,  Reinforcement Learning Algorithm ,  Exploration Time ,  Routing Algorithm ,  Percentage Of Nodes ,  Battery Lifetime ,  Scheduling Algorithm ,  Industrial Internet Of Things ,  Management Routines ,  Long-term Reward ,  Network Reconfiguration ,  Repeat Simulations ,  Residual Energy "
DRL-ER: An Intelligent Energy-Aware Routing Protocol With Guaranteed Delay Bounds in Satellite Mega-Constellations,https://ieeexplore.ieee.org/document/9266059/,34,Journal Article,IEEE,2021,"Major space companies are developing satellite mega-constellations to provide global Internet coverage and services. Limited battery capacity is one of the biggest obstacles on mega-constellations due to the restricted weight and volume of satellites. Massive Internet packet routing tasks pose a big challenge to the energy system in such mega constellations. Incorrect use of satellite batteries during routing phases may significantly increase the energy consumption and cause node failure quickly. Existing state-of-the-art works on energy-saving routing for satellite networks paid much attention on traffic distribution and end-to-end delay issues. However, these methodologies were using many real-time network information for optimization which is not practical in mega-constellations. Note also that these works did not consider energy efficiency and guaranteed end-to-end delay simultaneously. In this paper, we propose a novel deep reinforcement learning based energy-efficient routing protocol called DRL-ER, which avoids the battery energy imbalance of constellations and can also guarantee a required bounded end-to-end delay. In DRL-ER, satellites can learn a routing policy that will balance energy usage among satellites. Extensive simulation results show that our proposed DRL-ER protocol reduces the energy consumption of satellites in average by more than 55% compared to the current state-of-the-art work, and prolongs the lifetime of constellations significantly.","Bound Of Delay ,  Energy Consumption ,  Deep Learning ,  Energy Conservation ,  Deep Reinforcement Learning ,  Internet Service ,  Battery Capacity ,  Battery Energy ,  Satellite Networks ,  Network Environment ,  Markov Decision Process ,  Wireless Sensor Networks ,  Load Balancing ,  Extreme Learning Machine ,  Routing Problem ,  Ad Hoc Networks ,  Current Node ,  Dijkstra’s Algorithm ,  Destination Node ,  Depth Of Discharge ,  Degree Of Aging ,  Routing Decisions ,  Routing Method ,  Routing Scheme ,  Deep Q-learning ,  Routing Path ,  Routing Algorithm ,  Battery Level ,  Routing Table "
Reinforcement Learning-Based Routing Protocol for Underwater Wireless Sensor Networks: A Comparative Survey,https://ieeexplore.ieee.org/document/9615209/,12,Journal Article,IEEE,2021,"Underwater wireless sensor networks (UWSNs) have emerged as a promising networking technology owing to their various underwater applications. Many applications require sensed data to be routed to a centralized location. However, the routing of sensor networks in underwater environments presents several challenges in terms of underwater infrastructure, including high energy consumption, narrow bandwidths, and longer propagation delays than other sensor networks. Efficient routing protocols play a vital role in this regard. Recently, reinforcement learning (RL)-based routing algorithms have been investigated by different researchers seeking to exploit the learning procedure via trial-and-error methods of RL. RL algorithms are capable of operating in underwater environments without prior knowledge of the infrastructure. This paper discusses all routing protocols proposed for RL-based UWSNs. The advantages, disadvantages, and suitable application areas are also mentioned. The protocols are compared in terms of the key ideas, RL designs, optimization criteria, and performance-evaluation techniques. Moreover, research challenges and outstanding research issues are also highlighted, to indicate future research directions.","Wireless Sensor Networks ,  Underwater Wireless Sensor Networks ,  Energy Consumption ,  Optimization Criteria ,  Reinforcement Learning Algorithm ,  Propagation Delay ,  Undersea ,  Routing Algorithm ,  Underwater Applications ,  Neighboring Nodes ,  Reward Function ,  Data Packets ,  Source Node ,  Residual Energy ,  Acoustic Communication ,  Relay Nodes ,  Routing Path ,  Autonomous Underwater Vehicles ,  Dynamic Topology ,  Sink Node ,  Network Lifetime ,  Mobile Nodes ,  Packet Drop ,  Energy Of Nodes ,  Packet Forwarding ,  Node Depth ,  Packet Delivery Ratio ,  Underwater Communication ,  Vehicular Ad Hoc Networks "
Application of machine learning (reinforcement learning) for routing in Wireless Sensor Networks (WSNs),https://ieeexplore.ieee.org/document/6260967/,8,Conference Paper,IEEE,2012,"Traditionally, protocols and applications in the networking domain have been designed to work in large-scale heterogeneous, hierarchically organized networks with low failure rate. In a Wireless Sensor Network (WSN) scenario, new problems arise and traditional routing protocols cannot be successfully applied. Additionally, in energy-restricted environments like WSNs the overhead of keeping routing information fresh becomes unbearable. In this problem context problem context, many researchers have turned their attention to the domain of machine learning (ML). The goal of this paper is to analyze the application of the Reinforcement Learning (specifically Q-learning) for an energy- aware routing scenario.","Sensor Networks ,  Wireless Sensor Networks ,  Lower Failure Rate ,  Energy Levels ,  Lowest Energy ,  Wireless Networks ,  Shortest Path ,  Neighboring Nodes ,  Original Algorithm ,  Multiple Paths ,  Load Balancing ,  Node Level ,  Traffic Load ,  Energy Capacity ,  Routing Algorithm ,  Medium Access Control ,  Extra Overhead ,  Traffic Simulation ,  Q-learning Algorithm ,  Network Packets ,  Routing Table ,  Network Lifetime ,  Energy Of Nodes ,  Network Load ,  Simulation Environment ,  Computational Overhead ,  Feedback Delay ,  Exponential Function ,  Linear Function "
Enhancing Wireless Sensor Network Routing Strategies with Machine Learning Protocols,https://ieeexplore.ieee.org/document/10537481/,0,Conference Paper,IEEE,2024,"Woth the realm of Internet supportive Things (IoT), where numerous wireless components constantly communicate, a unique challenge arises. This challenge includes issues such as handling diverse devices, ensuring data broadcasting and managing scalability. To handle these issues, a new routing protocol has been proposed in this paper. This protocol is intelligent, energy-conscious, and employs a multi-objective approach, based on the distribution type Reinforcment based Learn -Driven (RL) mechanism integrated Meta-Learning termed as Data synchronized -Machine learning (DS-ML). The core goal of proposed data-route mechanism, called DS-ML, will optimized power consumption on IoT connected networks, a critical issue given the defined power resources of wireless connected IoT Components. Additionally, mechanism focuses on adapting to network changes seamlessly by ensuring smooth adjustments to alterations and minimizing disruptions to enhances entire network Efficacy. The algorithm incorporates correlates issues in rewards designed in acceleration of the learn cycle. Through various simulation parameters, the DS-ML routing protocol demonstrated significant improvements in power efficacy and rapid adapt in unexpected network happenings. This was evidenced by enhancements in delivered ratio of data sets and reductions in data-sets delivery latency when compares in conventional data-routing Techniques. In general, proposed DS-ML system represents a solution for enhancing the performances and sustainability of IoT network infrastructure.","Sensor Networks ,  Wireless Sensor ,  Wireless Sensor Networks ,  Machine Learning Protocol ,  Network Changes ,  All-to-all Communication ,  Energy Consumption ,  Learning Process ,  Specific Tasks ,  Performance Metrics ,  Internet Of Things ,  Data Transmission ,  Network Performance ,  Network State ,  Pathfinding ,  Energy Usage ,  Reward Function ,  Data Packets ,  Nodal Points ,  Traffic Load ,  Packet Delivery Ratio ,  Routing Algorithm ,  Sensory Environment ,  Delay Increases ,  Routing Decisions ,  Current State Of The Environment ,  Iterative Process ,  Network Topology ,  Sensor Devices "
Delay Analysis of Routing Protocols for WSN,https://ieeexplore.ieee.org/document/10323768/,0,Conference Paper,IEEE,2023,"In this paper, we explore the benefits of cooperative diversity for Wireless Sensor Network (WSN). Relays are uniformily distributed in 
$L$
 hops and 
$N$
 branches between the sensor nodes SN and the base station BS. Three cooperative routing protocols are considered, namely: one hop, suboptimal and optimal routing protocols. One hop routing chooses the best relay in each hop. Optimal routing selects the best path between SN and BS. Suboptimal routing decomposes the network into 
$K$
 subnetworks and selects successively the best path in each one. We derive the outage probability, the Packet Error Probability (PEP) and the queening delays spent in the system for each protocol.","Wireless Sensor Networks ,  Base Station ,  Bit Error Rate ,  Pathfinding ,  Outage Probability ,  Hierarchical Structure ,  Probability Density Function ,  Time Slot ,  K-means Algorithm ,  Deep Reinforcement Learning ,  Cooperative Strategy ,  Rayleigh Fading ,  Total Delay ,  Cumulative Density Function ,  Relay Nodes ,  Cluster Head ,  Network Lifetime ,  Quadrature Phase Shift Keying ,  Slot Duration ,  Packet Arrival ,  Consecutive Nodes ,  Multiple-access Channel "
Back Propagation Neural Network-Based Routing Optimization for IoT,https://ieeexplore.ieee.org/document/10346315/,0,Conference Paper,IEEE,2023,"The Internet of Things (IoT) has fundamentally changed how we engage with the environment that surrounds us by facilitating the connection of various devices and the flow of data between them. However, as the complexity of IoT networks increases, effective routing becomes more and more important to guarantee that data transfer and network performance are at their best. It is possible that traditional routing algorithms would not be able to manage the size and fluidity of Internet of Things networks. Optimizing the routing of Internet of Things devices has necessitated the use of more cutting-edge methods, such as the Back Propagation Neural Network (BPNN), which has been developed by researchers. In this research paper, we provide a unique strategy to handle the routing optimization issue in IoT by employing BPNNs. Back Propagation Neural Networks is a kind of neural network. By using the tremendous capabilities of artificial neural networks, the BPNN-based routing optimization intends to improve the efficacy of IoT networks as well as their adaptability.","Internet Of Things ,  Pathfinding ,  Neural Network ,  Artificial Neural Network ,  Network Performance ,  Internet Of Things Devices ,  Back Propagation Neural Network ,  Internet Of Things Networks ,  Routing Algorithm ,  Kind Of Neural Network ,  Service Quality ,  Energy Efficiency ,  Network Topology ,  Energy Use ,  Fault-tolerant ,  Limitation Of This Work ,  Sensor Networks ,  Amount Of Power ,  Wireless Sensor Networks ,  Ad Hoc Networks ,  Packet Delivery Ratio ,  Routing Decisions ,  Route Choice ,  Mobile Nodes ,  Routing Method ,  Traffic Load ,  Data Packets ,  Node Information "
Clustering-Based Reinforcement Learning Routing Protocol with Low Complexity for Underwater Acoustic Sensor Networks,https://ieeexplore.ieee.org/document/9538885/,1,Conference Paper,IEEE,2021,"With the increase in the number of relay nodes in large-scale underwater acoustic sensor networks (UWA-SNs), the learning costs of routing protocols based on reinforcement learning algorithms continue to increase. In this paper, we take the Q-learning (QL) algorithm as the example of the reinforcement learning algorithm, combined with the clustering algorithm based on genetic simulated annealing algorithm (SAGAFCM), and propose an improved QL routing protocol (IQLR) aimed at reducing the time complexity of QL-based routing algorithm. The core idea is to preprocess the underwater relay nodes before applying the traditional QL algorithm for routing optimization. The simulation results show that compared with the un-preprocessed/traditional QL routing algorithm (UQLR), the proposed IQLR can greatly reduce the time cost of the QL-based routing algorithm while ensuring that the transmission quality does not change much.","Acoustic Networks ,  Increase In The Number ,  Learning Algorithms ,  Clustering Algorithm ,  Simulated Algorithm ,  Reinforcement Learning Algorithm ,  Polynomial-time Algorithm ,  Simulated Annealing Algorithm ,  Routing Algorithm ,  Relay Nodes ,  Q-learning Algorithm ,  Quality Of Transmission ,  Energy Consumption ,  Total Distance ,  Energy Transmission ,  Reward Function ,  Cluster Nodes ,  Selection Stage ,  Source Node ,  Residual Energy ,  Transmission Energy Consumption ,  Route Selection ,  Route Design ,  Energy Of Nodes "
A Lifetime-Aware Centralized Routing Protocol for Wireless Sensor Networks using Reinforcement Learning,https://ieeexplore.ieee.org/document/9606390/,3,Conference Paper,IEEE,2021,"This paper presents the design of a Lifetime-Aware Centralized Q-routing Protocol (LACQRP) for Wireless Sensor Network (WSN) to maximize the network lifetime. This is achieved by implementing Q-learning on the sink of the WSN, which also acts as a controller that has global knowledge of the network topology as enabled by Software-Defined WSN (SDWSN). The controller generates all possible distance-based minimum spanning trees (MSTs), which form the set of routing tables (RTs). The maximization of the network lifetime is achieved by the controller learning the routing table that minimizes the maximum of the sensor nodes’ consumption energies using Reinforcement Learning (RL). The simulation results show that the LACQRP learns the best RT that maximizes the network lifetime and has a better network lifetime performance when compared with recent distributed RL routing protocols for lifetime optimization, which are Reinforcement Learning-Based Routing (RLBR) and Reinforcement Learning for Lifetime Optimization (R2LTO).","Sensor Networks ,  Wireless Sensor Networks ,  Centralized Routing ,  Spanning Tree ,  Network Lifetime ,  Routing Table ,  Energy Consumption ,  Energy Source ,  Distance Function ,  Energy Transmission ,  Reward Function ,  Optimal Path ,  Data Packets ,  Residual Energy ,  Learning Agent ,  Transmission Range ,  Routing Path ,  Energy Of Nodes ,  Network Energy Efficiency ,  Hop Count "
QEnergy and SARSAEnergy Learning for Energy efficient Routing in Wireless Sensor Networks,https://ieeexplore.ieee.org/document/9807754/,1,Conference Paper,IEEE,2022,"Wireless sensor network nodes will be located at varying distances in the network, and the data travel between each node requires the shortest path to transmit data. In data transmission, when a particular node is active for a long time, it will lead to energy depletion and the node will remain active based on residual energy. Reinforcement learning with the Markov model assigns rewards for the best path taken to transmit data between nodes. The nodes are located randomly with the Erdos-Renyi random graph model, which is a stochastic graph. The energy consumption depends on the amount of data transmitted and how long the particular node is active. The proposed QEnergy-Learning and SARSAEnergy algorithms can be used to calculate energy consumption in the wireless sensor network with rewards. The proposed work efficiency is evaluated by taking into account various WSN infrastructure and calculating energy consumption. The agent learns its environment and transmits data packets, and its performance is compared to that of various algorithms in different network infrastructures.","Sensor Networks ,  Wireless Sensor Networks ,  Energy-efficient Routing ,  Energy Consumption ,  Data Transmission ,  Shortest Path ,  Graphical Model ,  Network Infrastructure ,  Random Graph ,  Residual Energy ,  Network Distance ,  Erdős-Rényi Model ,  Data Packet Transmission ,  Learning Algorithms ,  Support Vector Machine ,  Artificial Neural Network ,  Hidden Markov Model ,  Transition Probabilities ,  Linear Programming ,  Inactive State ,  Markov Decision Process ,  Energy Of Nodes ,  Network Lifetime ,  Routing Information ,  Wireless Power Transfer ,  Scheduling Algorithm ,  Linear Problem ,  Mixed Integer Linear Programming ,  Cluster Head ,  Pathfinding "
MeFi: Mean Field Reinforcement Learning for Cooperative Routing in Wireless Sensor Network,https://ieeexplore.ieee.org/document/10164652/,2,Journal Article,IEEE,2024,"Wireless sensor networks (WSNs) enable intelligent collaborative perceptions in the Internet of Things. However, devices in WSNs are battery-powered with limited energy resources. During transmission, routing policies significantly affect the energy efficiency in terms of both energy consumption and energy balance among nodes, and further impact the network lifetime. Previous works mostly used heuristic fixed strategies to make routing decisions based on incomplete information in a distributed manner for lower control costs and faster calculation when facing numerous devices in WSNs, which easily lead to performance limitations and routing loops. To this end, we model the network lifetime maximization problem as a decentralized partially observable Markov decision process and propose a new scheme MeFi based on Mean Field Reinforcement Learning to perform real-time energy-efficient routing policies for WSNs. The utilization of Mean Field Theory effectively simplifies the intractable interactions among numerous agents and guides the policy training. Additionally, a prioritized-sampling loop-free algorithm is developed to eliminate routing loops and avoid routing policies with significant energy consumption. Experimental results show that our scheme outperforms several algorithms by up to 50%, significantly enhancing energy efficiency and extending WSN lifetime under different circumstances.","Mean-field ,  Wireless Sensor Networks ,  Wireless Sensor Network Routing ,  Energy Consumption ,  Energy Efficiency ,  Internet Of Things ,  Markov Decision Process ,  Network Lifetime ,  Routing Decisions ,  Inner Layer ,  Energy Distribution ,  Network State ,  Root Node ,  Actor Network ,  Reward Function ,  Nash Equilibrium ,  Residual Energy ,  Observation Space ,  Set Of Agents ,  Critic Network ,  Monte Carlo Tree Search ,  Sink Node ,  Energy Of Nodes ,  Spanning Tree ,  Well-trained Model ,  Transmission Range ,  Multi-agent Reinforcement Learning ,  Function Of Agent ,  Online Algorithm ,  Policy Agencies "
Soft computing techniques to address various issues in wireless sensor networks: A survey,https://ieeexplore.ieee.org/document/7813753/,3,Conference Paper,IEEE,2016,"Wireless sensor network (WSN) is a collection of large number of self-organized types of sensors which chain together to monitor and record physical or environmental conditions (i.e. used to measure temperature, sound, pressure) and passes gathered information to the central location. WSN build bridge between real world and virtual environment, which makes it more utilizable for many applications. Mainly WSN was used for military arena but now a days it is used in various area like industrial applications, consumer applications, health care applications and many more. Despite of having many advantages there are some issues also occurred in WSNs like hotspot problem, energy hole problem, routing, coverage problem, load balancing problem and so on. These issues effect on different factors of WSN named energy consumption, stability, quality, deployment time, lifetime of network, which degrade the performance of the WSN. To solve these issues various researchers develop different mechanisms. Among all of them, in this paper, we survey different kind of soft computing paradigms. Soft computing is a technique to use of improper solutions to solve the complicated problem in robust time. There are various types of soft computing techniques developed: swarm intelligence, fuzzy logic, neural network, reinforcement learning and evolutionary algorithm, which used to solve WSN problems so that performance of the network will be increased.","Sensor Networks ,  Wireless Sensor Networks ,  Soft Computing ,  Soft Computing Techniques ,  Neural Network ,  Energy Consumption ,  Learning Algorithms ,  Evolutionary Algorithms ,  Fuzzy Logic ,  Reinforcement Learning Algorithm ,  Swarm Intelligence ,  Coverage Problem ,  Network Lifetime ,  Optimization Algorithm ,  Probabilistic Model ,  Clustering Algorithm ,  Base Station ,  Particle Swarm Optimization ,  Neighboring Nodes ,  Data Fusion ,  Ant Colony Optimization Algorithm ,  Cluster Head ,  Ant Colony Optimization ,  Fuzzy Control ,  Fuzzy Clustering ,  Residual Energy ,  Sensor Deployment ,  Routing Table ,  Routing Algorithm ,  Time Difference Of Arrival "
A Survey on Utilizing Reinforcement Learning in Wireless Sensor Networks Routing Protocols,https://ieeexplore.ieee.org/document/10039013/,2,Conference Paper,IEEE,2022,"This article reviews the control and routing methods in Wireless Sensor Networks. These methods are able to increase the energy efficiency by using the reinforcement learning technique, considered as one of the means of machine learning. It is based on the reward and punishment technique which has a behavior similar to the learning process in children. Appropriate energy management and therefore lifespan increase in wireless sensor networks is one of the main issues in these types of networks due to the energy consumption limitation in its nodes. The purpose of writing the current article is to get acquainted with the relative methods provided. In this article, various means which are trying to use the reinforcement learning process to improve the behavior of wireless sensor networks and to make them smarter are presented and analyzed. Meanwhile, the evolution of these methods and the ratio of the superiority of each in comparison to the others have been examined.","Sensor Networks ,  Wireless Sensor ,  Wireless Sensor Networks ,  Energy Consumption ,  Learning Process ,  Wireless Networks ,  Reinforcement Learning Techniques ,  Routing Method ,  Value Function ,  Number Of Steps ,  Shortest Path ,  State Value ,  Information In Order ,  Optimal Policy ,  Neighboring Nodes ,  Techniques In Order ,  Source Node ,  Target Node ,  Policy Gradient ,  Current Node ,  Energy Of Nodes ,  Sink Node ,  Aggregation Techniques ,  Policy Gradient Method ,  Relay Nodes ,  Information Packets ,  Optimality Equation ,  Path Nodes ,  Data Transmission ,  Network Flow "
Distributed QoS routing algorithm in large scale Wireless Sensor Networks,https://ieeexplore.ieee.org/document/6237195/,3,Conference Paper,IEEE,2012,"This paper presents a novel routing protocol based on the Learning Automata method for large scale Wireless Sensor Networks (WSNs) codenamed DRLR (distributed reinforcement learning routing). In this method, each node is equipped with learning automata so that it can learn the best path to transmit data toward the sink. The approach proved to be efficient, reliable, and scalable. It also prevents routing hole by considering network density and average of energy levels available. The approach also increases network lifetime by balancing energy consumption. We compared our approach to two other methods (MMSPEED and EESPEED) and the simulation results show our algorithm to better meet end-to-end delay and reliability requirements and to improve network lifetime more.","Sensor Networks ,  Wireless Sensor Networks ,  Routing Algorithm ,  Scalable ,  Dense Network ,  Network Lifetime ,  Self-organization ,  Global Positioning System ,  Data Packets ,  Energy Parameters ,  Selection Phase ,  Residual Energy ,  Network Load ,  Routing Decisions ,  Routing Table ,  Packet Forwarding ,  Routing Approach "
Latency filtering for Q-routing on wireless networks,https://ieeexplore.ieee.org/document/9498737/,0,Conference Paper,IEEE,2021,"Q-routing is inspired by Q-learning, a reinforcement learning algorithm. Originally, it uses latency as routing metric. But, latency can be difficult to estimate especially in a noisy wireless environment. In this paper, we propose to filter the latency measure with a moving average, in order to improve the quality of service metrics such as packet delivery ratio and average delay. We compare our modification to the original Q-routing and use OLSRv2 as reference routing protocol. We observe an improvement of the average delivery time on a wireless grid of 3 % compared to the original Q-routing. On our mobility scenario, the number of routes changes is at least twice lower (from 6 to 3 route changes between the two approaches in this scenario). The gain on QoS metrics depends mainly on the speed of the nodes. These improvements are obtained without making Q-routing more complex as a moving average is added. We provide all the materials to conduct reproducible research on our public git repository.","Wireless Networks ,  Service Quality ,  Latency Measures ,  Mobility Scenarios ,  Packet Delivery Ratio ,  Learning Rate ,  Shortest Path ,  Simulated Networks ,  Wireless Sensor Networks ,  Application Layer ,  Toy Example ,  Ad Hoc Networks ,  Greedy Strategy ,  High Load Condition ,  Change In The Average Number "
