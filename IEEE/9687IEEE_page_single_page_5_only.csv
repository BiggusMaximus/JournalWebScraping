title,link,number_of_citation,article_type,publisher,publication_date,abstract,keyword
SSDWSN: A Scalable Software-Defined Wireless Sensor Networks,https://ieeexplore.ieee.org/document/10422802/,0,Journal Article,IEEE,2024,"In multi-hop wireless sensor networks (WSNs), sensors operate autonomously and make routing decisions independently. However, these devices are often located in remote or inaccessible areas and have limited energy and memory resources. As the network scales, efficient management to conserve resources and extend its lifetime becomes increasingly challenging. Software-defined WSNs (SDWSNs) offer a solution by enabling centralized control of low-power WSNs. However, continuously updating the controller with the network state generates significant traffic, resulting in energy loss, increased overhead, and reduced scalability and network lifetime. This study proposes a scalable SDWSN framework (SSDWSN) to address these challenges. The proposed approach focuses on scheduling, balanced routing, aggregation, and reducing traffic overhead caused by periodic network state updates to the controller. This paper presents the architecture of the proposed framework, along with the Deep Reinforcement Learning (DRL) agent. It also proposes two Proximal Policy Optimization (PPO)-based learning policies, namely PPO-ATCP and PPO-NSFP. These policies are designed to efficiently utilize SDWSN network resources and accurately predict the network state by continuously monitoring the synchronized network state within the controller, taking appropriate actions, and updating the learning parameters based on reward functions. The simulation results demonstrate the effectiveness of PPO-ATCP and PPO-NSFP in reducing controller-bound traffic overhead by 57% and 85%, respectively, while improving energy efficiency by 28% and 53% in SDWSNs. Additionally, PPO-NSFP achieved a minimum accuracy of 85% in network state prediction under different network-size scenarios.","Scalable ,  Wireless Sensor ,  Wireless Sensor Networks ,  Software-defined Wireless Sensor Networks ,  Energy Source ,  Deep Learning ,  Energy Efficiency ,  Utilization Efficiency ,  Network State ,  Optimal Policy ,  Network Resources ,  Reward Function ,  Deep Reinforcement Learning ,  Improve Energy Efficiency ,  Policy Learning ,  Memory Resources ,  Network Lifetime ,  Proximal Policy Optimization ,  Deep Reinforcement Learning Agent ,  Energy Consumption ,  Sink Node ,  Traffic Congestion ,  Received Signal Strength Indicator ,  Global Status ,  Global View ,  Network Size ,  Network Energy ,  Traffic Conditions ,  Network Energy Consumption ,  Residual Energy "
Modeling and Performance Optimization of Wireless Sensor Network Based on Markov Chain,https://ieeexplore.ieee.org/document/9274491/,1,Journal Article,IEEE,2021,"Wireless sensor networks are usually deployed in areas with relatively harsh natural environments, and the collection node transmits data to the destination node through a multi-hop route. Therefore, how to effectively plan the transmission path is an important issue. This paper combines the unbiased gray model with the Markov chain model to establish an unbiased gray Markov chain model, and points out that the unbiased gray Markov chain model also has shortcomings in parameter selection. The particle swarm algorithm is used to improve it, and the mathematical model, calculation principle and various parameters of the particle swarm optimization algorithm are introduced, and the implementation flow chart of the particle swarm algorithm is given. Aiming at the shortcomings of the unbiased gray Markov chain model, the particle swarm algorithm and the unbiased gray Markov chain model are combined to form the particle swarm unbiased gray Markov chain model. The simulation environment and the training environment of the particle swarm unbiased grey Markov chain model were designed in the experiment. The node scheduling optimization experiment proves that the scheduling method based on the particle swarm unbiased grey Markov chain model has achieved better results in coverage and energy consumption balance than the random and shortest distance method. In the routing experiment, the experimental analysis of the node’s Q value proved the convergence of the algorithm, and compared with other protocols, it proved that the routing algorithm can effectively extend the network life cycle and achieve load balancing.","Wireless Sensor Networks ,  Energy Consumption ,  Optimization Algorithm ,  Particle Swarm ,  Shortest Distance ,  Particle Swarm Optimization ,  Optimization Experiments ,  Flowchart Of Algorithm ,  Grey Model ,  Scheduling Method ,  Routing Algorithm ,  Unbiased Model ,  Particle Swarm Algorithm ,  Hierarchical Structure ,  Forecasting ,  Simulation Experiments ,  Random Selection ,  Data Transmission ,  Wireless Networks ,  State Value ,  Particle Position ,  Residues In Sequence ,  Real-time Object ,  Reinforcement Learning Algorithm ,  Cluster Head ,  Deep Q-network ,  Ant Colony ,  Entire Network ,  Greater Volatility ,  Flight Speed "
RCAR: A Reinforcement-Learning-Based Routing Protocol for Congestion-Avoided Underwater Acoustic Sensor Networks,https://ieeexplore.ieee.org/document/8782596/,77,Journal Article,IEEE,2019,"Underwater acoustic sensor networks (UASNs) have attracted much attention due to various aquatic applications. However, UASNs have many specific characteristics, such as high propagation delay, high packet error rate, and low bandwidth, which bring challenges to network congestion control. Furthermore, the point-to-point congestion control algorithms cannot guarantee the end-to-end optimal performance. Therefore, congestion avoidance is an important issue to be considered when designing routing protocols for UASNs. In addition, since the sensor nodes deployed underwater are powered by batteries, which are hard to be replaced or recharged, energy limitation should be taken into account as well. In this paper, we propose a reinforcement-learning-based congestion-avoided routing (RCAR) protocol to reduce the end-to-end delay and energy consumption. With the application of reinforcement learning, the protocol converges to the optimal route from the source node to the surface sink by exploring hop-by-hop. In RCAR, a reward function in reinforcement learning is defined in which congestion and energy are both considered for adequate routing decision. To accelerate the convergence of the algorithm, we introduce a dynamic virtual routing pipe with variable radius, which is related to the average residual energy of the neighbors of the sender node. Moreover, in the cross-layer-information-based RCAR protocol, an information update method based on a handshake in the MAC layer is proposed, which guarantees the optimal routing decision. The simulation results show that the proposed RCAR protocol outperforms hop-by-hop vector-based forwarding protocol (HHVBF), QELAR, and GEDAR in terms of convergence speed, energy efficiency, and end-to-end delay.","Sensor Networks ,  Acoustic Networks ,  Energy Consumption ,  Energy Efficiency ,  Average Energy ,  Neighboring Nodes ,  Bit Error Rate ,  Pathfinding ,  Reward Function ,  Source Node ,  Propagation Delay ,  Residual Energy ,  Dynamic Routing ,  Routing Decisions ,  Application Of Reinforcement Learning ,  Variable Radius ,  Information Exchange ,  Local Information ,  Dense Network ,  Energy Distribution ,  Sink Node ,  Packet Forwarding ,  Communication Range ,  Packet Delivery Ratio ,  Optimal Policy ,  Packet Transmission ,  Constant Cost ,  Initiation Phase ,  Undersea ,  Buffer State "
Network-Lifetime Maximization of Wireless Sensor Networks,https://ieeexplore.ieee.org/document/7322190/,45,Journal Article,IEEE,2015,"Network lifetime (NL) maximization techniques have attracted a lot of research attention owing to their importance for extending the duration of the operations in the battery-constrained wireless sensor networks (WSNs). In this paper, we consider a two-stage NL maximization technique conceived for a fully-connected WSN, where the NL is strictly dependent on the source node's (SN) battery level, since we can transmit information generated at the SN to the destination node (DN) via alternative routes, each having a specific route lifetime (RL) value. During the first stage, the RL of the alternative routes spanning from the SN to the DN is evaluated, where the RL is defined as the earliest time, at which a sensor node lying in the route fully drains its battery charge. The second stage involves the summation of these RL values, until the SN's battery is fully depleted, which constitutes the lifetime of the WSN considered. Each alternative route is evaluated using cross-layer optimization of the power allocation, scheduling and routing operations for the sake of NL maximization for a predetermined per-link target signal-to-interference-plus-noise ratio values. Therefore, we propose the optimal but excessive-complexity algorithm, namely, the exhaustive search algorithm (ESA) and a near-optimal single objective genetic algorithm (SOGA) exhibiting a reduced complexity in a fully connected WSN. We demonstrate that in a high-complexity WSN, the SOGA is capable of approaching the ESA's NL within a tiny margin of 3.02% at a 2.56 times reduced complexity. We also show that our NL maximization approach is powerful in terms of prolonging the NL while striking a tradeoff between the NL and the quality of service requirements.","Sensor Networks ,  Wireless Sensor Networks ,  Optimization Algorithm ,  Service Quality ,  Alternative Route ,  Battery Charging ,  Specific Routes ,  Quality Of Service Requirements ,  Network Lifetime ,  Battery Level ,  Exhaustive Search Algorithm ,  Computational Complexity ,  Low Complexity ,  Random Selection ,  Network Topology ,  Additive Noise ,  Bit Error Rate ,  Bit Error ,  Candidate Solutions ,  Battery Capacity ,  Distinct Routes ,  Signal-to-interference-plus-noise Ratio ,  Quadrature Phase Shift Keying ,  Crossover Operator ,  Genetic Operators ,  Route Selection ,  Transmission Phase ,  Single Route ,  Routing Information ,  Routing Algorithm "
Optimal Route Selection in 5G-based Smart Health-care Network: A Reinforcement Learning Approach,https://ieeexplore.ieee.org/document/9609815/,2,Conference Paper,IEEE,2021,"Smart health-care is the most promising application of the next-generation 5G wireless network. Because of low latency and high data rate, many applications with high resources are supporting 5G, including smart health-care application. In smart health-care, medical sensors exchange data to establish a network. However, the mobility of nodes and density changes the network topology usually. Medical sensor nodes have limited energy, which is used for transmission and receiving of data. In this paper, an idea of selection of route is distinguished by taking into account of stability and higher residual energy in 5G-based smart health-care network to decrease energy consumption along with links disconnection and improve network lifetime. For this purpose, we present reinforcement learning-based algorithm and investigate the effect of various learning rates on energy consumption, links disconnection and network lifetime in smart health-care network.","Pathfinding ,  Reinforcement Learning Approach ,  Route Selection ,  Smart Healthcare ,  Optimal Route Selection ,  Energy Consumption ,  Learning Rate ,  Network Topology ,  Wireless Networks ,  Decreased Energy Expenditure ,  Residual Energy ,  Mobile Nodes ,  Network Lifetime ,  Service Quality ,  Small Cell ,  Dense Network ,  Data Transmission ,  Neighboring Nodes ,  Energy Model ,  Higher Learning Rate ,  Destination Node ,  Routing Scheme ,  Broken Links ,  Communication Nodes ,  Source Node ,  Selection Decisions ,  Node Selection ,  Time Nodes ,  Transmission Circuit "
A Routing Algorithm for Underwater Acoustic– Optical Hybrid Wireless Sensor Networks Based on Intelligent Ant Colony Optimization and Energy-Flexible Global Optimal Path Selection,https://ieeexplore.ieee.org/document/10502320/,0,Journal Article,IEEE,2024,"Due to the increasing demand for oceanic exploration, routing algorithms in underwater wireless sensor networks (UWSNs) have garnered widespread research interest. However, the majority of current routing algorithms only use a single transmission medium and consider the information from merely one or two hops when selecting relay nodes, thereby attaining limited achievement of globally optimal path selection. To address these issues, in this article, we propose a routing algorithm for underwater acoustic–optical hybrid wireless sensor networks based on intelligent ant colony optimization and energy-flexible (IAEF) global optimal path selection. Given the diverse energy-consumption characteristics of acoustic and optical waves, the proposed IAEF algorithm uses acoustic waves in seeking optimal path and optical waves in delivering data packets. In contrast to other routing algorithms based on ant colony techniques, the proposed IAEF algorithm enables source nodes to select the optimal path for data transmission with the heuristic factor updated according to a comprehensive consideration on remained energy and transmission deviation angle. Considering the limited energy in networks, the proposed IAEF algorithm designs an energy classification network update mechanism with flexible cycles, which enables network updates according to an adjustable energy threshold for the nodes along the optimal path. In addition, a protection period is implemented to prevent excessive network updates to improve packet delivery rate (PDR) and network lifetime. Simulation results exhibit that the proposed IAEF algorithm can obtain up to about 37% and 78% improvements in PDR and network lifetime when compared with the classical routing algorithms adopted in the simulations.","Optical Sensors ,  Optimal Selection ,  Sensor Networks ,  Ant Colony ,  Optimal Path ,  Wireless Sensor Networks ,  Ant Colony Optimization ,  Optical Networks ,  Routing Algorithm ,  Path Selection ,  Intelligent Optimization ,  Global Path ,  Optical Hybrid ,  Optimal Path Selection ,  Global Optimal Path ,  Data Transmission ,  Acoustic Waves ,  Angle Difference ,  Data Packets ,  Source Node ,  Network Energy ,  Energy Consumption ,  Multi-agent Reinforcement Learning ,  Periodic Updates ,  Undersea ,  Residual Energy ,  Reduce Energy Consumption ,  Acoustic Sensors ,  Sink Node ,  Energy Of Nodes "
Reinforcement Learning Framework for Delay Sensitive Energy Harvesting Wireless Sensor Networks,https://ieeexplore.ieee.org/document/9292079/,9,Journal Article,IEEE,2021,"A multi-hop energy harvesting wireless sensor network (EH-WSNs) is a key enabler for future communication systems such as the internet-of-things. Optimal power management and routing selection are important for the operation and successful deployment of EH-WSNs. Characterizing the optimal policies increases significantly with the number of nodes in the network. In this paper, optimal control policy is devised based on minimum-delay transmission in a multi-hop EH-WSN using reinforcement learning (RL). The WSN consists of M EH sensor nodes aiming to transmit their data to a sink node with a minimum delay. Each sensor node is equipped with a battery of limited capacity to save the harvested energy and a data buffer of limited size to store both the sensed and relayed data from neighboring nodes. Centralized and distributed RL algorithms are considered for EH-WSNs. In the centralized RL algorithm the control action is taken at a central unit using the state information of all sensor nodes. In the distributed RL algorithm the control action is taken locally at each sensor node using its state of information and the state information of neighboring nodes. The proposed RL algorithms are based on the state-action-reward-state-action (SARSA) algorithm. Simulation results demonstrate the merits of the proposed algorithms.","Energy Harvesting ,  Wireless Sensor ,  Wireless Sensor Networks ,  Reinforcement Learning Framework ,  Energy Harvesting Wireless Sensor ,  Optimal Control ,  Central Unit ,  Optimal Policy ,  Neighboring Nodes ,  Optimal Power ,  Reinforcement Learning Algorithm ,  Node Information ,  Minimum Delay ,  Route Selection ,  Sink Node ,  Optimal Control Policy ,  Resource Allocation ,  State Space ,  Linear Approximation ,  Time Slot ,  Multi-agent Reinforcement Learning ,  Average Reward ,  Feasibility Constraints ,  Greedy Policy ,  Buffering Capacity ,  Reward Function ,  Number Of Sensor Nodes ,  Markov Decision Process ,  Optimal Power Allocation ,  Buffer State "
An energy efficient topology control scheme with connectivity learning in wireless networks,https://ieeexplore.ieee.org/document/6968247/,3,Conference Paper,IEEE,2014,"In wireless networks, due to the variation in environmental and link characteristics, the network topology will change over time. The foremost feature that affects the connectivity and lifetime of a network is the distributed topology control. Nodes in a wireless network are resource constrained. Topology control algorithms should be helpful to improve the energy utilization, reduce interference between nodes and extend lifetime of the networks operating on battery power. This paper proposes a topology control and maintenance scheme while learning the network link characteristics. The system learns the varying network link characteristics using reinforcement learning technique and gives an optimal choice of paths to be followed for packet forwarding. The algorithm calculates the number of neighbors a node can have, which helps to reduce power consumption and interference effects. The algorithm also ensures strong connectivity in the network so that reachability between any two nodes in the network is guaranteed. Analysis and simulation results illustrate the correctness and effectiveness of our proposed algorithm.","Energy Efficiency ,  Wireless Networks ,  Topology Control ,  Learning In Wireless Networks ,  Strong Connection ,  Network Topology ,  Interference Effect ,  Battery Power ,  Energy Utilization ,  Reinforcement Learning Techniques ,  Network Lifetime ,  Dynamic Network ,  Network Size ,  Simulation Environment ,  Sensor Networks ,  Node Status ,  Neighboring Nodes ,  Communication Cost ,  Wireless Sensor Networks ,  Node Selection ,  Sparse Graph ,  Neighbor List ,  Packet Delivery Ratio ,  Sink Node ,  Node Deployment ,  Random Topology ,  Energy Of Nodes ,  Average Node Degree ,  Minimum Total Cost ,  Wireless Communication Networks "
Reinforcement Learning for Delay Tolerance and Energy Saving in Mobile Wireless Sensor Networks,https://ieeexplore.ieee.org/document/10049537/,5,Journal Article,IEEE,2023,"Reinforcement Learning (RL) has emerged as a promising approach for improving the performance of Wireless Sensor Networks (WSNs). The Q-learning technique is one approach of RL in which the algorithm continuously learns by interacting with the environment, gathering information to take certain actions. It maximizes performance by determining the optimal result from that environment. In this paper, we propose a data gathering algorithm based on a Q-learning approach named Bounded Hop Count - Reinforcement Learning Algorithm (BHC-RLA). The proposed algorithm uses a reward function to select a set of Cluster Heads (CHs) to balance between the energy-saving and data-gathering latency of a mobile Base Station (BS). In particular, the proposed algorithm selects groups of CHs to receive sensing data of cluster nodes within a bounded hop count and forward the data to the mobile BS when it arrives. In addition, the CHs are selected to minimize the BS tour length. Extensive experiments by simulation were conducted to evaluate the performance of the proposed algorithm against another traditional heuristic algorithm. We demonstrate that the proposed algorithm outperforms the existing work in the mean of the length of a mobile BS tour and a network’s lifetime.","Sensor Networks ,  Wireless Sensor Networks ,  Mobile Wireless Sensor Networks ,  Learning Algorithms ,  Wireless Networks ,  Heuristic Algorithm ,  Reward Function ,  Cluster Nodes ,  Reinforcement Learning Algorithm ,  Data Nodes ,  Mobile Base Stations ,  Hop Count ,  Energy Consumption ,  Maximum Distance ,  Line Segment ,  Parts Of The Tree ,  Residual Energy ,  Set Of Sensors ,  Transmission Range ,  Nearest Neighbor Algorithm ,  Network Lifetime ,  Number Of Sensor Nodes ,  Routing Path ,  Subset Of Nodes ,  Star Symbol ,  Algorithm In This Paper ,  Merging Clusters ,  Relay Nodes ,  Maximum Reward "
A Novel QoS-Awared Grid Routing Protocol in the Sensing Layer of Internet of Vehicles Based on Reinforcement Learning,https://ieeexplore.ieee.org/document/8938706/,7,Journal Article,IEEE,2019,munication and Fog/Edge Computing Towards Intelligent Connected Vehicles (ICVs),"Internet Of Vehicles ,  Service Quality ,  Complex Environment ,  Network Topology ,  Wireless Networks ,  Sensor Networks ,  High-quality Services ,  Wireless Sensor ,  Wireless Sensor Networks ,  Grid Nodes ,  Highest Reliability ,  Energy Consumption ,  Election ,  Energy Levels ,  Dynamic Environment ,  Additive Noise ,  Grid Size ,  Real-time Information ,  Heterogeneous Network ,  Node Positions ,  Network Lifetime ,  State Transition Function ,  Network Delay ,  Data Delivery ,  Routing Algorithm ,  Video Information ,  Sink Node ,  Node Information ,  Geolocated ,  Artificial Intelligence Techniques "
The Detection Scheme Against Selective Forwarding of Smart Malicious Nodes With Reinforcement Learning in Wireless Sensor Networks,https://ieeexplore.ieee.org/document/9777986/,7,Journal Article,IEEE,2022,"Wireless sensor networks (WSNs) are extremely vulnerable to different attacks because of open communication, and distribution in unattended areas. The selective forwarding attack is one of the most difficult inside attacks to be detected for two reasons. The node in a harsh environment has to drop some data packets, and the smart malicious node frequently eludes detection. In this paper, we model a selective forwarding attack of smart malicious nodes with a reinforcement learning (RL) algorithm. To effectively detect the selective forwarding attack under a harsh environment, we design the double-threshold density peaks clustering (DT-DPC) algorithm. Abnormal nodes are identified as malicious and isolated owing to continuous abnormalities. Suspicious nodes are determined by the neighbor voting method because malicious behaviors show up separately and a harsh environment universally disturbs agglomerate nodes. Even if smart malicious nodes elude the detection by an RL algorithm, DT-DPC improves the network throughput. The simulation results show that DT-DPC has a low false detection rate (FDR) of around 1% and a missed detection rate (MDR) of around 10%. The network throughput increases by about 4% under a harsh environment.","Detection Scheme ,  Wireless Sensor Networks ,  Malicious Nodes ,  Selective Forwarding ,  Simulation Results ,  Learning Algorithms ,  Clustering Algorithm ,  Harsh Environments ,  Data Packets ,  Reinforcement Learning Algorithm ,  Network Throughput ,  False Detection Rate ,  Malicious Behavior ,  Uniform Distribution ,  Detection Results ,  Game Theory ,  Cluster Centers ,  Neighboring Nodes ,  Markov Decision Process ,  Accuracy Metrics ,  Forward Rate ,  Normal Nodes ,  Behavior Of Nodes ,  Noise Points ,  Cluster Nodes ,  Packet Loss ,  Network Lifetime ,  Residual Energy ,  Relay Selection ,  Purple Bars "
A Double Q-Learning Routing in Delay Tolerant Networks,https://ieeexplore.ieee.org/document/8761526/,20,Conference Paper,IEEE,2019,"Delay tolerant networks (DTNs) are wireless mobile networks, where the nodes are sparse and end-to-end connectivity is rare. The intermittent connectivity in DTNs makes it challenging to efficiently deliver messages. Research results have shown that the routing protocol based on reinforcement learning can achieve a reasonable balance between routing performance and cost. However, how to predict the next hop of messages more accurately is still open. In this paper, Double Q-Learning Routing (DQLR) protocol is proposed, which investigates the routing selection of the next hop in a distributed manner and solves the overestimation problem by Double Q-Learning algorithm. Further, the intermediate value and dynamic reward mechanisms are proposed to adapt node mobility and network topology change, which improve the network performance. The simulation results show that DQLR protocol can increase the delivery ratio with a low overhead.","Double Q-learning ,  Delay Tolerant Network ,  Dynamic Mechanism ,  Mediated Mechanism ,  Distributed Manner ,  Mobile Nodes ,  Q-learning Algorithm ,  Delivery Ratio ,  Changes In Network Topology ,  Learning Rate ,  Value Function ,  Sensor Networks ,  Informal Learning ,  Neighboring Nodes ,  Network Environment ,  Markov Decision Process ,  Reinforcement Learning Algorithm ,  Node Attributes ,  Movement Model ,  Ad Hoc Networks ,  Current Node ,  Delivery Delay ,  Network Routing ,  Routing Algorithm ,  Learning Rate Parameter ,  Destination Node ,  Hop Count ,  Actual Reward "
DQQS: Deep Reinforcement Learning-Based Technique for Enhancing Security and Performance in SDN-IoT Environments,https://ieeexplore.ieee.org/document/10506479/,0,Journal Article,IEEE,2024,"The Internet of Things (IoT) is an emerging technology that allow smart devices to communicate through various heterogeneous channels (wired or wireless). However, for conventional networks, it has become a challenging task to efficiently control and manage the data flows of a huge number of devices. Software-defined networking (SDN) is a new way of thinking about networking. Because it is programmable, flexible, agile, and gives you a big picture of the network, it has tried to solve some IoT problems, like scalability, heterogeneity, and complexity. In large-scale SDN-IoT networks, there is a requirement for routing protocols that are both efficient and secure in order to ensure a superior level of quality of service (QoS) and quality of experience (QoE). To address the above stated challenges, a novel deep reinforcement learning (DRL) known as DQQS model is proposed. The aim is to achieve QoS and QoE while also ensuring the security of the SDN-IoT network. The proposed DQQS model dynamically extracts patterns from the past network history by interacting with the underlying network and generating optimized routing policies. This article employs three network metrics—throughput, latency, and the probability of avoiding malicious nodes—to measure the performance of DQQS. Simulations reveal that the proposed framework outperforms four state-of-the-art routing algorithms: OSPF, L-L Routing, Sailfish Routing, and RL-Routing in terms of both throughput and latency. For instance, in an attacked environment, the proposed DQQS model achieved the highest throughput value of 14.5 Mbps, surpassing OSPF at 8 Mbps, L-L at 8.2 Mbps, Sailfish at 9 Mbps, and RL at 9.5 Mbps. Similarly, this model exhibited superior performance in latency, recording the lowest latency value of 52 ms, compared to OSPF 88 ms, L-L 85 ms, Sailfish 72 ms, and RL 75 ms routing algorithms. The experimental results demonstrate that this new DQQS model is a pioneering deep reinforcement learning-based techni...","Deep Learning ,  Service Quality ,  Internet Of Things ,  Network Performance ,  Quality Of Experience ,  Pathfinding ,  Deep Reinforcement Learning ,  Network Metrics ,  Routing Algorithm ,  Malicious Nodes ,  Convolutional Neural Network ,  Learning Curve ,  Deep Learning Models ,  Actor Network ,  Security Threats ,  Internet Of Things Devices ,  Data Layers ,  Severe Attacks ,  Denial Of Service ,  Critic Network ,  Distributed Denial Of Service ,  Deep Reinforcement Learning Agent ,  Packet Loss Rate ,  Security Attacks ,  Control Plane ,  Deep Reinforcement Learning Techniques ,  Man-in-the-middle ,  Network Latency ,  Flow Table ,  Network Congestion "
Reinforcement Learning Based Channel Selection for Design of Routing Protocol in Cognitive Radio Network,https://ieeexplore.ieee.org/document/9031024/,3,Conference Paper,IEEE,2019,"Cognitive Radio Network (CRN) is a next generation of wireless communication technology for efficient spectrum utilization. A cognitive Radio (CR) is able to recognize the idle spectrum. It solves the problem of spectrum scarcity in CRN. Due to intermittent channel usage by Primary Users (PUs), it is difficult to perform routing task in CRN. We are proposing a solution for optimal channel selection and routing in Cognitive Radio Network. Due to uncertainty in the number of active users, Monte Carlo method is performed for probabilistic outcome. During spectrum access process, Reinforcement Learning (RL) is applied to select best frequency band for routing. From the Simulation results, it is observed that the proposed routing protocol outperform in terms of throughput, packet delivery ratio, delay, dropping ratio & jitter compared to the routing protocol without machine learning assisted routing decision.","Channel Selection ,  Cognitive Networks ,  Cognitive Radio ,  Routing Protocol Design ,  Throughput ,  Monte Carlo Simulation ,  Frequency Band ,  Wireless Technologies ,  Frequency Selectivity ,  Unlicensed Spectrum ,  Number Of Uncertainties ,  Packet Delivery Ratio ,  Performance Metrics ,  Ratio Of The Number ,  Network Performance ,  Simulation Parameters ,  Channel State ,  Policy Evaluation ,  Data Packets ,  Source Node ,  Reinforcement Learning Model ,  Packet Loss Rate ,  Policy Improvement ,  Stable Channel ,  Near Field Communication ,  Wireless Environment ,  Federal Communications Commission "
A Survey on the Development of Wireless Sensor Network Challenges Using ML Algorithms,https://ieeexplore.ieee.org/document/10452252/,0,Conference Paper,IEEE,2023,"A wireless sensor network is a network that consists of a number of sensor nodes that are used to communicate wirelessly. These nodes are used to continuously monitor changes in the environment in a sensing area that are due to external factors, system design hardware, etc. Due to the limited power of wireless sensor networks and the constantly shifting topology of the network, attempts Common techniques for security, such as cryptography and key management, are useless. Machine learning(ML) algorithms can combine surveillance and intelligence-based decisions to deliver safety measures in this kind of system are one of the suggested methods. This information is given to a central processing area, which is a base station connected to the internet, through which a user can observe. WSN is a network that is an enabler for IOT Technology. In this review paper, we analyze over a two-decade time period in WSN issues or challenges faced, which can be reduced using different algorithms of machine learning. In this survey paper, some of the issues faced by WSN are Security, Routing, Clustering, Localization, Fault detection, Medium Access Control (MAC) protocols, etc., so by using ML algorithms, they are evaluated against the corresponding problems. Thus, this review paper provides an overall idea of ML algorithms for different issues faced by WSN.","Learning Algorithms ,  Wireless Sensor ,  Wireless Sensor Networks ,  Machine Learning ,  Review Paper ,  Wireless Networks ,  Base Station ,  Paper Surveys ,  Medium Access Control ,  Energy Efficiency ,  Machine Learning Methods ,  Aggregate Data ,  K-nearest Neighbor ,  E-learning ,  Function Of Problem ,  Late 1950s ,  Use Of Machine Learning ,  Object Tracking ,  Machine Learning Technology ,  Network Congestion ,  Machine Learning Strategies ,  Sink Node "
CDEIR: Intelligent Routing for Efficient Wireless Sensor Networks Using BUG Algorithm,https://ieeexplore.ieee.org/document/10182238/,2,Journal Article,IEEE,2023,"Wireless Sensor Networks (WSNs) are used to monitor specific areas of the environment by networking multiple sensors and collecting data for analysis. However, due to limited processing capabilities, the collected data needs to be transmitted to a Base Station (BS) that has high computational power and storage capacity. As SNs are not directly connected to the BS, multihop data transmissions through other SNs are required to reach the BS, which leads to congestion and additional energy consumption. To address these challenges, we propose a novel algorithm called Congestion, Delay, Energy-aware Intelligent Routing (CDEIR) using the BUG algorithm. The CDEIR approach identifies congested nodes using a Directed Spanning Tree and avoids traffic through them by paving an alternate path. This approach minimizes delay and optimizes energy consumption while avoiding congestion, all within a short computational time. We demonstrate the effectiveness of the CDEIR approach through theoretical analyses and simulations.","Wireless Sensor Networks ,  Intelligent Routing ,  Bug Algorithm ,  Energy Consumption ,  Data Transmission ,  Base Station ,  Spanning Tree ,  Energy Efficiency ,  Recurrent Neural Network ,  Shortest Path ,  Network Changes ,  Neighboring Nodes ,  Reduce Energy Consumption ,  Pathfinding ,  Leaf Node ,  Deep Reinforcement Learning ,  Data Packets ,  Efficient Route ,  Network Throughput ,  Division By Zero ,  Routing Algorithm ,  Hop Count ,  Node Weights ,  Number Of Sensor Nodes ,  Ant Colony Optimization Algorithm ,  Running Example ,  Routing Path ,  Clustering Algorithm ,  Worst Case ,  Energy Availability "
Pheromone-based in-network processing for wireless sensor network monitoring systems,https://ieeexplore.ieee.org/document/6364847/,5,Conference Paper,IEEE,2012,"Monitoring spatio-temporal continuous fields using wireless sensor networks has emerged as a novel and efficient solution. The development of energy efficient query dissemination and data collection algorithms for environments where only a small subset of nodes has relevant readings is a challenging problem if no information about the location of these nodes is available. Monitoring these data requires not only an initial discovery but also a continuous search for new relevant data due to field variations in time. One solution to this problem is to let nodes cooperate and decide jointly which data are relevant and their location. Trails to relevant data can be distributively marked as insect colonies do using pheromone-based schemes. In this work, we propose PhINP, a probabilistic pheromone-based in-network processing scheme to monitor information on WSNs. Our proposal takes advantage of both query-based innetwork filtering to select nodes to answer, and a pheromone-based strategy to direct queries towards nodes with relevant readings. Additionally, nodes use reinforcement learning to improve the routing performance of queries. We demonstrate by extensive simulations that the routing cost can be reduced by approximately 70% over flooding with an error below 1%.","Sensor Networks ,  Wireless Sensor Networks ,  In-network Processing ,  Node Positions ,  Subset Of Nodes ,  Random Walk ,  Network Size ,  Hybrid Approach ,  Ant Colony ,  Adaptive Filter ,  Failure Conditions ,  Packet Loss ,  Sensor Readings ,  Dynamic Threshold ,  Error Cost ,  Routing Algorithm ,  Node Failure ,  Sink Node ,  Relevant Nodes ,  Routing Mechanism ,  Static Threshold "
An Effectual Secure Cryptography Scheme for Multipath Routing in A Wsn-Based IoT Environment,https://ieeexplore.ieee.org/document/9888604/,2,Conference Paper,IEEE,2022,"Internet of Things (IoT) provides dependable with impeccable data transmission for the heterogeneous Wireless Sensor Network (WSN). Maximum of the WSN based routing protocols are remain exposed to specific problems concerning packet delivery ratio and delay. This work establishes a security algorithm (SA) for WSN’s IoT networks. At first, the built network includes optimization-related deep learning for route introduction. After this, the ClonQlearn-related SA will be applied to enhance the security that is centered upon an ECC algorithm which combines the process of data encryption and decryption mainly for random key generation. The proffered security approach includes reinforcement learning based ClonQlearn incorporated with ECC (ClonQlearn+ECC). This proffered approach shows secure data transition with enhanced network execution while correlated with the previous studies in simulation.","Internet Of Things ,  Multipath Routing ,  Data Transmission ,  Heterogeneous Network ,  Wireless Sensor Networks ,  Internet Of Things Networks ,  Encryption And Decryption ,  Packet Delivery ,  Packet Delivery Ratio ,  Throughput ,  Internet Of Things Devices ,  Radio Frequency Identification ,  Optimal Path ,  Secret Key ,  Public Key ,  Power Utility ,  Cloning Procedures ,  Ad Hoc Networks ,  Man-in-the-middle ,  Vehicular Ad Hoc Networks "
WLARS: Workload-Aware Recharge Scheduling Mechanism for Improving Surveillance Quality in Wireless Rechargeable Sensor Networks,https://ieeexplore.ieee.org/document/10103824/,1,Journal Article,IEEE,2023,"With radio frequency (RF), the mobile charger (MC) can wirelessly transmit energy to the sensor nodes in the network. The wireless energy transfer enhances the lifetime of sensor nodes in wireless rechargeable sensor networks (WRSNs). Most of the studies improved the efficiency of MC or perpetuated the lifetime of WRSNs. At the same time, none of the studies focused on considering the spatial and temporal surveillance qualities (STSQs) of each sensor recharged. Therefore, this article proposed an efficient energy recharge scheduling for MC, aiming to maximize the STSQ of the given network. Initially, sensor routing load (RL) is considered to partition the network to distribute the charging load of the MCs evenly. Second, the busy level of the MC is considered to send the recharging requests to the MC. Based on the busy level of MC, the sensors adjust the sensing rate frequency to manage their energy. Finally, cooperation between the neighboring MCs is proposed to reduce the waiting time for recharging requested sensors. The simulation results present that the proposed work yields the literature in terms of STSQ, traveling distance, average waiting time (AWT), and energy usage efficiency.","Sensor Networks ,  Wireless Sensor ,  Wireless Sensor Networks ,  Quality Surveillance ,  Wireless Rechargeable Sensor Networks ,  Rechargeable Sensor ,  Spatial Features ,  Temporal Features ,  Problem Statement ,  Time Slot ,  Spatial Distance ,  Typical Architecture ,  Arrival Rate ,  Scheduling Algorithm ,  Queueing System ,  Sensing Time ,  Boolean Variable ,  Charging Rate ,  Queue Length ,  Prediction Formula ,  Rate Of Sensor ,  Sensor Density ,  Hybrid Mechanism ,  Ant Algorithm ,  Network Planning "
TQOR: Trust-based QoS-oriented routing in cognitive MANETs,https://ieeexplore.ieee.org/document/8171332/,2,Conference Paper,IEEE,2017,"Dynamicity and infrastructure-less nature of MANETs expose the routing in such networks to a variety of attacks, and moreover, make the conventional fixed policy routing algorithms inefficient. To deal with the routing challenges and varying behavior of malicious nodes in such networks, employing reinforcement learning algorithms and proper trust models seem promising. In this paper, we introduce a cognition layer in parallel and interacting with the network layer which comprises two cognitive processes: path learning (routing) and trust learning. The first process is based on machine learning algorithms and the latter is based on trust management. We compare our algorithm, TQOR, with a well known trust-based routing protocol, TQR, in terms of three measures of performance. The simulation results show better end-to-end delay and communication overhead which further improve as time progresses, without sacrificing the data packet delivery ratio.","Ad Hoc Networks ,  Cognitive Processes ,  Learning Algorithms ,  Performance Measures ,  Data Packets ,  Communication Overhead ,  Routing Algorithm ,  Trust Model ,  Delivery Ratio ,  Malicious Nodes ,  Trust Management ,  Behavior Of Nodes ,  Packet Delivery Ratio ,  Service Quality ,  Machine Learning Techniques ,  Network Topology ,  Wireless Networks ,  Calculation Procedure ,  Learning Phase ,  Markov Decision Process ,  Trust Value ,  Reinforcement Learning Methods ,  Cognitive Networks ,  Total Delay ,  Wireless Sensor Networks ,  Source Node ,  Routing Table ,  Control Packets ,  Final Destination ,  Quality Of Service Constraints "
Energy Optimized Route Selection in WSNs for Smart IoT Applications,https://ieeexplore.ieee.org/document/10150824/,0,Conference Paper,IEEE,2023,"Interest in the IoT and smart cities has been growing as people learn about its potential applications in fields as diverse as healthcare, remote monitoring, and transportation. In these Internet of Things (IoT)-based systems, wireless networked sensors (WSNs) gather data critical to the operation of smart surroundings. IoT-enabled WSNs face challenges such high latency, low bandwidth, and short network lifespan due to the copious amounts of data generated by a wide variety of sensors. This study presents a deep reinforcement learning-based efficient routing method for IoT-enabled WSNs to combat latency as well as electricity consumption (DRL). The proposed strategy separates the network into unequal cluster according to the present data transmission existing in the sensors, hence preventing the network from collapsing prematurely. Extensive testing has been performed in ns3 using the recommended strategy. The results of the experiments are contrasted to the state-of-the-art methodologies to demonstrate that the proposed method is effective in the areas in received packets, connectivity latency, clean energy, and the amount of living nodes within a network.","Internet Of Things ,  Pathfinding ,  Internet Of Things Applications ,  Wireless Networks ,  Smart City ,  Deep Reinforcement Learning ,  High Latency ,  Routing Method ,  Energy Consumption ,  Energy Efficiency ,  Cluster Formation ,  Sensor Networks ,  Fuzzy Logic ,  Dependability ,  Markov Decision Process ,  Wireless Sensor Networks ,  Power Outages ,  Mesh Network ,  Ground Station ,  Internet Of Things Networks ,  Percentage Of Nodes ,  Internet Of Things Sensors ,  Routing Algorithm ,  Sink Node ,  Packet Delivery ,  Cluster Radius ,  Home Automation ,  Total Amount Of Data ,  Field Of View ,  Wireless Sensor "
Towards Energy Efficient LPWANs through Learning-based Multi-hop Routing,https://ieeexplore.ieee.org/document/8767193/,13,Conference Paper,IEEE,2019,"Low-power wide area networks (LPWANs) have been identified as one of the top emerging wireless technologies due to their autonomy and wide range of applications. Yet, the limited energy resources of battery-powered sensor nodes is a top constraint, especially in single-hop topologies, where nodes located far from the base station must conduct uplink (UL) communications in high power levels. On this point, multi-hop routings in the UL are starting to gain attention due to their capability of reducing energy consumption by enabling transmissions to closer hops. Nonetheless, a priori identifying energy efficient multi-hop routings is not trivial due to the unpredictable factors affecting the communication links in large LPWAN areas. In this paper, we propose epsilon multi-hop (EMH), a simple reinforcement learning (RL) algorithm based on epsilon-greedy to enable reliable and low consumption LPWAN multi-hop topologies. Results from a real testbed show that multi-hop topologies based on EMH achieve significant energy savings with respect to the default single-hop approach, which are accentuated as the network operation progresses.","Energy Efficiency ,  Low Power Wide Area Networks ,  Multi-hop Routing ,  Energy Consumption ,  Energy Conservation ,  Base Station ,  Communication Links ,  Node Positions ,  Reinforcement Learning Algorithm ,  High Levels Of Power ,  Wide Area Network ,  Service Quality ,  Internet Of Things ,  Wireless Networks ,  Transmission Power ,  Channel State ,  Efficient Route ,  Signal-to-interference-plus-noise Ratio ,  Network Deployment ,  Received Signal Strength Indicator ,  Wireless Module ,  Multi-armed Bandit ,  Multi-hop Communication ,  Link Reliability ,  Star Topology ,  Protocol Stack ,  Network Lifetime ,  Historical Bottlenecks ,  Routing Approach ,  Time Division Multiple Access "
Coding-Aware Routing for Maximum Throughput and Coding Opportunities by Deep Reinforcement Learning in FANET,https://ieeexplore.ieee.org/document/10074889/,1,Conference Paper,IEEE,2022,"Coding-Aware routing algorithm improves the performance of Network Coding (NC) by selecting the paths with more coding opportunities, thus increasing the throughput of network transmission. However, the Unmanned Aerial Vehicle (UAV) flight in Flying Ad-hoc Network (FANET) causes network topology changes and calculating coding opportunities is NP-hard complex problem, so the performance of traditional coding-aware routing is limited. We try to solve this problem using reinforcement learning and propose a deep reinforcement learning-based coding-aware routing (RLCAR) that maximizes throughput and coding opportunities. In RLCAR, we define new concepts of coding benefits, throughput and energy distribution, and we put these parameters into the routing metric (Reward function). We evaluate the performance of RLCAR and compare the throughput, packet delivery ratio (PDR), coding/decoding rate with other coding-aware routings. The results show that RLCAR acquires more coding opportunities and improves the throughput of FANET. And, RLCAR can cope with the dynamic changes of UAV topology.","Deep Reinforcement Learning ,  Network Throughput ,  Flying Ad Hoc Networks ,  Network Topology ,  Energy Distribution ,  Unmanned Aerial Vehicles ,  Reward Function ,  Traditional Routes ,  Routing Algorithm ,  Changes In Network Topology ,  Network Coding ,  Packet Delivery Ratio ,  Energy Consumption ,  Value Function ,  Decoding ,  Data Transmission ,  Network Performance ,  Time Slot ,  Data Streams ,  Unmanned Aerial Vehicles Networks ,  Routing Decisions ,  Wireless Sensor Networks ,  Routing Problem ,  Network Environment ,  Action-value Function ,  Increase In Flow Rate ,  Transmission Performance ,  Flooding Process ,  Routing Model "
Deep Reinforcement Learning for Energy Efficient Routing and Throughput Maximization in Various Networks,https://ieeexplore.ieee.org/document/9987395/,10,Conference Paper,IEEE,2022,"Large bandwidth and more mobility are only two reasons why wireless and mobile networks are fast overtaking wired ones as the preferred mode of connectivity. Heterogeneous networks refer to systems that consist of many independent networks, each of which has its own unique set of protocols and characteristics. Due to their density and complexity, such dense small-cell heterogeneous networks currently consume a lot of power; thus, in order to tackle climate change, we require power information security. A Modified Deep Reinforcement Learning (MDRL) approach may offer an on-demand automated approach with short inference time for NP-hard network communication problems including radio resource distribution, identification, and battery preservation. We examine the DRL algorithm’s applicability to a multi-objective issue. A paradigm for hopeful nonlinear assistance that is founded on the entertainer paradigm and explores repeatedly for potential answers to the multiobjective issue we have given. Throughput and energy savings achieved by our algorithm are equivalent to those of currently used approaches, according to the findings of our tests.","Deep Learning ,  Deep Reinforcement Learning ,  Throughput Maximization ,  Energy Conservation ,  Mobile Network ,  Heterogeneous Network ,  Deep Reinforcement Learning Algorithm ,  Energy Consumption ,  Data Rate ,  Wireless Networks ,  Weight Vector ,  Markov Decision Process ,  Mesh Network ,  Network Throughput ,  Hierarchical Architecture ,  User Equipment ,  Deep Q-network ,  Deep Reinforcement Learning Method ,  Radio Resource Management ,  Deep Reinforcement Learning Techniques "
Work-in-Progress: Q-Learning Based Routing for Transiently Powered Wireless Sensor Network,https://ieeexplore.ieee.org/document/8949903/,0,Conference Paper,IEEE,2019,"Reliable communication is a critical concern in power-limited energy harvesting wireless sensor networks (EH-WSNs). The communication optimization is needed since the protocols in battery-powered WSNs cannot adapt to the intermittent harvestable energy sources. In this paper, a novel reinforcement learning (RL) based routing algorithm that fully exploits the capability of wake-up radio (WuR) is presented. This routing strategy aims at increasing the packet delivery rate by leveraging wake-up radio devices to enable receiver nodes to make the decentralized forwarding decision. Simulation results show that the performance of the proposed learning approach, which requires only limited knowledge of the energy harvesting process, has only a small degradation compared to the optimal routing decision with full knowledge of energy harvesting process.","Wireless Sensor Networks ,  Energy Harvesting ,  Delivery Rate ,  Routing Algorithm ,  Routing Decisions ,  Receiver Node ,  Time Slot ,  Optimal Policy ,  Reward Function ,  Markov Decision Process ,  Greedy Strategy ,  State-action Pair ,  Action-value Function "
