,title,link,number_of_citation,article_type,publisher,publication_date,abstract,keyword
0,RL-based routing in biomedical mobile wireless sensor networks using trust and reputation,https://ieeexplore.ieee.org/document/6328422/,9,Conference Paper,IEEE,2012,"The main function of biomedical sensor network is to guarantee that the data packets from patients can be delivered reliably to the destination node or medical center. Attached to patients, these nodes can be mobile, thus forming a mobile wireless sensor network (mWSN). Moreover, non-cooperative nodes may also be present in the network. This paper therefore proposes a routing method for non-cooperative mWSNs based on Reinforcement Learning (RL). In particular, a reputation and trust scheme to avoid misbehaving nodes was integrated with an existing RL-based routing protocol called RL-QRP. We evaluated its performance in non-cooperative mWSNs under various conditions of non-cooperation and mobility. We found that the proposed method can achieve a success ratio of up to 11% over the RL-QRP, and 25% over a non-learning brute force search threshold method.","Sensor Networks ,  Wireless Sensor ,  Wireless Sensor Networks ,  Mobile Wireless Sensor Networks ,  RL-based Routing ,  Data Packets ,  Destination Node ,  Mobile Sensors ,  Success Ratio ,  Biomedical Sensors ,  Shortest Path ,  Neighboring Nodes ,  Reward Function ,  Secret Sharing ,  Routing Algorithm ,  Routing Scheme ,  Trust Value ,  Mobile Nodes ,  Sink Node ,  Malicious Nodes ,  Number Of Sensor Nodes ,  Packet Forwarding ,  Packet Drop ,  Trust Mechanism "
1,Applying Graph Neural Network in Deep Reinforcement Learning to Optimize Wireless Network Routing,https://ieeexplore.ieee.org/document/9816354/,3,Conference Paper,IEEE,2022,"At present, the traffic in wireless sensor networks (WSN) is growing at an extremely fast speed, consuming more and more network resources. This undoubtedly affects the transmission performance of WSN. Good and efficient routing technology is one of the key technologies to solve this problem. Limited by the dynamic network state, traditional routing technology faces some problems such as performance degradation and lack of learning ability. In contrast, Deep Reinforcement Learning (DRL), which has the ability of decision-making and online learning, has a better effect in facing the routing optimization problem. DRL can learn routing strategy online or offline through reinforcement learning mechanism and deep neural network. However, the existing routing models based on DRL use fully connected neural networks or convolutional neural networks, and cannot learn the network topology information. This will lead to the failure of the previously trained routing model in the face of a new network. Therefore, under the background that WSN nodes may fail, resulting in topology changes, this paper combines Graph Neural Network (GNN) with DRL, and proposes GRL-NET intelligent routing algorithm. The algorithm uses GNN instead of conventional neural network to construct DRL Agent. With the help of GNN, GRL-NET can not only learn the complex relationship among network topology, traffic and routing from the perspective of network topology, but also run in a network topology that has never appeared before. In order to evaluate the effect of GRL-NET, several groups of experiments were conducted under different traffic intensity. Experimental results show that GRL-NET can not only learn the best routing strategy, but also keep good results in the never-seen network topology.","Neural Network ,  Deep Learning ,  Wireless Networks ,  Deep Reinforcement Learning ,  Graph Neural Networks ,  Network Routing ,  Convolutional Neural Network ,  Deep Neural Network ,  Network Topology ,  Online Learning ,  Network State ,  Pathfinding ,  Intelligence Algorithms ,  Topological Changes ,  Wireless Sensor Networks ,  Topological Information ,  Traditional Routes ,  Face Model ,  Routing Algorithm ,  Routing Scheme ,  Actor Network ,  Sink Node ,  Source Node ,  Node Features ,  Graph Structure ,  Cause Of This Phenomenon ,  Critic Network ,  Neighboring Nodes ,  Markov Decision Process ,  Network Input "
2,Energy-Efficient Routing Protocols for Wireless Sensor Networks,https://ieeexplore.ieee.org/document/10060003/,0,Conference Paper,IEEE,2022,"Wireless Sensor Networks (WSN) has been a topic of research since a very long time. The importance of WSN is of huge diversity as it is used in military services, environmental services, medicine, agriculture, etc. WSN is a composition of many sensor nodes that work together to send data from the source to the base station. The sensor nodes are placed systematically inside a network. The design of this network is of most importance as it deals with the reliability, efficiency, energy consumption, delay, and lifetime of the entire WSN. The longest lifespan of the system and lowering sensor node energy consumption are given top priority while developing a WSN. Various types of routing algorithms are used in the perspective of this. In this paper, the author has bifurcated the routing protocols into four main categories which are Multi-hop, Hierarchical, Cluster-based, and Long range. Apart from these, the author has also mentioned routing methods on Fault tolerance, Neutral network, Query based, and Swarm intelligence.","Wireless Sensor Networks ,  Energy-efficient Routing ,  Ecosystem Services ,  Military Service ,  Base Station ,  Fault-tolerant ,  Network Design ,  Swarm Intelligence ,  Routing Algorithm ,  Routing Method ,  Neutral Network ,  Energy Levels ,  Entire Network ,  Source Node ,  Node Level ,  Lot Of Energy ,  Destination Node ,  Routing Scheme "
3,Routing in Wireless Sensor Networks using swarm intelligence,https://ieeexplore.ieee.org/document/6357964/,4,Conference Paper,IEEE,2012,"Wireless Sensor Networks consisting of nodes with limited power are deployed to collect and distribute useful information from the field to the other sensor nodes. Energy consumption is a key issue in the sensor's communications since many use battery power, which is limited. The sensors also have limited memory and functionality to support communications. Ant Colony Optimization, a swarm intelligence based optimization technique, is widely used in network routing. This paper describes a new routing approach for Wireless Sensor Networks consisting of stable nodes based an Ant Colony Optimization algorithm that explore the network and learn good routes, using a novel variation of reinforcement learning. Simulation results show that proposed algorithm provides promising solutions allowing node designers to efficiently operate routing tasks.","Sensor Networks ,  Wireless Sensor Networks ,  Swarm Intelligence ,  Wireless Sensor Network Routing ,  Optimization Algorithm ,  Battery Power ,  Ant Colony Optimization ,  Ant Colony Optimization Algorithm ,  Network Routing ,  Energy Levels ,  Base Station ,  Decision Rules ,  Neighboring Nodes ,  Source Node ,  Node Level ,  Table Entries ,  Routing Algorithm ,  Routing Scheme ,  Sink Node ,  Network Lifetime ,  Routing Table "
4,CLORP: Cross-Layer Opportunistic Routing Protocol for Underwater Sensor Networks Based on Multiagent Reinforcement Learning,https://ieeexplore.ieee.org/document/10492498/,0,Journal Article,IEEE,2024,"With the development of the Internet of Underwater Things (IoUT), both academia and industry have significant emphasized underwater wireless sensor networks (UWSNs). To address the issues of slow convergence, high latency, and limited energy in existing intelligent routing protocols in UWSNs, a cross-layer opportunistic routing protocol (CLORP) for underwater sensor networks based on multiagent reinforcement learning (MARL) is proposed in this article. First, CLORP combines the decision-making capability of MARL with the idea of opportunistic routing to sequentially select a set of neighbors with larger values as potential forwarding nodes, thereby increasing the packet transmission success rate. Second, in the design of the MARL reward function, two reward functions for successful and unsuccessful packet transmission are designed jointly with cross-layer information to improve the routing protocol’s performance. Finally, two algorithmic optimization strategies, adaptive learning rate and 
 ${Q}$ 
-value initialization based on location and number of neighbors, are proposed to facilitate the faster adaptation of agents to the dynamic changes of network topology and accelerate CLORP convergence. The experimental results demonstrate that CLORP can increase algorithm convergence speed by 13.2%, reduce network energy consumption by 25%, and decrease network latency by 31.2%.","Sensor Networks ,  Multi-agent Reinforcement Learning ,  Underwater Sensor ,  Underwater Sensor Networks ,  Opportunistic Routing ,  Opportunistic Routing Protocol ,  Energy Consumption ,  Dynamic Changes ,  Learning Rate ,  Convergence Rate ,  Network Topology ,  Convergence Of Algorithm ,  Topological Changes ,  Reward Function ,  Adaptive Rate ,  Wireless Sensor Networks ,  High Latency ,  Packet Transmission ,  Adaptive Learning Rate ,  Neighboring Locations ,  Energy Of Nodes ,  Delay Cost ,  Routing Algorithm ,  Congestion Costs ,  Routing Method ,  Routing Scheme ,  Autonomous Underwater Vehicles ,  Transmission Failure ,  Relay Nodes ,  Path Planning "
5,Design of energy-aware QoS routing protocol in wireless sensor networks using reinforcement learning,https://ieeexplore.ieee.org/document/6900988/,5,Conference Paper,IEEE,2014,"Nowadays a major class of wireless sensor networks (WSNs) applications require a minimum quality of service parameters to be satisfied while the wireless sensor nodes are mobile. Most of the standard WSN routing protocols greedily choose the neighbor node with the best quality of service (QoS) parameter(s) as a next hop. However, the data packet might be able to be routed through other neighbors as it might require less QoS. So the energy of the neighbor node with the best QoS will deplete earlier than other nodes which will result in the reduction of network lifetime. Therefore, it is important that QoS routing protocols of WSNs be capable of efficiently balancing energy and other resources consumption throughout the network. In this paper, we proposed EQR-RL, energy-aware QoS routing protocol in WSNs using reinforcement learning. We compare the network performance of our proposed protocol with two other protocols (QoS-AODV and RL-QRP). The packet delivery ratio, average end-to-end delay and impact of the different traffic load on average end-to-end delay are investigated. Simulation results indicate the superiority of our proposed protocol over two others by considering different network traffic load and node mobility in terms of average end-to-end delay and packet delivery ratio.","Service Quality ,  Sensor Networks ,  Wireless Sensor ,  Wireless Sensor Networks ,  Quality Of Service Routing ,  Resource Consumption ,  Neighboring Nodes ,  Data Packets ,  Traffic Load ,  Mobile Nodes ,  Delivery Ratio ,  Network Lifetime ,  Packet Delivery Ratio ,  Wireless Sensor Nodes ,  Learning Rate ,  Network Topology ,  Load Balancing ,  Beginning Of The Simulation ,  Exploration Strategy ,  Routing Problem ,  Routing Table ,  Multi-agent Reinforcement Learning ,  Quality Of Service Requirements ,  Packet Header ,  Round-trip Time ,  Routing Algorithm ,  Latency Range ,  Routing Cost ,  Number Of Distance "
6,QEBR: Q-Learning Based Routing Protocol for Energy Balance in Wireless Mesh Networks,https://ieeexplore.ieee.org/document/8780798/,8,Conference Paper,IEEE,2018,"For wireless mesh networks (WMN), energy balance has a significant impact on network lifetime. With the rapid growth of intelligent devices, learning from the environment and experience is a challenge for conventional routing protocols. To alleviate this problem, this paper proposes an energy balanced routing protocol based on Q-learning (QEBR) for WMN. Routing decisions are made by distributed reinforcement learning based routing models. A concept of neighbor energy sorting is proposed in QEBR to design the state and the reward function of Q-learning model. Simulation results demonstrate that QEBR has better performance of energy balance and packet loss rate, compared to the conventional method.","Energy Balance ,  Wireless Networks ,  Wireless Mesh ,  Wireless Mesh Networks ,  Reward Function ,  Loss Of Balance ,  Conventional Route ,  Routing Model ,  Network Lifetime ,  Routing Decisions ,  Packet Loss Rate ,  Growth Of Devices ,  Machine Learning ,  Energy Consumption ,  Learning Rate ,  Service Quality ,  Internet Of Things ,  E-learning ,  Energy Distribution ,  Shortest Path ,  Routing Scheme ,  Routing Method ,  Markov Decision Process ,  Wireless Sensor Networks ,  Q-learning Algorithm ,  Distributed Manner ,  Routing Algorithm ,  Machine Learning Concepts ,  Energy Model ,  Problem Statement "
7,Adaptive Reinforcement Learning-Based Routing Protocol for Wireless Multihop Networks,https://ieeexplore.ieee.org/document/8545412/,10,Conference Paper,IEEE,2018,"This paper presents a research on a topic of development of an adaptive packet routing scheme for wireless multihop networks, based on reinforcement learning optimization algorithm. A brief overview of classical approaches for data routing in multihop networks is provided, emphasizing main drawbacks of such algorithms, caused by ineffective hop count routing metric used in traditional multihop routing algorithms. Then, an approach based on reinforcement learning theory is presented, that has a potential to select more effective routes, relying on feedback information from neighboring nodes. An algorithm based on reinforcement learning optimization function is proposed, as well as additional functions are introduced for initial route weights distribution and dynamic route probability selection, depending from the current packet loss ratio (PLR) and receive signal strength indicator (RSSI) factors. The elaborated adaptive routing scheme then has been tested in real wireless multihop topology, where a programming implementation of the proposed algorithm - RLRP protocol, showed better routing performance characteristics in terms of PLR and RRT (Route Recovery Time), compared to a traditional improved proactive scheme of wireless multihop routing, implemented in widely used B.A.T.M.A.N. (Better Approach to Mobile Ad hoc Networking) protocol.","Wireless Networks ,  Multi-hop Networks ,  Adaptive Routing ,  Multi-hop Wireless Networks ,  Adaptive Routing Protocol ,  Wireless Multihop ,  Implementation Of Programs ,  Neighboring Nodes ,  Feedback Information ,  Adaptive Scheme ,  Packet Loss ,  Effective Route ,  Traditional Routes ,  Routing Algorithm ,  Routing Scheme ,  Received Signal Strength Indicator ,  Hop Count ,  Reinforcement Learning Theory ,  Estimated Values ,  Internet Of Things ,  Source Node ,  Round-trip Time ,  Packet Loss Rate ,  Packet Forwarding ,  Transition Probabilities ,  Probability Of Selection ,  Physical Interface ,  Wireless Sensor Networks ,  Markov Decision Process ,  Receiver Node "
8,A tailored Q- Learning for routing in wireless sensor networks,https://ieeexplore.ieee.org/document/6449899/,19,Conference Paper,IEEE,2012,Wireless sensor networks (WSNs) have major importance in distributed sensing applications. The important concern in the intend of wireless sensor networks is battery consumption which usually rely on non-renewable sources of energy. In this paper we have proposed a tailored Q-Learning algorithm for routing scheme in wireless sensor network. Our primary goal is to make an efficient routing algorithm with help of modified Q-Learning approach to minimize the energy consumption utilized by sensor nodes. This approach is a modified version of existing Q-Learning method for WSN that leads to the convergence problem.,"Sensor Networks ,  Wireless Sensor Networks ,  Q-learning ,  Energy Consumption ,  Wireless Networks ,  Convergence Problems ,  Routing Algorithm ,  Routing Scheme ,  Q-learning Algorithm ,  Non-renewable Energy Sources ,  Battery Consumption ,  Simulation Results ,  Learning Algorithms ,  Energy Conservation ,  Aggregate Data ,  Simulation Time ,  Energy Difference ,  Transmission Power ,  Learning Phase ,  Multi-agent Systems ,  Number Of Sensor Nodes ,  Sink Node ,  Delivery Ratio ,  Routing Table ,  Flow Routing ,  Data Packets ,  Network Lifetime ,  Reinforcement Learning Approach "
9,Design of energy-aware QoS routing algorithm in wireless sensor networks using reinforcement learning,https://ieeexplore.ieee.org/document/6993408/,8,Conference Paper,IEEE,2014,"Nowadays a major class of wireless sensor network (WSN) applications required a minimum quality of service parameters to be satisfied while the wireless sensor nodes might be mobile. Most of the standard WSN routing algorithms greedily choose the neighbor node with the best quality of service (QoS) parameter(s) as a next hop. However, the data packet might be able to be routed through other neighbors as it might require less QoS. So the energy of the neighbor node with the best QoS will deplete earlier than other nodes which will result in the reduction of network lifetime. Therefore, it is important for WSN QoS routing protocols to efficiently balance energy and other resources consumption throughout the network. In this paper, we proposed EQR-RL, energy-aware QoS routing protocol in WSNs using reinforcement learning. We compare the network performance of our proposed protocol with three other protocols (QoS-AODV, RSSI and RL-QRP). The packet delivery ratio, average end-to-end delay and impact of the different traffic load on average end-to-end delay are investigated. Simulation results indicate the superiority of our proposed protocol over two others by considering different network traffic load and node mobility in terms of average end-to-end delay and packet delivery ratio.","Service Quality ,  Sensor Networks ,  Wireless Sensor ,  Wireless Sensor Networks ,  Routing Algorithm ,  Quality Of Service Routing ,  Neighboring Nodes ,  Data Packets ,  Traffic Load ,  Mobile Nodes ,  Delivery Ratio ,  Network Lifetime ,  Energy Of Nodes ,  Packet Delivery Ratio ,  Wireless Sensor Nodes ,  Learning Rate ,  Load Balancing ,  Beginning Of The Simulation ,  Exploration Strategy ,  Routing Problem ,  Routing Table ,  Quality Of Service Requirements ,  Routing Cost ,  Multi-agent Reinforcement Learning ,  Node Failure ,  Round-trip Time ,  Packet Header ,  Learning Protocol ,  Latency Range ,  Number Of Distance "
10,Cost-efficient Federated Reinforcement Learning- Based Network Routing for Wireless Networks,https://ieeexplore.ieee.org/document/10056648/,5,Conference Paper,IEEE,2022,"Advances in Artificial Intelligence (AI) provide new capabilities to handle network routing problems. However, the lack of up-to-date training data, slow convergence, and low robustness due to the dynamic change of the network topology, makes these AI-based routing systems inefficient. To address this problem, Reinforcement Learning (RL) has been introduced to design more flexible and robust network routing protocols. However, the amount of data (
$i$
. e., state-action space) shared be- tween agents, in a Multi-Agent Reinforcement Learning (MARL) setup, can consume network bandwidth and may slow down the process of training. Moreover, the curse of dimensionality of RL encompasses the exponential growth of the discrete state-action space, thus limiting its potential benefit. In this paper, we present a novel approach combining Federated Learning (FL) with Deep Reinforcement Learning (D RL) in order to ensure an effective network routing in wireless environment. First, we formalize the problem of network routing as a problem of RL, where multiple agents that are geographically distributed train the policy model in a fully distributed manner. Thus, each agent can quickly obtain the optimal policy that maximizes the cumulative expected reward, while preserving the privacy of each agent's data. Experiments results show that our proposed Federated Reinforcement Learning (FRL) approach is robust and effective.","Wireless Networks ,  Network Routing ,  Federated Reinforcement Learning ,  Training Data ,  Deep Learning ,  Multi-agent ,  Network Topology ,  Multiple Agents ,  Deep Reinforcement Learning ,  Slow Convergence ,  Effective Route ,  Federated Learning ,  Routing Problem ,  Flexible Network ,  Learning In Order ,  Wireless Environment ,  Reinforcement Learning Approach ,  Reinforcement Learning Problem ,  Multi-agent Reinforcement Learning ,  State Action Space ,  Routing Scheme ,  Deep Reinforcement Learning Agent ,  Negative Reward ,  Packet Delivery Ratio ,  Restricted Boltzmann Machine ,  Network Delay ,  Reward Function ,  Cluster Head ,  Reward Type ,  Wireless Sensor Networks "
11,Routing Protocol Design for Underwater Optical Wireless Sensor Networks: A Multiagent Reinforcement Learning Approach,https://ieeexplore.ieee.org/document/9076600/,52,Journal Article,IEEE,2020,"Underwater optical wireless sensor networks (UOWSNs) have been attracting many interests for the advantages of high transmission rate, ultrawide bandwidth, and low latency. However, due to limited energy resources and highly dynamic topology caused by the water flow movement, it is challenging to provide a low-consumption and reliable routing in UOWSNs. To tackle this issue, in this article, we propose an efficient routing protocol based on multiagent reinforcement learning, termed as DMARL, for UOWSNs. The network is first modeled as a distributed multiagent system, and residual energy and link quality are considered into the routing protocol design to improve the adaptation to a dynamic environment and the support of prolonging network life. Additionally, two optimization strategies are proposed to accelerate the convergence of the reinforcement learning algorithm. On the basis, a reward mechanism is provided for the distributed system. The simulation results show that the DMARL-based routing protocol has low energy consumption and high packet delivery ratio (over 90%), and it is suitable for networks where the average number of neighbor nodes is less than 14.","Wireless Sensor Networks ,  Multi-agent Reinforcement Learning ,  Multi-agent Reinforcement Learning Approach ,  Routing Protocol Design ,  Energy Consumption ,  Learning Algorithms ,  Optimal Strategy ,  Low Energy Consumption ,  Neighboring Nodes ,  Convergence Of Algorithm ,  Multi-agent Systems ,  Reinforcement Learning Algorithm ,  Residual Energy ,  Reward Mechanism ,  Dynamic Topology ,  Delivery Ratio ,  Packet Delivery Ratio ,  Learning Rate ,  Data Transmission ,  Value Of Node ,  Computation Energy ,  Higher Learning Rate ,  Routing Decisions ,  Routing Algorithm ,  Undersea ,  Lower Learning Rate ,  Relay Nodes ,  Hop Count ,  Node Information ,  Convergence Speed Of The Algorithm "
12,Efficient Routing Protocol for Wireless Sensor Network based on Reinforcement Learning,https://ieeexplore.ieee.org/document/9231883/,19,Conference Paper,IEEE,2020,"Wireless sensor nodes are battery-powered devices which makes the design of energy-efficient Wireless Sensor Networks (WSNs) a very challenging issue. In this paper, we propose a new routing protocol for WSN based on distributed Reinforcement Learning (RL). The proposed approach optimises WSN lifetime and energy consumption. This routing protocol learns, over time, the optimal path to the sink node(s). With a dynamic path selection, our algorithm ensures higher energy efficiency, postpones nodes death and isolation. We consider while routing messages the distance between nodes, available energy and hop count to the sink node. The effectiveness of the proposed protocol is demonstrated through simulations and comparisons with some existing algorithms over different lifetime definitions.","Wireless Sensor ,  Wireless Sensor Networks ,  Efficient Routing Protocol ,  Energy Consumption ,  Energy Efficiency ,  Energy Availability ,  Sink Node ,  Wireless Sensor Nodes ,  Hop Count ,  Lifetime Consumption ,  Learning Process ,  Network Topology ,  Discovery Process ,  Reward Function ,  Data Packets ,  Processing Routes ,  Communication Range ,  Routing Problem ,  Current Node ,  Identification Of Nodes ,  Packet Delivery ,  Routing Algorithm ,  Network Lifetime ,  Continuous Learning Process "
13,Multi-Agent Deep Reinforcement Learning for Packet Routing in Tactical Mobile Sensor Networks,https://ieeexplore.ieee.org/document/10388032/,4,Journal Article,IEEE,2024,"Tactical wireless sensor networks (T-WSNs) are used in critical data-gathering military operations, such as battlefield surveillance, combat monitoring, and intrusion detection. These networks have unique challenges, such as jamming attacks, which are not normally encountered in traditional WSNs. Jamming attacks on the networks’ links disrupt data communication and make packet routing in T-WSNs a difficult task. Consequently, T-WSN routing aims to find the most reliable routes, while meeting the stringent delay and energy requirements. To this end, we propose a distributed multi-agent deep reinforcement learning (MADRL)-based routing solution for multi-sink tactical mobile sensor networks to overcome link layer jamming attacks. Our proposed routing scheme captures the hop count to the nearest sink, the one-hop delay, the next hop’s packet loss rate (PLR), and the energy cost of packet forwarding in the action reward estimation. Furthermore, the proposed scheme outperforms benchmark algorithms in terms of the packet delivery ratio (PDR), packet delivery time, and energy efficiency.","Sensor Networks ,  Deep Reinforcement Learning ,  Multi-agent Deep Reinforcement Learning ,  Packet Routing ,  Energy Efficiency ,  Energy Cost ,  Wireless Sensor Networks ,  Packet Loss ,  Intrusion Detection ,  Routing Scheme ,  Packet Delivery ,  Packet Loss Rate ,  Packet Forwarding ,  Packet Delivery Ratio ,  Reliable Route ,  Link Layer ,  Jamming Attacks ,  Hop Count ,  Neural Network ,  Energy Consumption ,  Deep Reinforcement Learning Agent ,  Deep Q-network ,  Data Packets ,  Routing Algorithm ,  Delay Cost ,  Deep Neural Network ,  Neighboring Nodes ,  Proximal Policy Optimization ,  Pathfinding ,  Route Length "
14,Collaborative Energy-Efficient Routing Protocol for Sustainable Communication in 5G/6G Wireless Sensor Networks,https://ieeexplore.ieee.org/document/10243620/,8,Journal Article,IEEE,2023,"One of the main problems with WSNs is that most sensor nodes in wireless sensor networks (WSNs) are motorized by energy-constrained, which significantly affects the system’s effectiveness, dependability, and lifespan. Numerous clustering strategies have been created to enhance the energy efficiency of WSNs in 5G and 6G transmission. To overcome these issues, we suggest a collaborative energy-efficient routing protocol (CEEPR) for sustainable communication in 5G/6G wireless sensor networks (WSNs). Initially, this study gathered and collected the data at the sink node. The network’s nodes are clustered using the reinforcement learning technique (R.L.). Cluster head selection is employed for better data transmission using residual energy (RE) based cluster head selection algorithm. A collaborative energy-efficient routing protocol (CEERP) is proposed. We use a multi-objective improved seagull algorithm (MOISA) as an optimization technique to enhance the system’s performance. Finally, the presentation of the system is analyzed. Compare with the existing methods, the primary metrics are throughput, energy consumption, network lifetime, packet transmission, routing overhead, and transmission speed. The proposed approach uses 50% less energy while improving network lifespan and energy efficiency compared to the current protocols.","Sensor Networks ,  Communication Protocol ,  Wireless Sensor Networks ,  Collaborative Protocol ,  Energy-efficient Routing ,  Energy Consumption ,  Energy Efficiency ,  Data Transmission ,  Wireless Networks ,  Residual Energy ,  Transmission Speed ,  Packet Transmission ,  Sink Node ,  Cluster Head ,  Network Lifetime ,  Seagull ,  Learning Algorithms ,  Service Quality ,  Energy Levels ,  Internet Of Things ,  Vehicular Ad Hoc Networks ,  Mobile Edge Computing ,  Wireless Technologies ,  Markov Decision Process ,  Energy Use ,  Energy Usage ,  6G Networks ,  Ad Hoc Networks ,  Pareto Front ,  Routing Method "
15,Improving the Software-Defined Wireless Sensor Networks Routing Performance Using Reinforcement Learning,https://ieeexplore.ieee.org/document/9504585/,34,Journal Article,IEEE,2022,"Software-defined networking (SDN) is an emerging architecture used in many applications because of its flexible architecture. It is expected to become an essential enabler for the Internet of Things (IoTs). It decouples the control plane from the data plane, and the controller manages the whole underlying network. SDN has been used in wireless sensor networks (WSNs) for routing. The SDN controller uses some algorithms to calculate the routing path; however, none of these algorithms have enough ability to obtain the optimized routing path. Therefore, reinforcement learning (RL) is a helpful technique to select the best routing path. In this article, we optimize the routing path of SDWSN through RL. A reward function is proposed that includes all required metrics regarding energy efficiency and network Quality-of-Service (QoS). The agent gets the reward and takes the next action based on the reward received, while the SDWSN controller improves the routing path based on the previous experience. However, the whole network is also controlled remotely through the Web. The performance of the RL-based SDWSN is compared with SDN-based techniques, including traditional SDN and energy-aware SDN (EASDN), QR-SDN, TIDE and non SDN-based techniques, such as 
 $Q$ 
-learning and RL-based routing (RLBR). The proposed RL-based SDWSN outperforms in terms of lifetime from 8% to 33% and packet delivery ratio (PDR) from 2% to 24%. It is envisioned that this work will help the engineers for achieving the desired WSN performance through efficient routing.","Wireless Sensor Networks ,  Wireless Sensor Network Routing ,  Software-defined Wireless Sensor Networks ,  Energy Efficiency ,  Internet Of Things ,  Wireless Networks ,  Reward Function ,  Efficient Route ,  Control Plane ,  Routing Path ,  Delivery Ratio ,  Packet Delivery Ratio ,  Energy Consumption ,  Information And Communication Technologies ,  Network Performance ,  Life Time ,  Neighboring Nodes ,  Deep Reinforcement Learning ,  Data Packets ,  Higher Lifetime ,  Raspberry Pi ,  Routing Table ,  Control Nodes ,  Residual Energy ,  Control Packets ,  Control Side ,  Data Nodes ,  Routing Algorithm ,  Deployment Area ,  Network Energy Consumption "
16,Design of Routing Protocols for Heterogeneous WSN Based on Multi-Agent Reinforcement Learning,https://ieeexplore.ieee.org/document/10561011/,0,Conference Paper,IEEE,2024,"The proliferation of IoT and wireless sensor networks is affecting many different industries. The primary concern in designing IoT-integrated heterogeneous WSNs is energy efficiency since nodes often operate with limited battery units. Software-defined heterogeneous WSNs integrated with the IoT provide an innovative design that can successfully handle these problems. The major concern in WSN is energy consumption by each node and the way of communication between the nodes in the form delivery ration and the reliability need to be more concentrated. This paper presents an enhanced routing method to resolve the two interrelated issues of large-scale IoT-based WSNs. Systems that address clustering and routing independently do not function well together, leading to inefficient solutions when considering energy usage and network longevity. There are several cluster-based routing algorithms for usage with homogeneous WSNs, but very few cater to heterogeneous WSNs regarding energy efficiency. The study's proposed routing protocol, MARL-HWSN, uses multi-agent reinforcement learning to address the heterogeneous WSN issue. The routing protocol design would improve clustering, reduce energy consumption, and provide reliable routing in the network. Modelling the network's architecture with multiple agents and developing a routing protocol with residual power and connectivity quality in mind improves adaptation to changing circumstances and helps extend the network's lifetime. The optimization approach incorporates a global reward function as part of the networked system. Compared to previous approaches, the experimental results showed that MARL-HWSN simulations employing Software-Defined Nets (SDN) enhanced the packet delivery ratio and lowered data delivery time while demonstrating excellent energy efficiency and quick response to unanticipated adjustments to the network.","Multi-agent Reinforcement Learning ,  Routing Protocol Design ,  Energy Consumption ,  Energy Efficiency ,  Sensor Networks ,  Energy Usage ,  Reward Function ,  Wireless Sensor Networks ,  Network Routing ,  Routing Algorithm ,  Delivery Ratio ,  Network Lifetime ,  Routing Method ,  Packet Delivery Ratio ,  Learning Rate ,  Multi-agent Systems ,  Markov Decision Process ,  Data Packets ,  Residual Energy ,  Network Energy ,  Relay Nodes ,  Routing Scheme ,  Routing Approach ,  Route Design ,  Packet Loss Rate "
17,A dyna-Q based multi-path load-balancing routing algorithm in wireless sensor networks,https://ieeexplore.ieee.org/document/7461455/,1,Conference Paper,IEEE,2015,"In wireless sensor networks, since the energy and computing capacity of sensor nodes are limited, routing algorithm has become one of the most important area on which researchers focus. As most general routing algorithms cannot efficiently solve the minimal energy consumption and load-balancing problem, we propose a Dyna-Q based energy-efficient load-balancing multi-path routing algorithm, which fully considers the number of hops, the residual energy of sensor nodes and the energy consumption of nodes, reduces the network energy consumption and hence improves the network lifetime. The experiment showed that the survival number of nodes, the residual energy distribution of nodes and transmission success rate surpassed those of GT algorithm, indicating that the proposed algorithm could effectively reduce energy consumption and prolong the network lifetime.","Wireless Sensor ,  Wireless Sensor Networks ,  Routing Algorithm ,  Energy Consumption ,  Wireless Networks ,  Residual Energy ,  Distribution Of Nodes ,  Minimum Energy Consumption ,  Network Lifetime ,  Energy Of Nodes ,  Premature Death ,  Neighboring Nodes ,  Reinforcement Learning Algorithm ,  Node Information ,  Routing Scheme ,  Routing Path ,  Sink Node ,  Hop Count "
18,Relational Deep Reinforcement Learning for Routing in Wireless Networks,https://ieeexplore.ieee.org/document/9469475/,4,Conference Paper,IEEE,2021,"While routing in wireless networks has been studied extensively, existing protocols are typically designed for a specific set of network conditions and so do not easily accommodate changes in those conditions. For instance, protocols that assume network connectivity cannot be easily applied to disconnected networks. In this paper, we develop a distributed routing strategy based on deep reinforcement learning that generalizes to diverse traffic patterns, congestion levels, network connectivity, and link dynamics. We make the following key innovations in our design: (i) the use of relational features as inputs to the deep neural network approximating the decision space, which enables our algorithm to generalize to diverse network conditions, (ii) the use of packet-centric decisions to transform the routing problem into an episodic task by viewing packets, rather than wireless devices, as reinforcement learning agents, which provides a natural way to propagate and model rewards accurately during learning, and (iii) the use of extended-time actions to model the time spent by a packet waiting in a queue, which reduces the amount of training data needed and allows the learning algorithm to converge more quickly. We evaluate our routing algorithm using a packet-level simulator and show that the policy our algorithm learns during training is able to generalize to larger and more congested networks, different topologies, and diverse link dynamics. Our algorithm outperforms shortest path and backpressure routing with respect to packets delivered and delay per packet.","Wireless Networks ,  Deep Reinforcement Learning ,  Routing In Wireless Networks ,  Deep Neural Network ,  Related Features ,  Shortest Path ,  Use Of Features ,  Network State ,  Traffic Congestion ,  Wireless Devices ,  Traffic Patterns ,  Network Congestion ,  Routing Algorithm ,  Routing Scheme ,  Reinforcement Learning Agent ,  Congestion Level ,  Time Step ,  Network Size ,  Sensor Networks ,  Reward Function ,  Deep Reinforcement Learning Agent ,  Policy Learning ,  Lattice Dynamics ,  Queue Length ,  Random Topology ,  Traffic Scenarios ,  Graph Neural Networks ,  Queue Size ,  Markov Decision Process ,  Trained Agent "
19,Static and Dynamic Routing Protocols in Network Security Attacks,https://ieeexplore.ieee.org/document/10276123/,0,Conference Paper,IEEE,2023,"Network devices use communication protocols to transfer information by physical or wireless technologies, including routers and access points. Networking components are used to software monitor, manage and secure the network. The router is quite trained by the use of reinforcement learning which can make all the hardest decisions for making algorithms. Routing selects Internet Protocol(IP) paths, also known as Internet Protocol, and those packages are sent from their starting point. Routers can make the decision to route packets along with the network paths. An innovative routing system for Flying AdHoc Network(FANET) is provided by an enhanced form of AntHocNet. Dynamic routing protocols are more efficient in medium and large networks because they require most of the computing power, which is why smaller networks rely on the static routing protocol. In this study, routing algorithms, dynamic routing networks, Unmanned Aerial Vehicle(UAV) protocol, Routing Protocol(RPL) in the security of networks, and Flying Ad hoc networks are discussed.","Dynamic Routing ,  Static Routing ,  Dynamic Routing Protocol ,  Unmanned Aerial Vehicles ,  Wireless Technologies ,  Network Devices ,  Internet Protocol ,  Ad Hoc Networks ,  Network Routing ,  Routing Algorithm ,  Neural Network ,  Internet Of Things ,  Recurrent Neural Network ,  Wireless Networks ,  Access Control ,  Recommender Systems ,  Mobile Services ,  Wireless Sensor Networks ,  Denial Of Service ,  Cyber-physical Systems ,  Distributed Denial Of Service ,  Neural Architecture Search ,  Routing Table ,  Sybil Attack ,  Malicious Activities ,  Malicious Attacks ,  Routing Information ,  Mobile Nodes "
20,Reinforcement Learning-Based Opportunistic Routing Protocol Using Depth Information for Energy-Efficient Underwater Wireless Sensor Networks,https://ieeexplore.ieee.org/document/10154617/,7,Journal Article,IEEE,2023,"An efficient routing protocol is critical for the data transmission of underwater wireless sensor networks (UWSNs). Aiming to the problem of void region in UWSNs, this article proposes a reinforcement learning-based opportunistic routing protocol (DROR). By considering the limited energy and underwater environment, DROR is a receiver-based routing protocol, and combines reinforcement learning (RL) with opportunistic routing (OR) to ensure real-time performance of data transmission as well as energy efficiency. To achieve reliable transmission when encountering void regions, a void recovery mechanism is designed to enable packets to bypass void nodes and continue forwarding. Furthermore, a relative 
 ${Q}$ 
-based dynamic scheduling strategy is proposed to ensure that packets can efficiently forward along the global optimal routing path. Simulation results show that the proposed protocol performs well in terms of end-to-end delay, reliability, and energy efficiency in UWSNs.","Depth Information ,  Wireless Sensor Networks ,  Underwater Wireless Sensor Networks ,  Opportunistic Routing ,  Opportunistic Routing Protocol ,  Energy Efficiency ,  Data Transmission ,  Dynamic Strategy ,  Optimal Path ,  Undersea ,  Reliable Transmission ,  Routing Path ,  Global Path ,  Energy Consumption ,  Neighboring Nodes ,  Value Of Node ,  Reward Function ,  Source Node ,  Performance Of Protocol ,  Communication Range ,  Relay Nodes ,  Optimal Node ,  Packet Forwarding ,  Node Information ,  Residual Energy ,  Packet Header ,  Packet Transmission ,  Transmission Energy Consumption ,  Node Deployment ,  Number Of Sensor Nodes "
21,Multiagent Meta-Reinforcement Learning for Adaptive Multipath Routing Optimization,https://ieeexplore.ieee.org/document/9410247/,20,Journal Article,IEEE,2022,"In this article, we investigate the routing problem of packet networks through multiagent reinforcement learning (RL), which is a very challenging topic in distributed and autonomous networked systems. In specific, the routing problem is modeled as a networked multiagent partially observable Markov decision process (MDP). Since the MDP of a network node is not only affected by its neighboring nodes’ policies but also the network traffic demand, it becomes a multitask learning problem. Inspired by recent success of RL and metalearning, we propose two novel model-free multiagent RL algorithms, named multiagent proximal policy optimization (MAPPO) and multiagent metaproximal policy optimization (meta-MAPPO), to optimize the network performances under fixed and time-varying traffic demand, respectively. A practicable distributed implementation framework is designed based on the separability of exploration and exploitation in training MAPPO. Compared with the existing routing optimization policies, our simulation results demonstrate the excellent performances of the proposed algorithms.","Pathfinding ,  Adaptive Routing ,  Multipath Routing ,  Meta Reinforcement Learning ,  Optimal Policy ,  Neighboring Nodes ,  Markov Decision Process ,  Reinforcement Learning Algorithm ,  Routing Problem ,  Traffic Demand ,  Model-free Reinforcement Learning ,  Multi-agent Reinforcement Learning ,  Proximal Policy Optimization ,  Time Step ,  Value Function ,  Reward Function ,  Noisy Environments ,  Information For Decision-making ,  Wireless Sensor Networks ,  Ideal Environment ,  Routing Scheme ,  Delivery Delay ,  Distribution Routes ,  Policy Gradient Method ,  Routing Algorithm ,  Critic Network ,  Multi-hop Networks ,  Policy Gradient Algorithm ,  Exploration Phase ,  Edge Server "
22,RLBEEP: Reinforcement-Learning-Based Energy Efficient Control and Routing Protocol for Wireless Sensor Networks,https://ieeexplore.ieee.org/document/9756551/,16,Journal Article,IEEE,2022,"One of the most important topics in the field of wireless sensor networks is the development of approaches to improve network lifetime. In this paper, an energy-efficient control and routing protocol for wireless sensor networks is presented. This algorithm is based on reinforcement learning for energy management in the network. This protocol seeks to optimize routing policies to maximize the long-term reward received by each node, using reinforcement learning, which is a machine learning approach. In order to improve the lifetime of wireless sensor network, three energy management approaches have been proposed. The first approach is to navigate correctly using reinforcement learning to reduce the length of the routes and to improve energy consumption. The second approach is to exploit a sleep scheduling technique to improve node energy consumption. The last approach is used to restrict data transmission of each node based on the received data change rate. Simulation results show that in terms of network lifespan, the proposed method significantly outperforms previous reported methods.","Energy Efficiency ,  Sensor Networks ,  Control Protocol ,  Wireless Sensor Networks ,  Energy-efficient Control ,  Energy Efficient Protocol ,  Energy Consumption ,  Simulation Results ,  Machine Learning Approaches ,  Data Transmission ,  Wireless Networks ,  Energy Management ,  Network Management ,  Sleep Schedule ,  Network Lifetime ,  Energy Of Nodes ,  Changes In Data ,  Optimal Policy ,  Node Status ,  Neighboring Nodes ,  Routing Method ,  Cluster Head ,  Data Fusion ,  Sink Node ,  Network Routing ,  Reward Function ,  Current Node ,  Percentage Of Nodes ,  Nodes In Order ,  Processing Routes "
23,A Comprehensive Research on Deep Learning Based Routing Optimization Algorithms in Software Defined Networks,https://ieeexplore.ieee.org/document/10392911/,0,Conference Paper,IEEE,2023,"Discovering an optimal routing in Software Defined Networks (SDNs) is challenging due to several factors like scalability issues, interoperability, reliability, poor configuration of controllers and security measures. The compromised SDN controller attacks at the control plane layer, packet losses in the topology and end-to-end delay are the most security risk factors in SDNs. To overcome this, in most of the existing researches, Deep Reinforcement Learning (DRL) algorithm with various optimization techniques was implemented for optimal routing in SDN by providing link weights to balance the end-to-end delay and packet losses. DRL used Deterministic Policy Gradient (DPG) method which acts as an actor-critic reinforcement learning agent that searches for an optimal policy to minimize the expected cumulative long-term reward. However, discovering an optimal routing with efficient security measures is still a major challenge in SDNs. This research proposes a detailed review of routing optimization algorithms in SDN using Deep Learning (DL) methods which supports the researchers in accomplishing a better solution for future research.","Deep Learning ,  Pathfinding ,  Deep Reinforcement Learning ,  Packet Loss ,  Deep Reinforcement Learning Algorithm ,  Deterministic Policy Gradient ,  Control Plane ,  Deep Learning Models ,  Cloud Computing ,  Flow Data ,  Literature Survey ,  Generalization Capability ,  Optimal Feature ,  Network Resources ,  Optimal Path ,  Wireless Sensor Networks ,  Network Management ,  Load Balancing ,  Graph Neural Networks ,  Kinds Of Applications ,  Intrusion Detection System ,  Kernel Principal Component Analysis ,  Routing Scheme ,  Routing Method ,  Routing Algorithm ,  Intrusion Detection ,  Network Routing ,  Network Topology "
24,Distributed Cooperative Reinforcement Learning for Wireless Sensor Network Routing,https://ieeexplore.ieee.org/document/9771591/,4,Conference Paper,IEEE,2022,"In this work we examine a specific case of wireless sensor networks (WSN) we call peer-to-peer WSN where source and destination are both dynamic and each is subject to constraints of low bandwidth, limited energy storage, and limited computational resources. Peer-to-peer WSN require the consideration of data computation time as a limiting constraint on information availability unlike a standard WSN that can rely on the unconstrained sink to perform the necessary computation of the raw sensor data into usable information. To effectively manage and improve upon peer-to-peer WSN routing, and WSN routing in general, we present a deep reinforcement learning algorithm known as distributed cooperative reinforcement for routing (DCRL-R) which uses a neural network and expanded state space parameters to learn routing policies for WSN. DCRL-R also incorporates an increased action space for determining when and where to perform in-network computation of the raw sensor data. We perform tests of DCRL-R on a physical network utilizing measured node state parametric data and show its viability in future WSN applications compared to a baseline routing algorithm using shortest path decisions with no computational offloading.","Wireless Sensor Networks ,  Network Routing ,  Wireless Sensor Network Routing ,  Neural Network ,  State Space ,  Sensor Data ,  Shortest Path ,  Network State ,  Deep Reinforcement Learning ,  Reinforcement Learning Algorithm ,  Routing Algorithm ,  Deep Reinforcement Learning Algorithm ,  Computation Offloading ,  Decision-making Process ,  Learning Process ,  Internet Of Things ,  Input Layer ,  Global Status ,  Reward Function ,  Individual Nodes ,  Ad Hoc Networks ,  Network Discovery ,  Round-trip Time ,  Policy Learning ,  Actual Hardware ,  Deep Reinforcement Learning Model ,  Source Node ,  Distributed Algorithm ,  Notion Of State "
