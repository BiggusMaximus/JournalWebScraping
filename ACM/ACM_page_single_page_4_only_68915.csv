title,link,number_of_citation,article_type,publisher,publication_date,abstract,keyword
Multi-agent collaborative path planning algorithm with reinforcement learning and combined prioritized experience replay in Internet of Things,https://dl.acm.org/doi/10.1016/j.compeleceng.2024.109193,0,research-article,ACM,2024,"ts•Collaborating on data collection through multi-mobile sinks reduces the average delay.•Multiple agents acquire optimal strategies through interactions with environment.•Improved experience replay strategy solves the problem of inefficient sampling.•The path planning algorithm increases the task completion rate in complex environment.AbstractAs one of the most promising research areas in the field of reinforcement learning, multi-agent collaborative decision-making faces the challenge of real-time control in dynamic environments. This paper focuses on the path planning problem of multi-mobile sink collaborative data collection in the Internet of Things. Based on the excellent collaborative decision-making performance of multi-agent deep deterministic policy gradients (MADDPG), a novel path planning algorithm is proposed in the constructed wireless sensor network model. Furthermore, a combined prioritized experience replay strategy is designed to increase the utilization of important experiences in MADDPG. Extensive experiments conducted in various conditions show that compared with traditional MADDPG and MADDPG with prioritized experience replay, the proposed algorithm demonstrates the best performance. The accelerated convergence speed, enhanced training effectiveness and shortened paths indicate the capability of the proposed algorithm in multi-agent collaborative path planning problem.Graphical abstractDisplay Omitted",none
EBR-RL: energy balancing routing protocol based on reinforcement learning for WSN,https://dl.acm.org/doi/10.1145/3412841.3442063,7,research-article,ACM,2021,"A Wireless Sensor Network (WSN) is a wireless network that monitors physical environment conditions through resource-constrained sensor nodes and delivers data to a sink node through the network. One of the most important constraints on sensor nodes is their limited power source, which consists of small and irreplaceable batteries. Energy conservation is thus a dominant factor in WSN. Therefore, when designing a routing protocol for WSNs, it is necessary to consider the energy constraint of sensor nodes. In this paper, we consider the energy constraint of sensor nodes and propose an Energy Balancing Routing Protocol using reinforcement learning. The performance of the proposed protocol is compared to other existing energy-efficient routing protocols and the results show that the proposed protocol performs better with regards to energy saving and network lifetime.",none
Battery and supercapacitor imperfections modeling and comparison for RF energy harvesting wireless sensor network,https://dl.acm.org/doi/10.1007/s11276-018-1831-z,4,research-article,ACM,2020,"In an energy harvesting communication system, the main challenge is to improve network lifetime and maximize throughput by allocating optimal power over a finite span of time, with varying channel and energy. Considering (1) causal state information (SI) of channel and energy (CSI and ESI) and (2) energy storage device imperfections, the problem of power allocation is solved using dynamic programming. As compared to the battery, the supercapacitor is a good alternative for network lifetime improvement, but the imperfections hinder the performance. In this paper, imperfections (storage inefficiency and energy leakage equation) are modeled for supercapacitor and battery. We consider a constant leakage rate for battery. Also, the imperfections of battery and supercapacitor are compared to find which imperfection of supercapacitor is a bottleneck in system performance in different settings (varying channel conditions). The analysis is supported by numerical results.",none
A parallel compact cat swarm optimization and its application in DV-Hop node localization for wireless sensor network,https://dl.acm.org/doi/10.1007/s11276-021-02563-9,7,research-article,ACM,2021,"Cat swarm optimization (CSO) has been applied to a variety of fields because of the better capacity of searching for optimum and higher robustness. However, the poor convergency and larger memory consumption are still core defects, which restricts the efficiency of optimization to a larger extent. A new heuristic algorithm named Parallel Compact Cat Swarm Optimization (PCCSO) with three separate communication strategies and the concept of the compact are presented in this article. The advantage of PCCSO is not only reflected in enhancing the ability of local search, but also in saving the computer memory. The experimental results on CEC2013 benchmark functions demonstrate that the PCCSO is always superior to PSO, CSO, and improved CSO in getting convergent. Then, the PCCSO is applied to DV-Hop to effectively improve the localization accuracy of unknown nodes while also saving WSN memory. The experimental results based on PCCSO from the different number of sensor nodes also illustrate that the PCCSO-DV-Hop shows a lower localization error compared to other optimization algorithms based on DV-Hop.",none
IoT Network with Energy Efficiency for Dynamic Sink via Reinforcement Learning,https://dl.acm.org/doi/10.1007/s11277-024-11355-1,0,research-article,ACM,2024,"In a society where better, cleaner power generation and management are needed, IoT devices and battery technologies have gained prominence. The Internet of Things (IoT) paradigm has revolutionized various industries by enabling seamless connectivity and data exchange among heterogeneous devices. However, the energy constraints of IoT devices, particularly in dynamic environments with mobile sinks, pose significant challenges to network performance and longevity. This article proposes a novel approach to enhance energy efficiency in IoT networks with dynamic sinks using reinforcement learning (RL). Better and more effective wireless communication methods could increase the lifespan of battery-powered devices and networks as these technologies advance. Compared to more conventional methods, the application of reinforcement learning can encourage even more advancements in these protocols. In order to elect cluster leaders and create clusters in a network of one hundred randomly generated nodes, a revised version of a previously suggested methodology will be presented in this study. Predictively moving the sink, or base station, from its fixed location in the middle of the plot will be the adjustment.",none
A study on data aggregation techniques in wireless sensor network in static and dynamic scenarios,https://dl.acm.org/doi/10.1007/s11334-019-00326-6,2,article,ACM,2019,"Small-size sensor nodes are used as the basic component for collecting and sending the data or information in the ad hoc mode in wireless sensor network (WSN). This network is generally used to collect and process data from different regions where the movement of human is very rare. The sensor nodes are deployed in such a region for collecting data using ad hoc network where, at any time, the unusual situation may happen or there is no fixed network that can work positively and provide any transmission procedure. The location may be very remote or some disaster-prone area. In disaster-prone zone, after disaster, most often no fixed network remains alive. In that scenario, the ad hoc sensor network is one of the reliable sources for collecting and transmitting the data from that region. In this type of situation, sensor network can also be helpful for geo-informatic system. WSN can be used to handle the disaster management manually as well as through an automated system. The main problem for any activity using sensor node is that the nodes are very much battery hunger. An efficient power utilization is required for enhancing the network lifetime by reducing data traffic in the WSN. For this reason, some efficient intelligent software and hardware techniques are required to make the most efficient use of limited resources in terms of energy, computation and storage. One of the most suitable approaches is data aggregation protocol which can reduce the communication cost by extending the lifetime of sensor networks. The techniques can be implemented in different efficient manners, but all are not useful in same application scenarios. More specifically, data can be collected by dynamic approach using rendezvous point (RP), and for that purpose, intelligent neural network-based cluster formation techniques can be used and for fixing the targeted base station, the ant colony optimization algorithm can be used. In this work, we have made a comprehensive study of such energy efficient integrated sensor-based system in order to achieve energy efficiency and to prolong network lifetime.",none
A tutorial on reinforcement learning in selected aspects of communications and networking,https://dl.acm.org/doi/10.1016/j.comcom.2023.05.019,0,review-article,ACM,2023,"Telecommunication systems are increasingly complex, dynamic, and heterogeneous. Tools are needed to efficiently support and automate complex control and management processes. Reinforcement learning becomes one of the most attractive and popular solutions applicable to a wide variety of different aspects of communications and networking. Its development is further boosted by the favorable conditions created by both the existing IT infrastructure and evolving network architectures.The aim of this tutorial is twofold. Firstly, to provide fundamentals regarding the Reinforcement Learning (RL) method. Secondly, to comprehensively study the examples of applying RL-based solutions to solve problems in different aspects of communications and networking. Studies are supplemented with additional explanations, figures and critical considerations, including pros and cons of using selected methods for particular purposes. This part uniquely complements the tutorial one and facilitates in-depth understanding of RL. Based on the conducted studies, we draw a comparative analysis, summaries and expected future research topics and challenges of using RL in communications and networking.Highlights•Comprehensive studies on examples of using Reinforcement Learning solutions in different aspects of communications.•Additional explanations, figures and critical considerations to facilitate understanding.•Theoretical fundamentals of Reinforcement Learning.",none
Energy Efficient and Delay Aware Optimization Reverse Routing Strategy for Forecasting Link Quality in Wireless Sensor Networks,https://dl.acm.org/doi/10.1007/s11277-022-09982-7,1,research-article,ACM,2022,"Wireless Sensor Networks (WSNs) have a rapidly increasing number of applications due to the development of long-range low-powered wireless devices. Node decoupling for (NoRD) efficient power-supplying of nodes offers a evade network to avoid sleepy nodes (Chen and Pinkston in NoRD: Node-node decoupling for effective power-gating of on-chip nodes, in Intl, Symp, On Microarchitecture (MICRO), 2012). Though, it obtains a huge latency as well as restricted scalability. In addition, it enhances energy utilization. To defeat this problem, Energy Efficient and Delay Aware Optimization Reverse Routing Strategy (EEOS) is proposed for forecasting link quality in WSN. The main objective of this research is to design a Multi-hop Reverse Routing Technique in WSN. The reverse routing technique avoids the amount of retransmission. Forecasting link quality is used to measure the link quality by Estimating Communication Count (ECC), energy, and delay. This technique enhances routing, link stability, and energy efficiency and minimizes network congestion. It supports Quality of Service (QoS) necessities of energy control, traffic arrangement, and route allotment. In this scheme, the Signal-to-Interference and Noise Ratio (SINR) assists in measuring the quality of a wireless connection. In addition, the route link score is used to form the route from sender to receiver. The reverse routing also provides an efficient route. Simulation results prove that the EEOS minimizes both the delay and the energy utilization and increases the network throughput compared to the baseline protocol.",none
Optimizing Clustering in Wireless Sensor Networks: A Synergistic Approach Using Reinforcement Learning (RL) and Particle Swarm Optimization (PSO),https://dl.acm.org/doi/10.1007/s42979-024-03080-0,0,research-article,ACM,2024,"Significant research efforts are currently devoted to wireless sensor networks due to its broad range of applications. WSNs face various constraints, encompassing challenges related to communication, clustering management and the finite battery life of nodes. Thus, Energy conservation in such networks is indispensable. Given a constant energy consumption rate during information sensing and reception, the highest energy consumption among sensor nodes occurs during data transmission. One of promising solution to reduce energy consumption is organizing WSN in clusters. Clustering in Wireless Sensor Networks (WSN) involves grouping sensor nodes into clusters to facilitate efficient data aggregation, communication, and management within the network. This organizational structure helps optimize energy consumption, enhance scalability, and prolong the overall lifespan of the WSN. However determining the optimal criteria for selecting cluster heads is challenging, as it involves balancing energy efficiency, network connectivity, and load distribution. In this paper, a dual-phase approach is proposed, firstly Reinforcement learning (RL) approach has been applied to clustering in WSNs which enables nodes to autonomously adapt their clustering strategies, leading to more efficient and adaptive network configurations. Further Particle Swarm Optimization (PSO) can be utilized for cluster head selection in Wireless Sensor Networks (WSNs) to optimize the formation of clusters. The consideration of both local and global perspectives in the proposed approach results in a more balanced and efficient clustering solution. The outcomes of our experiments demonstrate the enhanced performance of the integrated approach as compared to traditional clustering algorithms. Results show considerable improvement in terms of reduced energy consumption, accuracy and efficiency in fault detection specifically tailored for Wireless Sensor Networks (WSNs). In addition the proposed algorithm show enhanced residual energy of the nodes compared to previous methods used.",none
"Deep Reinforcement Learning for intrusion detection in Internet of Things: Best practices, lessons learnt, and open challenges",https://dl.acm.org/doi/10.1016/j.comnet.2023.110016,1,article,ACM,2023,"The Internet of Things (IoT) scenario places important challenges even for deep learning-based intrusion detection systems. IoTs are highly heterogeneous networks in which multiple types of nodes and connections between them proliferate at a fast pace. From a deep learning perspective, such complexity translates into dynamic feature spaces where the extraction of semantic patterns and correlations among features may require sophisticated inductive biases to be learnt by gradient-based techniques. The research community has recently suggested using Deep Reinforcement Learning (DRL) as a potent approach to effectively identify cyber-threat attempts in IoTs.DRL consists of a Markov Decision Process-based meta-model that permits solving high-dimensional combinatorial optimization problems where differentiable supervisory signals may be absent. For this reason, multiple intelligent intrusion detection systems have been proposed for the IoT environment where high-level requirements are been pursued alongside the detection accuracy. These goals are related to optimizing the computational overhead, reducing power consumption at the edge, and preserving the privacy of sensitive information, among others.This survey offers a clear bird’s eye view of the most recent design choices for DRL-based intrusion detection systems with a focus on the specific context of IoT. Our aim is not only to offer an exhaustive taxonomy of design alternatives made by DRL practitioners in the field of Intrusion detection, but also to discuss the advantages and the effective deployment of each setting concerning real IoT environments. We hope this work would guide the researchers interested in Intrusion Detection for IoTs to establish solid criteria for the most effective usage of Deep Reinforcement Learning in their future work.Graphical abstractDisplay OmittedHighlights•Literature review on design of Intrusion Detection Systems for IoT based on Deep Reinforcement Learning.•Best practices, lessons learnt, and open challenges in this DRL research trend.•Conditions are identified upon which DRL may potentially benefit IoT Intrusion Detection pipelines.",none
Reinforcement learning based multi-parameter joint optimization in dense multi-hop wireless networks,https://dl.acm.org/doi/10.1016/j.adhoc.2023.103357,0,research-article,ACM,2024,"Carrier Sense Multiple Access with Collision Avoid (CSMA/CA) restricts the channel utilization efficiency although it always is regarded as a promising distributed channel access scheme, especially in dynamic dense wireless network scenarios. This paper investigates a Reinforcement Learning (RL) based multi-parameter joint optimization mechanism to build suitable access configuration for dense wireless multi-hop networks. Specifically, we propose a light-weight CSMA/CA mechanism based on Q-Learning (QL), namely QL-CSMA/CA, which jointly optimizes multiple channel access parameters, including Contention Window (CW), Maximum Backoff Exponent (MaxBE), and Maximum CSMA Backoffs (MaxCSMABackoffs), by setting mixed rewards and thus leading to higher network performance. Due to the limitation of the QL-CSMA/CA in large-scale state-space scenarios, we further present an enhanced CSMA/CA mechanism based on Deep Q-Network (DQN), namely DQN-CSMA/CA. Despite introducing a little complexity, the DQN-CSMA/CA can significantly improve transmission performance by utilizing more comprehensive network state information in complex dynamic network scenarios. Simulation results demonstrate the effectiveness of the proposed algorithms in terms of throughput, packet loss rate, delay, and collision rate, especially in high-density scenarios. Specifically, compared to SCAMA and traditional CSMA/CA algorithms, the QL-CSMA/CA algorithm achieves 9% and 5% performance improvements in terms of throughput, while DQN-CSMA/CA algorithm achieves 14% and 10% improvements in terms of throughput, respectively.",none
Reinforcement Learning Based Cluster Formation Algorithm in Wireless Sensor Networks,https://dl.acm.org/doi/10.1145/3654446.3654512,0,research-article,ACM,2024,"Wireless Sensor Networks (WSNs) play a pivotal role in various domains, offering various applications from environmental monitoring to industrial automation. Clustering is a fundamental technique that facilitates long-distance data transmission with minimal energy loss for energy-constrained sensor nodes. The selection of optimal cluster head (CH) profoundly impacts network performance by efficiently extending the network longevity. This paper presents a holistic clustering and CH selection algorithm for WSNs, which employs K-Means clustering to partition the network into distinct clusters. Moreover, we utilize a Soft Actor-Critic for Discrete Action Space (SAC-D) to dynamically assign CH for the dynamic real-time network. This reinforcement learning based approach optimizes CH selection and enhances the network lifespan. The simulation results show that the proposed algorithm outperforms the Low-Energy Adaptive Clustering Hierarchy (LEACH) and Energy-Aware Multi-Hop Multi-Path Hierarchical (EAMMH) protocols in terms of network lifespan, as indicated by average remaining energy and the number of dying nodes.",none
A novel reinforcement learning-based reptile search algorithm for solving optimization problems,https://dl.acm.org/doi/10.1007/s00521-023-09023-9,0,research-article,ACM,2023,"This work proposes a novel reptile search algorithm (RSA) to solve optimization problems called reinforcement reptile search algorithm (RLRSA). The basic RSA performs exploitation through highly walking in the first half of searching process while the exploration phase is executed through the hunting phase in the second half. Therefore, the algorithm is not able to balance exploration and exploitation and this behavior results in trapping in local optima. A novel learning method based on reinforcement learning and Q-learning model is proposed to balance the exploitation and exploration phases when the solution starts deteriorating. Furthermore, the random opposite-based learning (ROBL) is introduced to increase the diversity of the population and so enhance the obtained solutions. Twenty-three typical benchmark functions, including unimodal, multimodal and fixed-dimension multimodal functions, were employed to assess the performance of RLRSA. According to the findings, the RLRSA method surpasses the standard RSA approach in the majority of benchmark functions evaluated, specifically in 12 out of 13 unimodal functions, 9 out of 13 multimodal functions, and 8 out of 10 fixed multimodal functions. Furthermore, the RLRSA is applied to vessel solve pressure and tension/compression spring design problems. The results show that RLRSA significantly found the solution with minimum cost. The experimental results reveal the superiority of the RLRSA compared to RSA and other optimization methods in the literature.",none
Energy efficient secure data collection with path-constrained mobile sink in duty-cycled unattended wireless sensor network,https://dl.acm.org/doi/10.1016/j.pmcj.2019.02.002,2,research-article,ACM,2019,"This paper addresses the problem of secure data transmission and balanced energy consumption in an unattended wireless sensor network (UWSN) comprising of multiple static source nodes and a mobile sink in the presence of adversaries. The proposed system comprises of three phases: the identification of data collection points (convex nodes), path planning by the mobile sink, and secure data transmission. An energy-aware convex hull algorithm is used for the identification of data collection points for data transmission to the mobile sink. Data transmission from sensor nodes to the nearest data collection point is performed using multihop communication and from sensor nodes to the mobile sink in a single hop. Data are securely transmitted through an elliptic curve cryptography based ElGamal scheme for message authentication. A data packet is associated with a digital signature. The variation in a digital signature and threshold energy obtained using support vector machine is used to determine the presence of malicious nodes in the network. The performance of the proposed system is evaluated using Cooja simulator by Contiki for various node counts under a static sink and mobile sink, with different threat scenarios. The results indicate that the proposed system is resilient against threats and provides satisfactory performance",none
A review of cooperative multi-agent deep reinforcement learning,https://dl.acm.org/doi/10.1007/s10489-022-04105-y,10,research-article,ACM,2022,"Deep Reinforcement Learning has made significant progress in multi-agent systems in recent years. The aim of this review article is to provide an overview of recent approaches on Multi-Agent Reinforcement Learning (MARL) algorithms. Our classification of MARL approaches includes five categories for modeling and solving cooperative multi-agent reinforcement learning problems: (I) independent learners, (II) fully observable critics, (III) value function factorization, (IV) consensus, and (IV) learn to communicate. We first discuss each of these methods, their potential challenges, and how these challenges were mitigated in the relevant papers. Additionally, we make connections among different papers in each category if applicable. Next, we cover some new emerging research areas in MARL along with the relevant recent papers. In light of MARL’s recent success in real-world applications, we have dedicated a section to reviewing these applications and articles. This survey also provides a list of available environments for MARL research. Finally, the paper is concluded with proposals on possible research directions.",none
Lifetime maximization of wireless sensor network using fuzzy based unequal clustering and ACO based routing hybrid protocol,https://dl.acm.org/doi/10.1007/s10489-017-1077-y,23,article,ACM,2018,"Wireless Sensor Networks (WSN) became a key technology for a ubiquitous living and remains an active research due to the wide range of applications. The design of energy efficient WSN is still a greater research challenge. Clustering techniques have been widely used to reduce the energy consumption and prolong the network lifetime. This paper introduces an algorithm named Fuzzy logic based Unequal clustering, and Ant Colony Optimization (ACO) based Routing, Hybrid protocol for WSN to eliminate hot spot problem and extend the network lifetime. This protocol comprises of Cluster Head (CH) selection, inter-cluster routing and cluster maintenance. Fuzzy logic selects CHs efficiently and divides the network into unequal clusters based on residual energy, distance to Base Station (BS), distance to its neighbors, node degree and node centrality. It uses ACO based routing technique for efficient and reliable inter-cluster routing from CHs to BS. Moreover, this protocol transmits data in a hybrid manner, i.e. both proactive and reactive manner. A threshold concept is employed to transmit/intimate sudden changes in the environment in addition to periodic data transmission. For proper load balancing, a new routing strategy is also employed where threshold based data transmission takes place in shortest path and the periodic data transmission takes place in unused paths. Cross-layer cluster maintenance phase is also used for uniform load distribution. The proposed method is intensively experimented and compared with existing protocols namely LEACH, TEEN, DEEC and EAUCF. The simulation results show that the proposed method attains maximum lifetime, eliminates hot spot problem and balances the energy consumption among all nodes efficiently.",none
Cyber-security and reinforcement learning — A brief survey,https://dl.acm.org/doi/10.1016/j.engappai.2022.105116,3,article,ACM,2022,"This paper presents a comprehensive literature review on Reinforcement Learning (RL) techniques used in Intrusion Detection Systems (IDS), Intrusion Prevention Systems (IPS), Internet of Things (IoT) and Identity and Access Management (IAM). This study reviews scientific documents such as journals and articles, from 2010 to 2021, extracted from the Science Direct, ACM, IEEEXplore, and Springer database. Most of the research articles published in 2020 and 2021, for cybersecurity and RL are for IDS classifiers and resource optimization in IoTs. Some datasets used for training RL-based IDS algorithms are NSL-KDD, CICIDS, and AWID. There are few datasets and publications for IAM. The few that exist focus on the physical layer authentication. The current state of the art lacks standard evaluation criteria, however, we have identified parameters like detection rate, precision, and accuracy which can be used to compare the algorithms employing RL. This paper is suitable for new researchers, students, and beginners in the field of RL who want to learn about the field and identify problem areas.",none
Energy-efficiency and reliability in MAC and routing protocols for underwater wireless sensor network,https://dl.acm.org/doi/10.1016/j.jnca.2016.06.005,17,research-article,ACM,2016,"Underwater wireless sensor network (UWSN) technology has introduced a new flux to a whole gamut of application domains such as scientific exploration, commercial exploitation, underwater disaster prevention, etc. Such diversity of UWSN has gained prominence to the researchers quite fast and has marked this field of research as one of the emerging ones. With extensive researches conducted in this field, several design challenges have been experienced and explored by the network designers. Large propagation delay, low bandwidth, frequent loss of connectivity, variability of sound speed, limitation on source of energy, etc. are the key challenges, which are identified as necessary issues for establishing efficient and reliable UWSN. To address these issues, several MAC and routing protocols for UWSN have been proposed by the researchers during the last decade. In this review, the core design aspects for an ideal UWSN are identified which are energy-efficiency and reliability. These design aspects are evaluated in terms of energy consumption and communication efficiency - in order to provide an insight to the network designers on ideal design metrics. It is found that the protocols are highly selective, and the fitness of any protocol depends solely on the application and design requirements, which is addressed by this review. This paper also provides a comprehensive overview through comparison and simulation to analyze and summarize the MAC and routing protocols under concern.",none
Reinforcement learning for autonomous vehicle movements in wireless multimedia applications,https://dl.acm.org/doi/10.1016/j.pmcj.2023.101799,0,research-article,ACM,2023,"We develop a Deep Reinforcement Learning (DeepRL)-based, multi-agent algorithm to efficiently control autonomous vehicles that are typically used within the context of Wireless Sensor Networks (WSNs), in order to boost application performance. As an application example, we consider wireless acoustic sensor networks where a group of speakers move inside a room. In a traditional setup, microphones cannot move autonomously and are, e.g., located at fixed positions. We claim that autonomously moving microphones improve the application performance. To control these movements, we compare simple greedy heuristics against a DeepRL solution and show that the latter achieves best application performance.As the range of audio applications is broad and each has its own (subjective) performance metric, we replace those application metrics by two immediately observable ones: First, quality of information (QoI), which is used to measure the quality of sensed data (e.g., audio signal strength). Second, quality of service (QoS), which is used to measure the network’s performance when forwarding data (e.g., delay). In this context, we propose two multi-agent solutions (where one agent controls one microphone) and show that they perform similarly to a single-agent solution (where one agent controls all microphones and has a global knowledge). Moreover, we show via simulations and theoretical analysis how other parameters such as the number of microphones and their speed impacts performance.",none
Handling Coexistence of LoRa with Other Networks through Embedded Reinforcement Learning,https://dl.acm.org/doi/10.1145/3576842.3582383,2,research-article,ACM,2023,"The rapid growth of various Low-Power Wide-Area Network (LPWAN) technologies in the limited spectrum brings forth the challenge of their coexistence. Today, LPWANs are not equipped to handle this impending challenge. It is difficult to employ sophisticated media access control protocol for low-power nodes. Coexistence handling for WiFi or traditional short-range wireless network will not work for LPWANs. Due to long range, their nodes can be subject to an unprecedented number of hidden nodes, requiring highly energy-efficient techniques to handle such coexistence. In this paper, we address the coexistence problem for LoRa, a leading LPWAN technology. To improve the performance of a LoRa network under coexistence with many independent networks, we propose the design of a novel embedded learning agent based on a lightweight reinforcement learning at LoRa nodes. This is done by developing a Q-learning framework while ensuring minimal memory and computation overhead at LoRa nodes. The framework exploits transmission acknowledgments as feedback from the network based on what a node makes transmission decisions. To our knowledge, this is the first Q-learning approach for handling coexistence of low-power networks. Considering various coexistence scenarios of a LoRa network, we evaluate our approach through experiments indoors and outdoors. The outdoor results show that our Q-learning approach on average achieves an improvement of 46% in packet reception rate while reducing energy consumption by 66% in a LoRa network. In indoor experiments, we have observed some coexistence scenarios where a current LoRa network loses all the packets while our approach enables 99% packet reception rate with up to 90% improvement in energy consumption.",none
