title,link,number_of_citation,article_type,publisher,publication_date,abstract,keyword
Coverage Prediction for Target Coverage in WSN Using Machine Learning Approaches,https://dl.acm.org/doi/10.1007/s11277-024-11410-x,0,research-article,ACM,2024,"Mathematical programming techniques are widely used in the determination of optimal functional configuration of a wireless sensor network (WSN). But these techniques have usually high computational complexity and are often considered as Non Polynomial complete problem. Therefore, machine learning techniques can be utilized for the prediction of the WSN parameters with high accuracy and lesser computational complexity than the mathematical programming techniques. This paper focuses on developing the prediction model for determination of the node status to be included in the set cover based on the coverage probability and trust values of the nodes. The set covers are defined as the subset of nodes which are scheduled to monitor the region of interest with the desired coverage level. Several machine learning techniques have been used to determine the node activation status based on which the set covers are obtained. The results show that the random forest based prediction model yields the highest accuracy for the considered network setting.",none
A New Method to Find a High Reliable Route in IoT by Using Reinforcement Learning and Fuzzy Logic,https://dl.acm.org/doi/10.1007/s11277-020-07086-8,7,research-article,ACM,2020,"Recently, Internet is moving quickly toward the interaction of objects, computing devices, sensors, and which are usually indicated as the Internet of things (IoT). The main monitoring infrastructure of IoT systems main monitoring infrastructure of IoT systems is wireless sensor networks. A wireless sensor network is composed of a large number of sensor nodes. Each sensor node has sensing, computing, and wireless communication capability. The sensor nodes send the data to a sink or a base station by using wireless transmission techniques However, sensor network systems require suitable routing structure to optimizing the lifetime. For providing reasonable energy consumption and optimizing the lifetime of WSNs, novel, efficient and economical schemes should be developed. In this paper, for enhancing network lifetime, a novel energy-efficient mechanism is proposed based on fuzzy logic and reinforcement learning. The fuzzy logic system and reinforcement learning is based on the remained energies of the nodes on the routes, the available bandwidth and the distance to the sink. This study also compares the performance of the proposed method with the fuzzy logic method and IEEE 802.15.4 protocol. The simulations of the proposed method which were carried out by OPNET (Optimum Network performance) indicated that the proposed method performed better than other protocols such as fuzzy logic and IEEE802.15.4 in terms of power consumption and network lifetime.",none
A reinforcement learning-based sleep scheduling algorithm for cooperative computing in event-driven wireless sensor networks,https://dl.acm.org/doi/10.1016/j.adhoc.2022.102837,1,research-article,ACM,2022,"Emergency event monitoring is an important application of wireless sensor networks (WSNs). In the traditional cloud-assisted WSNs, the monitored data needs to be sent back to the cloud for processing. The round-trip of huge and burst data causes long delay and high energy consumption. With the increase of the computing capability of sensor nodes, local processing of events can be accomplished through cooperative computing between sensor nodes. However, if a node continues to undertake cooperative computing tasks, the energy consumption of nodes will be unbalanced and the network lifetime will be shortened. Sleep scheduling is an effective method to achieve energy balance, which can activate idle nodes alternately to participate in cooperative computing. In this paper, in order to make WSN more efficient to complete the local processing of events, we build a new system model based on node cooperative computing, and propose a multi-node Q learning-based cooperative computing node selection algorithm to obtain the sleep scheduling strategy. Simulation results show that compared with the classical algorithms, the proposed algorithm can complete more event processing, improve the reliability, and prolong the lifetime of WSNs.",none
Learning automaton-based energy-efficient and fault-tolerant topology evolution algorithm for underwater acoustic sensor network,https://dl.acm.org/doi/10.1016/j.jnca.2023.103690,1,research-article,ACM,2023,"With the development of Marine Internet of Things, underwater acoustic sensor network (UASN) has become a research focus. However, the energy of UASN nodes is limited, and the complex underwater environment is easy to cause the failure of UASN nodes, which will affect the normal operation of UASN. To address this issue, in this paper, an UASN energy-efficient and fault-tolerant topology is generated to prolong the node lifetime and improve the fault tolerance for node failure. Initially, the learning automaton is introduced and improved to optimize the transmission power of each node. Based on the optimized power of nodes, the node lifetime considering node load is analyzed. Then the preferential growth mechanism is improved to present the energy-efficient and fault-tolerant topology evolution algorithm. Consequently, the energy-efficient and fault-tolerant UASN topology is generated. In the simulation experiments, the selection criteria of parameters about transmission power and node load under different actual requirements is obtained, and the performance of generated topology is validated. Simulation results show that the fault tolerance and energy efficiency of generated topology in this paper outperforms the TCEB and PG-OSTCG topologies.",none
Energy-Efficient Clustering and Routing Algorithm Using Hybrid Fuzzy with Grey Wolf Optimization in Wireless Sensor Networks,https://dl.acm.org/doi/10.1155/2022/9846601,2,research-article,ACM,2022,"Wireless networking is popular due to the “3 any” concept: anyone, anytime, anywhere. Wireless communication technology advancements have covered the opportunities for sustainable development of low-power, low-cost, multipurpose sensor nodes in wireless sensor networks. In sensor networks, the network layer handles routing problems. Since radio transmission requires a significant amount of energy, it is essential to investigate power efficiency and optimization. As a result, the conservation of energy is a critical concern in wireless sensor networks. Recent research is focused on developing routing algorithms that use less amount of energy during communication, thereby prolonging the network’s life. Wireless sensor networks with energy recovery nodes use nodes that can extract energy from their environment. The fuzzy-GWO method and the energy-saving routing algorithm are proposed and analyzed in this research work. For simulation, the MATLAB 2021b working environment is used. The LEACH, HEED, MBC, FRLDG protocols, along with the proposed protocol F-GWO, are compared. From the obtained results, it is found that the network lifetime is increased by 20%, 14.8%, 12.5%, and 3.8%, respectively. In addition, the proposed method has a 37.5%, 33.3%, 16.6%, and 6.25% reduction in average energy consumption when compared with the conventional algorithms. According to the experimental data obtained through simulation, the proposed F-GWO algorithm outperforms the LEACH, HEED, MBC, and FRLDG in network lifetime, packet delivery ratio, throughput, bit error rate (BER), buffer occupancy, time analysis, and end-to-end delay.",none
Cooperative Channel Selection With Q-Reinforcement Learning and Power Distribution in Cognitive Radio Networks,https://dl.acm.org/doi/10.4018/IJACI.2021100102,1,article,ACM,2021,"With the increasing number of wireless communication devices, there may be a shortage of non-licensed spectrum, and at the same time, licensed spectrum may be underutilized by the primary users. The utilization of licensed spectrum can be improved using cognitive radio techniques. The proposed work allows secondary users to use the correct slot period of the channel as per their need. Particle swarm optimization technique is used to optimize the resource allocation. The aim of the proposed work is to determine the optimal throughput and power of available channels between the communicating nodes and improve the routing performance by selecting the best channel. Mathematical equation is derived that represents the channel selection relationship from the Q-value, congestion throughput, and benefit value. Network simulator-2 is used to simulate the proposed work and compared with the existing work. From the simulation results, it is observed that routing performance is improved in terms of throughput, packet delivery ratio, delay, packet dropped, and normalized routing overhead.",none
DRL-M4MR: An intelligent multicast routing approach based on DQN deep reinforcement learning in SDN,https://dl.acm.org/doi/10.1016/j.phycom.2022.101919,1,research-article,ACM,2022,"Traditional multicast routing methods have some problems in constructing a multicast tree. These problems include limited access to network state information, poor adaptability to dynamic and complex changes in the network, and inflexible data forwarding. To address these defects, the optimal multicast routing problem in software-defined networking (SDN) is tailored as a multiobjective optimization problem, and DRL-M4MR, an intelligent multicast routing algorithm based on the deep Q network (DQN) deep reinforcement learning (DRL) method is designed to construct a multicast tree in a software-defined network. First, combining the characteristics of SDN global network-aware information, the multicast tree state matrix, link bandwidth matrix, link delay matrix and link packet loss rate matrix are designed as the state space of the reinforcement learning agent to solve the problem in that the original method cannot make full use of network status information. Second, the action space of the agent is all the links in the network, and the action selection strategy is designed to add the links to the current multicast tree in four cases. Third, single-step and final reward function forms are designed to guide the agent to make decisions to construct the optimal multicast tree. The double network architectures, dueling network architectures and prioritized experience replay are adopted to improve the learning efficiency and convergence of the agent. Finally, after the DRL-M4MR agent is trained, the SDN controller installs the multicast flow entries by reversely traversing the multicast tree to the SDN switches to implement intelligent multicast routing. The experimental results show that, compared with existing algorithms, the multicast tree constructed by DRL-M4MR can obtain better bandwidth, delay, and packet loss rate performance after training, and it can make more intelligent multicast routing decisions in a dynamic network environment. Code and DRL model are available at https://github.com/GuetYe/DRL-M4MR.",none
Scaling configuration of energy harvesting sensors with reinforcement learning,https://dl.acm.org/doi/10.1145/3279755.3279760,25,research-article,ACM,2018,"With the advent of the Internet of Things (IoT), an increasing number of energy harvesting methods are being used to supplement or supplant battery based sensors. Energy harvesting sensors need to be configured according to the application, hardware, and environmental conditions to maximize their usefulness. As of today, the configuration of sensors is either manual or heuristics based, requiring valuable domain expertise. Reinforcement learning (RL) is a promising approach to automate configuration and efficiently scale IoT deployments, but it is not yet adopted in practice. We propose solutions to bridge this gap: reduce the training phase of RL so that nodes are operational within a short time after deployment and reduce the computational requirements to scale to large deployments. We focus on configuration of the sampling rate of indoor solar panel based energy harvesting sensors. We created a simulator based on 3 months of data collected from 5 sensor nodes subject to different lighting conditions. Our simulation results show that RL can effectively learn energy availability patterns and configure the sampling rate of the sensor nodes to maximize the sensing data while ensuring that energy storage is not depleted. The nodes can be operational within the first day by using our methods. We show that it is possible to reduce the number of RL policies by using a single policy for nodes that share similar lighting conditions.",none
SDN Flow Entry Management Using Reinforcement Learning,https://dl.acm.org/doi/10.1145/3281032,37,research-article,ACM,2018,"Modern information technology services largely depend on cloud infrastructures to provide their services. These cloud infrastructures are built on top of Datacenter Networks (DCNs) constructed with high-speed links, fast switching gear, and redundancy to offer better flexibility and resiliency. In this environment, network traffic includes long-lived (elephant) and short-lived (mice) flows with partitioned/aggregated traffic patterns. Although SDN-based approaches can efficiently allocate networking resources for such flows, the overhead due to network reconfiguration can be significant. With limited capacity of Ternary Content-Addressable Memory (TCAM) deployed in an OpenFlow enabled switch, it is crucial to determine which forwarding rules should remain in the flow table and which rules should be processed by the SDN controller in case of a table-miss on the SDN switch. This is needed in order to obtain the flow entries that satisfy the goal of reducing the long-term control plane overhead introduced between the controller and the switches. To achieve this goal, we propose a machine learning technique that utilizes two variations of Reinforcement Learning (RL) algorithms—the first of which is a traditional RL-based algorithm, while the other is deep reinforcement learning-based. Emulation results using the RL algorithm show around 60% improvement in reducing the long-term control plane overhead and around 14% improvement in the table-hit ratio compared to the Multiple Bloom Filters (MBF) method, given a fixed size flow table of 4KB.",none
Research on energy-efficient routing algorithm based on SWIPT in multi-hop clustered WSN for 5G system,https://dl.acm.org/doi/10.1186/s13638-021-01931-5,1,research-article,ACM,2021,"As one of the basic supporting technologies of 5G system, wireless sensor networks technology is facing a new challenge to improve its transmission energy efficiency. This paper considers combining simultaneous wireless information and power transfer (SWIPT) technique and routing technique, and applying them to multi-hop clustered wireless sensor networks (MCWSN), where each node can decode information and harvest energy from a received radio-frequency signal. And the relay nodes in MCWSN can utilize the harvest energy to forward data to their next hop nodes according to the routing scheme. First, we formulate an energy-efficient routing problem of MCWSN with SWIPT. Then, a heuristic energy efficient cooperative SWIPT routing algorithm (EECSR) is presented to find a transmission path with the maximum energy efficiency. Specifically, in EECSR, the resource allocation problem in each hop of the path is transformed to some equivalent convex optimization problems, which are resolved via dual decomposition. Moreover, a distributed routing protocol based on EECSR is proposed. As far as we know, this is the first solution that considers energy efficiency optimization based on routing and SWIPT in MCWSN. Simulation results show that our EECSR algorithm has high energy efficiency and good robustness. And our distributed routing protocol has better real-time performance than traditional protocols.",none
A Reinforcement Learning-Based Dynamic Clustering Algorithm for Compressive Data Gathering in Wireless Sensor Networks,https://dl.acm.org/doi/10.1155/2022/2736734,0,research-article,ACM,2022,"Compressive data gathering (CDG) is an effective technique to handle large amounts of data transmissions in resource-constrained wireless sensor networks (WSNs). However, CDG with static clustering cannot adapt to time-varying environments in WSNs. In this paper, a reinforcement learning-based dynamic clustering algorithm (RLDCA) for CDG in WSNs is proposed. It is a dynamic and adaptive clustering method aiming to further reduce data transmissions and energy consumption in WSNs. Sensor nodes act as reinforcement learning (RL) agents which can observe the environment and dynamically select a cluster to join in. These RL agents are instructed by a well-designed reward scheme to join a cluster with strong data correlation and proper distance. It is also a distributed and lightweight learning method. All agents are independent and operate in parallel. Additional overheads introduced by RL are lightweight. Computations of a linear reward function and a few comparison operations are needed. It is implementable in WSNs. Simulations performed in MATLAB validate the effectiveness of the proposed method and simulation results show that the proposed algorithm achieves the desired effect as well as fine convergence. It decreases data transmissions by 16.6% and 54.4% and energy consumption by 6% and 29%, respectively, compared to the two contrastive schemes.",none
Associative Zone Based Energy Balancing Routing for Expanding Energy Efficient and Routing Optimization Over the Sensor Network,https://dl.acm.org/doi/10.1007/s11277-021-09443-7,1,research-article,ACM,2022,"Wireless sensor networks (WSNs) have become hugely popular as security surveillance is used by the public and industries in a variety of real-time applications. The development of wireless sensor networks that strengthen the life cycle of their network through energy saving is an important issue. Due to the low resource development of the sensor terminals, they must be used intelligently and efficiently. Although the previous methods have provided better data collection and power optimization, there are some issues with the routing optimization that could not be improved. To overcome this problem, an Associative Zone Based Energy Balancing Routing (AZEBR) with Adaptive Maximization Dijkstra’s shortest path algorithm is proposed for optimized routing over the network. This proposed AZEBR method evaluates the node distance and energy of each node by selecting the performance of balance nodes. Equal amount of transmission and energy are to be maintained in every transmission. There are two special nodes for each zone selected from the center of the zone with radius (r) and a higher residual energy it is called as Associated Wise Zone (AWZ) and centered zone head (CZH). Adaptive Maximization Dijkstra’s shortest path is to solve the problem from the source to the target. New technology performance is evaluated using a network emulator (NS2). Compared to the average pocket transfer rate and index, the proposed method’s simulation results prove that AZEBR provides less delay and higher performance compared to network lifetime.",none
Fuzzy-Cross: A fuzzy based architecture for wireless sensor network,https://dl.acm.org/doi/10.3233/JCM-150594,0,research-article,ACM,2015,"This paper introduces Fuzzy-Cross, a decision making and information-sharing architecture for wireless sensor networks (WSN) that enables the protocols to achieve energy efficiency, reliability, and low data latency. FUCR retains a layered structure with each layer matching to a communication function to provide a practical and simple design. The administrative plane provided by FUCR collects residual energy from physical layer, data delivery, and channel assessment records from data link layer, packet dispatch rate from network layer and sensitivity of sensing unit from application layer. The information collected is used as input descriptors for running fuzzy logic. Output of the fuzzy logic assists physical layer protocol to decide node's transmit power; data link layer protocol to decide retransmission time out, back off time and duty cycle; network layer to determine chance of the node to become a relay node and application layer to determine chance of node to become a reporting node. To investigate the extent to which Fuzzy-Cross meets its goals, it is implemented on top of ZigBee standard. Simulation results demonstrated that Fuzzy-Cross with ZigBee outperforms both (i) ADaptive Access Parameters Tuning (ADAPT) with Zigbee and (ii) standard ZigBee without any modifcations. For a single hop network Fuzzy-Cross is up to 12% more energy efficient compared to ADAPT. Delivery ratio of Fuzzy-Cross is up to 12% more and data latency is up to 19% less compared to ADAPT. Similar trend is seen for multi-hop network and for a wide range of operating conditions.",none
A distributed coverage hole recovery approach based on reinforcement learning for Wireless Sensor Networks,https://dl.acm.org/doi/10.1016/j.adhoc.2020.102082,5,research-article,ACM,2020,"In Wireless Sensor Networks (WSNs), various anomalies may arise and reduce their reliability and efficiency. For example, Coverage Hole can occur in such networks due to several causes, such as damaging events, sensors battery exhaustion, hardware failure, and software bugs. Modern trends to use relocation of deployed sensor nodes when the manual addition of nodes is neither doable nor economical in many applications have attracted attention. The lack of central supervision and control in harsh and hostile environments have encouraged researchers to shift from centralized to distributed node relocation schemes. In this paper, a new game theory approach based on reinforcement learning to recover Coverage Holes in a distributed way is proposed. For the formulated potential game, sensor nodes can recover Coverage Holes using only local acquaintances. To reduce the coverage gaps, the combined action of node reposition and sensing range adjustment is chosen by each sensor node. The simulation results prove that, unlike previous methods, the proposed approach can sustain a network overall coverage in the presence of random damage events.",none
Dynamic collaborative optimization of end-to-end delay and power consumption in wireless sensor networks for smart distribution grids,https://dl.acm.org/doi/10.1016/j.comcom.2023.02.016,0,research-article,ACM,2023,"Wireless sensor network (WSN) technology is poised to be widely adopted in the smart distribution grid (SDG), which has strict requirements regarding communication delays. However, delays in WSNs are easily affected by dynamic interference factors (such as channel access competition, transmitting power, and node failure), and these dynamic characteristics make the traditional offline optimization methods unsuitable. Besides, the reinforcement learning (RL) based online optimization methods have dimension explosion and convergence problems. In this paper, we propose a dynamic collaborative optimization of the end-to-end delay and power consumption of the WSNs based on grouped RL. In particular, we first build an environment model for evaluating the values of the optimization objective. Those values are used to calculate the rewards for the RL algorithm. To accelerate the convergence of RL swamped by the dimensions of the action space, a novel grouped RL is proposed. Then iterative learning is performed to balance the end-to-end delay and power consumption by adjusting the transmitting power of each node. The simulation results show that the proposed algorithm is able to meet the SDG delay requirements with low power consumption when the communication is dynamically affected. The developed algorithm achieves a maximum end-to-end delay reduction of 20.3% and a computational cost reduction of 6.2% to 52.7% compared with the other two RL algorithms.",none
A source-driven reinforcement learning-based Data reply strategy to reduce communication overhead in Named Data Networks (NDN),https://dl.acm.org/doi/10.1007/s10586-021-03443-9,0,research-article,ACM,2022,"The Two-Armed Bernoulli Bandit (TABB) problem is an orthodox optimization dilemma in reinforcement learning discipline where a decision-maker or agent is repeatedly faced with a choice of two actions (options). Every time the agent selects an action, it receives a corresponding payoff from an unknown distribution. Thus, the agent must trade-off between exploration of new better action and exploitation of current best action. Content retrieval in Named Data Networks (NDN) commences with a consumer requesting the desired content by sending an Interest that hits multiple content sources over different paths. As the corresponding Interest arrives, the content sources respond by replying the matching Data to the requester. In this work, Data replying problem in NDN is considered a TABB problem, denoted as DTABB. Since numerous sources are available, a content source in DTABB can choose between responding with entire content and partial content once the corresponding Interest strikes. The best source is trained to answer with complete data, while other (sub-optimal) sources learn to react with partial (or payload-free) data. The proposed strategy is formulated from a source’s viewpoint, which uses four prominent reinforcement learning algorithms: greedy, ε-greedy, Upper Confidence Bound (UCB1), and Gradient Bandit to select the optimal action. Eventually, the network picture converges to a point where a single source is exploited for whole data while others send only partial data. Thus, DTABB can substantially reduce the transmission overhead and enjoy a better user experience in terms of delay. DTABB is implemented in ndnSIM, which reveals that the proposed solution can reduce the communication overhead by up to 40% compared to the default strategy.",none
An innovative routing algorithm with reinforcement learning and pattern tree adjustment for wireless sensor networks,https://dl.acm.org/doi/10.5555/1948072.1948123,0,Article,ACM,2010,"This paper proposes a new routing algorithm for wireless sensor network. The algorithm uses reinforcement learning and pattern tree adjustment to select the routing path for data transmission. The former uses Q value of each sensor node to reward or punish the node in the transmission path. The factor of Q value includes past transmission path, energy consuming, transmission reword to make the node intelligent. The latter then uses the Q value to real-time change the structure of the pattern tree to increase successful times of data transmission. The pattern tree is constructed according to the fusion history transmission data and fusion benefit. We use frequent pattern mining to build the fusion benefit pattern tree. The experimental results show that the algorithm can improve the data transmission rate by dynamic adjustment the transmission path.",none
MLSTL-WSN: machine learning-based intrusion detection using SMOTETomek in WSNs,https://dl.acm.org/doi/10.1007/s10207-024-00833-z,0,research-article,ACM,2024,"In the domain of cyber-physical systems, wireless sensor networks (WSNs) play a pivotal role as infrastructures, encompassing both stationary and mobile sensors. These sensors self-organize and establish multi-hop connections for communication, collectively sensing, gathering, processing, and transmitting data about their surroundings. Despite their significance, WSNs face rapid and detrimental attacks that can disrupt functionality. Existing intrusion detection methods for WSNs encounter challenges such as low detection rates, computational overhead, and false alarms. These issues stem from sensor node resource constraints, data redundancy, and high correlation within the network. To address these challenges, we propose an innovative intrusion detection approach that integrates machine learning (ML) techniques with the Synthetic Minority Oversampling Technique Tomek Link (SMOTE-TomekLink) algorithm. This blend synthesizes minority instances and eliminates Tomek links, resulting in a balanced dataset that significantly enhances detection accuracy in WSNs. Additionally, we incorporate feature scaling through standardization to render input features consistent and scalable, facilitating more precise training and detection. To counteract imbalanced WSN datasets, we employ the SMOTE-Tomek resampling technique, mitigating overfitting and underfitting issues. Our comprehensive evaluation, using the wireless sensor network dataset (WSN-DS) containing 374,661 records, identifies the optimal model for intrusion detection in WSNs. The standout outcome of our research is the remarkable performance of our model. In binary classification scenarios, it achieves an accuracy rate of 99.78%, and in multiclass classification scenarios, it attains an exceptional accuracy rate of 99.92%. These findings underscore the efficiency and superiority of our proposal in the context of WSN intrusion detection, showcasing its effectiveness in detecting and mitigating intrusions in WSNs.",none
MRL-SCSO: Multi-agent Reinforcement Learning-Based Self-Configuration and Self-Optimization Protocol for Unattended Wireless Sensor Networks,https://dl.acm.org/doi/10.1007/s11277-016-3729-3,2,article,ACM,2017,"Resource-constrained nodes in unattended wireless sensor network (UWSN) operate in a hostile environment with less human intervention. Achieving the optimal quality of service (QoS) in terms of packet delivery ratio, delay, energy, and throughput is crucial. In this paper, we propose a topology control and data dissemination protocol that uses multi-agent reinforcement learning (MRL) and energy-aware convex-hull algorithm, for effective self-configuration and self-optimization (SCSO) in UWSN, called MRL-SCSO. MRL-SCSO maintains a reliable topology in which the effective active neighbor nodes are selected using MRL. The network boundary is determined using convex-hull algorithm to maintain the connectivity and coverage of the network. The boundary nodes transmit data under high traffic load conditions. The performance of MRL-SCSO is evaluated for various nodes count and under different load conditions by using the Contiki's Cooja simulator. The results showed that MRL-SCSO stabilizes the performance and improves QoS.",none
Stochastic-Reinforcement Learning Assisted Dynamic Power Management Model for Zone-Routing Protocol in Mobile Ad Hoc Networks,https://dl.acm.org/doi/10.1007/s11277-021-08448-6,0,research-article,ACM,2021,"The Zone Routing Protocol of Mobile Ad Hoc Networks is one of the most reliable and efficient routing protocols. However, maintaining Quality of Service, energy-efficiency and optimal resource management is of utmost importance to provide timely and reliable communication services. In this paper, a highly robust and efficient reinforcement learning based Dynamic Power Management (DPM) and Switching control strategy is developed. Unlike classical DPM models, our proposed model employs both system layer information and PHY layer information to perform stochastic prediction to schedule PHY switching. Here, we have applied both known and unknown node/network parameters such as node’s holding period, Bit Error Probability to perform stochastic prediction. Our proposed model intends to maintain minimum BEP and holding period while assuring maximum resource utilization. To achieve it, the overall DPM model is formulated as Controlled Markov decision process, where employing hidden Markov model with Lagrange relaxation and cost function we achieved optimal resource allocation without compromising transmission quality, latency or computational costs. Through simulation-based evaluations, the proposed model outperforms the classical learning models by 50% reduction in PHY Transmission Action, 94% lower cost consumption, 83% decrease in buffer cost/delay and 94% reduction on packet overflow.",none
