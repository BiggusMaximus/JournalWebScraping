title,link,number_of_citation,article_type,publisher,publication_date,abstract,keyword
Real-time routing algorithm for mobile ad hoc networks using reinforcement learning and heuristic algorithms,https://dl.acm.org/doi/10.1007/s11276-015-1180-0,12,article,ACM,2017,"Mobile ad hoc networks (MANETs) consist of a set of nodes which can move freely and communicate with each other wirelessly. Due to the movement of nodes and unlike wired networks, the available routes used among the nodes for transmitting data packets are not stable. Hence, proposing real-time routing protocols for MANETs is regarded as one of the major challenges in this research domain. Algorithms compatible with the changes created in the network due to the nodes' movements are of high significance. For reducing data packet transmission time among nodes, not only should route shortness be considered but also route stability should be taken into consideration. Since available factors in different environments have specific behavior patterns especially in human environments, the parameters of link stability and route shortness were taken into consideration and the reinforcement learning was used to propose a method so as to make the best choice among the neighbors at any moment to transmit a packet to the destination. That is, the proposed method was aimed at predicting the behavior pattern of the nodes in relation to the target node through using reinforcement learning. The proposed method used Q-learning algorithm which has more homogeneity to estimate the value of actions. Simulation results in OPNET demonstrate the superiority of the proposed scheme over conventional MANET routing methods.",none
KESAR: A High-Accuracy Prediction Algorithm and Solar-Aware Routing Strategy for Outdoor WSN,https://dl.acm.org/doi/10.1007/978-3-030-86137-7_56,0,Article,ACM,2021,"The high energy density of sunlight makes solar wireless sensor networks (WSN) have advantages in outdoor monitoring applications. Two key technologies are applied: 1) Solar energy prediction and 2) Energy-aware routing strategy. Affected by frequently changing weather, shadows of buildings, trees, and other factors, the accuracy of existing prediction algorithms is relatively low, and the lifetime is not very satisfactory when the existing predictions are used as a support basis for routing. Thus, this paper proposes a prediction algorithm based on revised machine learning, and propose an adjustable routing strategy to achieve long-term stable monitoring. Experimental results show that the accuracy of prediction can be increased by up to 72.7%, and the network lifetime can be extended by at least 9.8%.",none
The Application Research of Distributed Interface Coordination Based on Deep Reinforcement Learning in English MOOC Platform,https://dl.acm.org/doi/10.1145/3614428,0,research-article,ACM,2023,"Developing information technology and other business management firms is not the same as technological advancement. The only way we can declare that complete technical progress is in place and operating well in the nation is if the education system has been built. The educational system is set up to instruct pupils via wireless technologies and online classes. Advancement in online classes has resulted in the Massive Open Online Courses (MOOC) Platform. The advantage of the MOOC platform is that it is a platform that provides free online courses for anyone to register and continue the course at their own pace. On this MOOC platform, implementing Deep Reinforcement Learning (DRL) aids in choosing the course and learning through an intelligent mechanism. The transmission between students and teachers will significantly rise because of this teaching strategy through the Distributed Interface Coordination (DIC) mechanism where the resources are distributed in the wireless networking environment. Additionally, the registered students should possess privileges to access the resources. This combination of DIC with DRL can be termed as DIC-DRL model for the proposed system. The data was collected using a low packet rate and outdated wireless connection technologies. The suggested model has a 97.67 percent accuracy rate in comparison with the existing model's support vector machine (SVM) mechanism.",none
A block-aware hybrid data dissemination with hotspot elimination in wireless sensor network,https://dl.acm.org/doi/10.1016/j.jnca.2014.05.006,0,article,ACM,2014,"As a significant milestone in the data dissemination of wireless sensor networks (WSNs), the comb-needle (CN) model was developed to dynamically balance the sensor data pushing and pulling during hybrid data dissemination. Unfortunately, the hybrid push-pull data dissemination strategy may overload some sensor nodes and form the hotspots that consume energy significantly. This usually leads to the collapse of the network at a very early stage. In the past decade, although many energy-aware dynamic data dissemination methods have been proposed to alleviate the hotspots issue, the block characteristic of sensor nodes has been overlooked and how to offload traffic from hot blocks with low energy through long-distance hybrid dissemination remains an open problem. In this paper, we developed a block-aware data dissemination model to balance the inter-block energy and eliminate the spreading of intra-block hotspots. Through the clustering mechanism based on geography and energy, ''similar'' large-scale sensor nodes can be efficiently grouped into specific blocks to form the global block information (GBI). Based on GBI, the long-distance block-cross hybrid algorithms are further developed by effectively aggregating inter-block and intra-block data disseminations. Extensive experimental results demonstrate the capability and the efficiency of the proposed approach.",none
Reinforcement learning based effective communication strategies for energy harvested WBAN,https://dl.acm.org/doi/10.1016/j.adhoc.2022.102880,2,research-article,ACM,2022,"This paper proposes effective communication strategies for Wireless Body Area Networks (WBANs) that consist of wearable or implantable sensor nodes placed in, on/around the human body to send body vitals to a sink. The main research challenges for communication strategy formulation include limited energy resources and varying link conditions. Though energy harvested sensor nodes partially address the problem of energy efficiency, finding an optimal balance between the energy constraint of the nodes and communication reliability is still challenging. Since data loss in such networks may prove to be fatal, it is important to investigate the problem prior to deployment and come up with effective communication strategies for initiating post-deployment operations. Hence, in this paper, the nodes are stochastically modeled as a Markov Decision Process. There is a need to adapt to the changing ambient conditions through exploration and exploitation. So, a modified Q-learning technique is proposed for post-deployment decision-making by the WBAN nodes subject to the dynamic ambient conditions. The effectiveness of the proposed strategy is validated through extensive simulation and compared with state-of-the-art works. The performance of the proposed approach is also verified with a real-life dataset. The results demonstrate that around 90% successful data delivery to sink could be made with the proposed scheme in the real-life scenario.",none
Multi-granularity fusion resource allocation algorithm based on dual-attention deep reinforcement learning and lifelong learning architecture in heterogeneous IIoT,https://dl.acm.org/doi/10.1016/j.inffus.2023.101871,1,research-article,ACM,2023,"Deep reinforcement learning (DRL) is a promising technology to address the resource allocation problem for efficient data transmission in complex network environments. However, most DRL-based resource allocation algorithms suffer from limited feature extraction capabilities and lack scalability and generalization, especially in heterogeneous Industrial Internet of Things (IIoT) environments. In this paper, we develop a lifelong learning architecture that can integrate artificial intelligence (AI) algorithms into the heterogeneous IIoT network for efficient data transmission. Based on this, we propose an intelligent resource allocation algorithm based on dual-attention DRL (DADR) for forwarding node selection and channel access slot allocation in a specific network environment. The proposed DADR algorithm combines the advantages of multi-dimension convolutional attention and multi-head self-attention mechanisms. It can provide local- and global-feature fusion capabilities for distributed nodes while maximizing the performance of data transmission. Furthermore, we present a lifelong federated meta reinforcement learning (LFMRL) that can effectively utilize prior knowledge and enable the DRL agent quickly adapt to a new environment. Specifically, LFMRL adopts a federated meta learning-based knowledge fusion algorithm to fuse the knowledge of learned DADR algorithms and iteratively update the shared model, thereby improving the scalability and generalization of the shared model in heterogeneous IIoT environments. In addition, a simple and efficient knowledge transfer mechanism is enabled to accelerate the DRL model convergence by transferring the knowledge of the shared model to the new environment. Simulation results demonstrate the effectiveness of the proposed algorithms in terms of energy efficiency, data transmission reliability, and network stability. Compared to DADR and FedAvg algorithms, LFMRL algorithm can further reduce the energy consumption, training time, and average forwarding node switching times, while improving packet delivery rate to 99.2%.Highlights•A novel lifelong learning architecture for resource allocation in heterogeneous IIoT.•Dual-attention deep reinforcement learning provides local- and global- feature fusion.•Federated meta learning based knowledge fusion learns the commonness of models.•Reinforcement learning based knowledge transfer learns the properties of model.•Knowledge fusion and knowledge transfer provide lifelong learning ability for system.",none
Design of wireless sensor network node for carbon monoxide monitoring,https://dl.acm.org/doi/10.1007/s11235-013-9675-4,1,article,ACM,2013,"Aim at protecting environment, a design proposal of Wireless Sensor Network (WSN) node for remote monitoring Carbon Monoxide is presented. The monitoring node uses a low-power SOC microprocessor C8051F930 who acts as a controller, utilizes Carbon Monoxide metal oxide (MOX) semiconductor sensor whose detective principle is that MOX semiconductor has redox reactions with CO and its resistance varies with gas concentration when it is heated, perceiving local CO concentration, conditioning the collected CO signals from the sensor, converting and processing datas, etc. The datas can be transmitted to Sink by high-performance wireless radio frequency chip Si4432 which supports for communication protocol IEEE 802.15.4, and Sink uses GPRS to send them remotely to the mobile network, realizing remote monitoring CO.",none
WOAD3QN-RP: An intelligent routing protocol in wireless sensor networks — A swarm intelligence and deep reinforcement learning based approach,https://dl.acm.org/doi/10.1016/j.eswa.2023.123089,0,research-article,ACM,2024,"Wireless Sensor Networks (WSN) are a crucial part of the Internet of Things (IoT), and research on WSN routing protocols has always been a hot topic in academia. However, traditional WSN routing protocols have limited utilization of available information during the routing decision process, leading to challenges such as insufficient adaptability to network topology changes, high communication delays, and short network lifetimes. To address these issues, this paper proposes an innovative intelligent routing algorithm WOAD3QN-RP, which cleverly integrates swarm intelligence algorithms and deep reinforcement learning. The WOAD3QN-RP not only effectively reduces delay but also balances energy consumption and flexibly adapts to changes in network topology, while simultaneously determining the optimal multi-hop path, effectively extending the lifetime of the network. Firstly, the WOAD3QN-RP algorithm employs the Whale Optimization Algorithm (WOA) to determine the optimal cluster heads (CHs). In the process of selecting CHs, the algorithm comprehensively considers key factors such as the residual energy of nodes, node distance, and communication delay, thereby significantly improving the accuracy and efficiency of CH selection, which contributes to better energy distribution and performance of the network. Secondly, in terms of multi-hop path selection, WOAD3QN-RP uses a dueling double deep Q-network (D3QN) to determine the optimal multi-hop path. Through utilizing neural networks to interact with the environment, intelligent agents are trained to learn routing policies to adapt to dynamic changes in the network topology and ensure the balance between energy consumption and multi-hop routing performance. Experimental results show that WOAD3QN-RP exhibits significant advantages over existing routing protocols in terms of network lifetime, energy efficiency, and communication delay.Highlights•Novel cluster head selection algorithm using the whale optimization algorithm.•Novel intelligent multi-hop path selection using deep reinforcement learning.•Enhancing intelligence and performance of wireless sensor networks.•Simulation results reveal the effectiveness and adaptivity of routing protocol.",none
Security enhanced optimal trajectory selection for mobile sink using reinforcement learning,https://dl.acm.org/doi/10.3233/JIFS-212557,0,research-article,ACM,2022,"Wireless visual sensor networks (WVSNs) have emerged as a strategic inter disciplinary category of WSN with its visual sensor based intelligence that has garnered considerable attention. The growing demand for energy efficient and maximized life time networks in highly critical applications like surveillance, military and medicine has opened up more prospects as well as challenges in the deployment of WVSNs. Multi-hop communication in WVSN results in overloading of intermediate sensor nodes due to its dual function in the network which results in hotspot effect. This can be mitigated with the help of mobile sinks and rendezvous points based route design. But mobile sinks has to visit every cluster head to gather data which results in longer traversal path and higher latency and power consumption related issues if not addressed properly will impact the performance of the network. Our objective is to analyze and determine the optimal trajectory for mobile sink node traversal with the help of a high quality transmission architecture integrated with reinforcement learning and isolation forest based anomaly detection to propose an energy efficient meta-heuristic approach to enhance the performance of network by reducing the latency and securing the network against possible attacks.",none
Reinforcement learning-based dynamic routing using mobile sink for data collection in WSNs and IoT applications,https://dl.acm.org/doi/10.1016/j.jnca.2021.103223,6,research-article,ACM,2021,"Energy is one of the most critical resources for sensor devices that decides the network lifetime of the wireless sensor networks. In many circumstances, sensor devices consume more energy for data transmission, reception, and forwarding operations. The major challenge is to increase the network lifetime by implementing the latest research models to reduce the deployment and operational cost. Many existing methods address the application of the static sink with multi-hop routing. But most of them suffer from energy-hole issues and inefficient data collection due to the early death of sensor nodes. Most of the existing methods of learning require massive data with feature engineering which eventually increases the learning complexity. In order to avoid these issues, a robust reinforcement learning-based mobile sink model is proposed for dynamic routing with efficient data collection. In addition, the Q-Learning approach is implemented to induce automatic learning through the shortest route. Combining these strategies preserves network stability and efficiently improves the routing performance as well as the reward. The simulation results reveal that the proposed reinforcement learning-based mobile sink model extends the network lifetime, provides an improved learning time with more reward, and results in high efficiency when compared with existing methods.",none
Dynamic energy scheduling and routing of a large fleet of electric vehicles using multi-agent reinforcement learning,https://dl.acm.org/doi/10.1016/j.cie.2022.108180,1,research-article,ACM,2022,"ts•An vehicle routing and energy scheduling decision model is developed.•The proposed model enables a flexable energy sharing among a large number of EV’s.•The proposed algorithm outperforms heuristic algorithms in terms of solution quality.•The proposed model is more computational efficient than heuristic algorithms and CRL.•The proposed algorithm output less solution quality compared to CRL.AbstractAs the world’s population and economy grow, demand for energy increases as well. Smart grids can be a cost-effective solution to overcome increases in energy demand and ensure power security. Current applications of smart grids involve a large numbers of agents (e.g., electric vehicles). Since each agent must interact with other agents when taking decisions (e.g., movement and scheduling), the computational complexity of smart grid systems increases exponentially with the number of agents. Computational tractability of planning is a significant barrier to implementation of large-scale smart grids of electric vehicles.Existing solution approaches such as mixed-integer programming and dynamic programming are not computationally efficient for high-dimensional problems. This paper proposes a reformulation of a Mixed-Integer Programming model into a Decentralized Markov Decision Process model and solves it using a Multi-Agent Reinforcement Learning algorithm to address the scalability issues of large-scale smart grid systems. The Decentralized Markov Decision Process model uses centralized training and distributed execution: agents are trained using a unique actor network for each agent and a shared critic network, and then agent execute actions independently from other agents to reduce computation time. The performance of the Multi-Agent Reinforcement Learning model is assessed under different configurations of customers and electric vehicles, and compared to the results from deep reinforcement learning and three heuristic algorithms. The simulation results demonstrate that the Multi-Agent Reinforcement Learning algorithm can reduce simulation time significantly compared to deep reinforcement learning, genetic algorithm, particle swarm optimization, and the artificial fish swarm algorithm. The superior performance of the proposed method indicates that it may be a realistic solution for large-scale implementation.",none
Dual-attention assisted deep reinforcement learning algorithm for energy-efficient resource allocation in Industrial Internet of Things,https://dl.acm.org/doi/10.1016/j.future.2022.12.009,1,research-article,ACM,2023,"This paper investigates the distributed resource allocation problem for energy-efficient data forwarding in resource-constrained Industrial Internet of Things (IIoT). We formulate this problem as a decentralized partially observable Markov decision process (Dec-POMDP) and propose a novel energy-efficient resource allocation algorithm based on the dual-attention assisted deep reinforcement learning (DRL) model, namely DADR, which adopts the centralized training and distributed executed (CTDE) framework to provide the intelligent decision-making ability for resource-constrained nodes. In DADR, we design a multi-scale convolutional attention module (CAM) in actor network that can extract the local state’s feature information from different dimensions; meanwhile, we propose a novel critic network based on dual-attention module and experience reconstruction module which provides a more objective and correct state evaluation from a global perspective. Moreover, the proposed critic network can solve the partially observable and non-stationary problems in multi-agent systems and can flexibly scale without changing the model structure even in a dynamic environment. Furthermore, the cooperation between CAM and multi-head self-attention (MHSA) in DADR improves the representation learning ability of DRL and offers better optimization direction for the DRL model to maximize the energy-efficient and data transmission reliability. Simulation results demonstrate that the proposed DADR algorithm outperforms the existing resource allocation algorithms and MARL models in terms of network lifetime, transmission reliability, and network stability, respectively.Highlights•A dual-attention module assisted DRL algorithm is designed for resource allocation.•The policy network with CAM module can extract fine-grained local state information.•A novel experience reconstruction module for updating the states and hybrid reward.•Dual-attention assisted critic network provides local and global modeling capability.",none
Review of Energy Conservation Using Duty Cycling Schemes for IEEE 802.15.4 Wireless Sensor Network (WSN),https://dl.acm.org/doi/10.1007/s11277-013-1524-y,4,article,ACM,2014,"Energy conservation is one of the crucial issues in wireless sensor network (WSN). A significant solution to conserve energy is done by deploying duty cycle management mechanisms in the WSN applications. This paper reviews several duty cycle mechanisms in WSN such as Duty Cycle Learning Algorithm, adaptive media access control (MAC) protocol for efficient IEEE 802.15.4 (AMPE), distributed duty cycle management (DDCM), distributed duty cycle management low power broadcast (DDCM + LPB) and distributed beacon only period. These mechanisms change their parameters such as idle listening, packet accumulation and delay in the end device transmitting queue to improve the energy conservation in WSN. The performances of these different energy conservation mechanisms have been compared at the MAC layer of IEEE 802.15.4 standard. It is found that the DDCM + LPB has made approximately 100 % enhancement in terms of average energy efficiency as compared to the other mechanisms. DDCM + LPB has significant enhancements by adapting the duty cycle according to the network traffic load condition. Using this mechanism, the duty cycle is increased when the traffic load increases and vice versa. Its energy efficiency also outperforms the conventional DDCM by the average of 10 %.",none
Intelligence in wireless network routing through reinforcement learning,https://dl.acm.org/doi/10.1504/ijcnds.2019.101224,0,research-article,ACM,2019,"One of the critical challenges in mobile wireless network is resource optimised routing of messages without compromising the performance criteria of the network. Routing in wireless networks has been extensively studied and a variety of routing protocols have been proposed. But these protocols experiences problems due to the dynamism in network topology. To address these problems, reinforcement learning approaches are integrated in routing solutions. This review focuses on the impact of reinforcement learning algorithms to achieve intelligence in wireless network routing. We provide contexts and benefits of applying reinforcement learning paradigm and discuss the major techniques applied to optimise routing solutions. A survey of state of the art reinforcement learning-based routing protocols is presented and categorised these protocols according to the learning strategies. We also provide open issues and suggestions for future research in improving routing solutions.",none
Optimal path selection using reinforcement learning based ant colony optimization algorithm in IoT-Based wireless sensor networks with 5G technology,https://dl.acm.org/doi/10.1016/j.comcom.2023.09.015,0,research-article,ACM,2024,"The Internet of Things (IoTs) expanded quickly, giving rise to numerous services, apps, electronic devices with integrated sensors, and associated protocols, which are still being developed today. By enabling physical objects to communicate with each other and share important information while making decisions and carrying out their essential jobs, the IoTs enable them to see, hear, think, and execute crucial tasks. Wireless sensor networks (WSN), which act as the IoT's permanent layer, are essential for fifth-generation (5G) communications, which need the IoT to be considerably helped. A WSN comprises many sensor nodes that track and transmit data to the sink. Every round's data transmission ends at the sink (or base station). This work presents a Proximal Policy Optimization based Ant Colony Optimization (PPO-ACO) algorithm for optimal path selection in WSN. The proposed algorithm combines the strengths of both PPO with a reinforcement learning (RL) method, and ACO, a swarm intelligence method, to address the stochastic nature of the network and the complex trade-off between energy efficiency and security. The PPO component learns the policy for path selection based on the sampled rewards, while the ACO component updates the pheromone levels to guide the search toward the optimal path. Compared to the state-of-the-art, our simulation findings show that the suggested PPO-ACO algorithm performs better in terms of the number of active nodes. The average residual energy of the suggested algorithm decreases later than existing algorithms, indicating its higher efficiency.",none
Reinforcement learning based on routing with infrastructure nodes for data dissemination in vehicular networks (RRIN),https://dl.acm.org/doi/10.1007/s11276-022-02926-w,0,research-article,ACM,2022,"Vehicular-Ad hoc Networks are extremely important due to the potential for improving road safety, traffic monitoring, and in-vehicle infotainment services. A novel Q-learning-based routing protocol named Reinforcement learning-based Routing with Infrastructure Node Data Dissemination in Vehicular Network (RRIN) is proposed to efficiently address such a dynamic network. RRIN is a routing protocol that aims to achieve low end-to-end communication latency and a high data delivery ratio. To meet the objectives, we proposed two Q-routing functions for Road Model Segment Selection (RMSS) and Intermediate Vehicle Selection (IVS). The network environment is separated into road model segments, and Road Side Units at each road junction to assist nodes in data dissemination was deployed. The exploration feature of the Q-learning algorithm allowed the vehicles to randomly explore and interact with the dynamic environment in the vehicular network. Our findings show that the proposed RRIN routing protocol is highly beneficial compared to other efficient routing protocols with high packet delivery, high throughput, and low end-to-end communication latency. Due to the exploration and exploitation phases of Q-learning, the proposed RRIN routing protocol enhances the reliability and the efficiency of the vehicular network in terms of high throughput, low communication latency, and low packet and high packet delivery ratio. For RMSS, the shortest distance and higher connectivity distribution are considered parameters; whereas, the parameters for IVS are vehicle speed difference, link reliability, moving direction, and buffer size.",none
Review of Underwater Mobile Sensor Network for ocean phenomena monitoring,https://dl.acm.org/doi/10.1016/j.jnca.2022.103418,0,review-article,ACM,2022,"Underwater Mobile Sensor Network (UWMSN) has marked a new era in ocean observation systems involving large scale ocean phenomena monitoring applications. These spatial and temporally varying applications demand multiple mobile entities for the collection of large amounts of data. This paper gives a concise view of the current state of the art of such networks comprising multiple Autonomous Underwater Vehicles (AUVs) and their challenges. It provides a literature review of the channel model and networking protocols of the physical layer, data link layer and network layer. Important algorithms and techniques for localization and time synchronization have also been reviewed. These algorithms play a huge role in a cooperative mission involving multiple AUVs, to achieve a common notion of time and to share the location information among the vehicles. Moreover, this paper includes a survey of various software platforms that support UWMSN, testbeds/real-time deployments of UWMSN developed by various research institutes/organizations and briefly discusses the recent advancement in the field of UWMSN.",none
3R: A reliable multi agent reinforcement learning based routing protocol for wireless medical sensor networks,https://dl.acm.org/doi/10.1016/j.comnet.2023.110073,0,research-article,ACM,2024,"Interest in the Wireless Medical Sensor Network (WMSN) is rapidly gaining attention thanks to recent advances in semiconductors and wireless communication. However, by virtue of the sensitive medical applications and the stringent resource constraints, there is a need to develop a routing protocol to fulfill WMSN requirements in terms of delivery reliability, attack resiliency, computational overhead, and energy efficiency. This paper proposes 3R, a reliable multi agent reinforcement learning routing protocol for WMSN. 3R uses a novel resource-conservative Reinforcement Learning (RL) model to reduce the computational overhead, along with two updating methods to speed up the algorithm convergence. The reward function is re-defined as a punishment, combining the proposed trust management system to defend against well-known dropping attacks. Furthermore, an energy model is integrated with the reward function to enhance the network lifetime and balance energy consumption across the network. The proposed energy model only uses local information to avoid the resource burdens and the security concerns of exchanging energy information. Experimental results prove the lightweightness, attacks resiliency and energy efficiency of 3R, making it a potential routing candidate for WMSN.",none
Energy efficient and reliable routing in wireless body area networks based on reinforcement learning and fuzzy logic,https://dl.acm.org/doi/10.1007/s11276-022-02997-9,1,research-article,ACM,2022,"In Wireless Body Area Networks (WBANs), on the one hand, the energy of nodes is limited. On the other hand, the network topology often changes due to human movement or posture changes. Unstable network topology is easy to cause packet loss, and packet loss will cause inaccurate data collection. Therefore, how to effectively use energy to transmit data reliably becomes a key issue. For this problem, we propose an optimized routing protocol namely Energy Efficient and Reliable Routing based on Reinforcement Learning and Fuzzy Logic (EERR-RLFL). In EERR-RLFL, considering the heterogeneity of nodes in WBANs, we first establish a node rank division mechanism, by which sensor nodes are divided into different ranks from three aspects. Each rank is considered to be one of the factors that affect the link quality. Then, we propose the Fuzzy-Logic-based Link Quality Evaluation (FLLQE) algorithm. It makes use of the fuzzy evaluation method of fuzzy logic and considers the comprehensive influence of multiple factors to evaluate the link quality between two nodes, which will provide reference for routing path selection. In the process of data transmission, based on the FLLQE algorithm, we use a hybrid data transmission mode, in which the time when a forwarding node is needed is first determined, and then the Reinforcement Learning algorithm is used to select the global optimized routing path. Simulation results show that EERR-RLFL outperforms Single Hop Transmission and Optimized Cost Effective and Energy Efficient Routing in terms of network lifetime, packet loss ratio and energy efficiency.",none
Reinforcement learning based energy efficient protocol for wireless multimedia sensor networks,https://dl.acm.org/doi/10.1007/s11042-021-11387-w,1,research-article,ACM,2022,"With the advancements in sensor networks, Wireless multimedia sensor networks (WMSNs) have emerged and shifted the objectives of sensor nodes to multimedia devices which can retrieve audio, images, and video. In WMSNs, the sensor nodes are tiny microphones and cameras which can transmit image, audio or video using the network. However, these nodes are battery constrained (i.e., may become dead after passing certain iterations). Therefore, improvement of the network lifetime is a challenging issue of WMSNs. In this paper, a reinforcement-based energy-aware protocol is designed and implemented. To successfully implement the reinforcement-based protocol, a State-Action-Reward-State-Action (SARSA) is used for learning a Markov decision process. Extensive experiments are considered to evaluate the significant improvement of the proposed protocol. Comparisons are also drawn between the competitive protocols and the proposed protocol. From comparative analysis, it is found that the proposed protocol conserves more energy as compared to the competitive protocols.",none
